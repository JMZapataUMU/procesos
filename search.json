[
  {
    "objectID": "Tema1.html#conceptos-básicos-y-ejemplos",
    "href": "Tema1.html#conceptos-básicos-y-ejemplos",
    "title": "2  Tema 1. Introducción a los procesos estocásticos",
    "section": "2.1 Conceptos básicos y ejemplos",
    "text": "2.1 Conceptos básicos y ejemplos\nA lo largo de este tema, vamos a fijar un espacio de probabilidad \\((\\Omega,\\mathcal{F},\\mathbb{P})\\) y un subconjunto \\(\\mathbb{T}\\subset [0,\\infty)\\).\n\n\n\n\n\n\nDefinición\n\n\n\nUn proceso estocástico \\((X_t)_{t\\in\\mathbb{T}}\\) es una colección de variables aleatorias reales \\(X_t\\) definidas en el espacio de probabilidad \\((\\Omega,\\mathcal{F},\\mathbb{P})\\).\n\n\nInterpretamos \\(t\\) como el tiempo (medido en cierta unidad).\n\nSi \\(\\mathbb{T}\\) es contable (por ejemplo, \\(\\mathbb{T}=\\{0&lt;1&lt;2&lt;\\ldots\\}\\), diremos que el proceso estocástico \\((X_t)_{t\\in\\mathbb{T}}\\) es de tiempo discreto.\nSi \\(\\mathbb{T}\\) es un intervalo (por ejemplo, \\(\\mathbb{T}=[0,T]\\) o \\(\\mathbb{T}=[0,\\infty)\\), diremos que el proceso estocástico es de tiempo continuo.\n\nPara cada \\(t\\in\\mathbb{T}\\) tenemos una variable aleatoria \\(X_t\\). La variable aleatoria \\(X_t\\) tomará un valor numérico \\(X_t(\\omega)\\) para cada \\(\\omega\\in\\Omega\\). A los posibles valores que toma un proceso estocástico se les llama estados.\n\nSi para cada \\(t\\in \\mathbb{T}\\) la variable aleatoria \\(X_t\\) es de tipo discreto, diremos que el proceso estocástico \\((X_t)_{t\\in\\mathbb{T}}\\) es de estado discreto.\nSi para cada \\(t\\in \\mathbb{T}\\) la variable aleatoria \\(X_t\\) es de tipo continuo, diremos que el proceso estocástico \\((X_t)_{t\\in\\mathbb{T}}\\) es de estado continuo.\n\n\n\n\n\n\nTipos de procesos estocásticos\n\n\n\n\nEn lo que sigue, siempre supondremos que \\(0\\in\\mathbb{T}\\). Esta condición no es realmente restrictiva, ya que podemos desplazar el tiempo por una constante para garantizar que dicha condición se cumpla.\n\n\n\n\n\n\nDefinición\n\n\n\nDado un proceso estocástico \\((X_t)_{t\\in\\mathbb{T}}\\), para cada realización \\(\\omega\\in\\Omega\\), la colección de números reales \\((X_t(\\omega))_{t\\in\\mathbb{T}}\\) se llama trayectoria del proceso.\n\n\n\nPara un proceso estocástico \\((X_{t})_{t=0,1,2,\\ldots}\\) de tiempo discreto, cada trayectoria define una sucesión de números reales \\((x_t)_{t=0,1,2,\\ldots}\\).\n\n\n\nPara un proceso estocástico \\((X_{t})_{t\\in [0,\\infty)}\\) de tiempo continuo, cada trayectoria define una función real \\(t\\mapsto x(t)\\colon [0,\\infty)\\to\\mathbb{R}\\).\n\nCada trayectoria corresponde a una observación particular de la evolución del valor de un proceso estocástico en el tiempo.\n\n\n\n\n\n\nEjemplo\n\n\n\nSupón que inviertes 100 euros en una cuenta bancaria con tipo de interés anual \\(R\\), compuesto anualmente. Es decir, si \\(X_t\\) es la cantidad de dinero en el año \\(t\\), entonces \\[\nX_t=100\\cdot(1+R)^t\\quad\\mbox{ para }t=0,1,2,\\ldots.\n\\] Supongamos también que el valor de \\(R&gt;0\\) es fijado cuando metes el dinero en la cuenta y sigue una distribución \\(\\mathrm{Exp}(1)\\).\nPara cada observación particular \\(R=r\\) de la variable \\(R\\) tendremos una trayectoria del proceso estocástico \\((X_t)_{t=0,1,2,\\ldots}\\). Podemos simular y dibujar cinco trayectorias de este proceso estocástico mediante el siguiente código en R:\n\nset.seed(112) \nnsim &lt;- 5  \nr &lt;- rexp(nsim, 1) \ntiempo &lt;- 0:10\nx &lt;- 100*(1+r[1])^tiempo\n\ncolores &lt;- rainbow(nsim)\n\nplot(tiempo, x, col=colores[1], type = \"l\", lty = 1)\n\nfor(i in 2:nsim){\n  x &lt;- 100*(1+r[i])^tiempo\n  lines(tiempo, x, col=colores[i])\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEjemplo\n\n\n\nUna moneda es lanzada reiteradas veces. En cada lanzamiento, apostamos un euro a cara, de modo que ganamos un euro si sale cara y perdemos un euro si sale cruz. De esta manera, si \\(X_t\\) es la ganancia acumulada en el lanzamiento \\(t\\), tendremos que \\(X_0=0\\) y \\[\nX_t=X_{t-1}+Y_t\\quad\\mbox{ para }t=1,2,3,\\ldots,\n\\] donde las variables \\(Y_1,Y_2,Y_3\\ldots\\) son indendientes y verfican \\(\\mathbb{P}(Y_t=1)=\\frac{1}{2}=\\mathbb{P}(Y_t=-1)\\).\n\n\nEl proceso del ejemplo anterior es un caso particular de un tipo de proceso el cual introducimos a continuación.\n\n\n\n\n\n\nDefinición\n\n\n\nSea una \\(Y_1,Y_2,Y_3,\\ldots\\) una sucesión de variables independientes de modo que \\(\\mathbb{P}(Y_t=1)=p\\) y \\(\\mathbb{P}(Y_t=1)=1-p\\). Al proceso estocástico \\((x_t)_{t=0,1,2,\\ldots}\\) con \\(X_0=0\\) y \\[\nX_t=X_{t-1}+Y_t\\quad\\mbox{ para }t=1,2,3,\\ldots,\n\\] se le llama paseo aleatorio (simple). Cuando \\(p=1/2\\) se dice se llama paseo aleatorio simétrico.\n\n\nPara cada secuencia de lanzamientos observados, tendremos una trayectoria diferente del proceso estocástico \\((X_t)_{t=0,1,2,\\ldots}\\). Podemos simular y dibujar veinte trayectorias de este proceso estocástico mediante el siguiente código en R:\n\nset.seed(145)\nnsim &lt;- 20\nnlanzamientos &lt;- 100\ny &lt;- sample(c(-1,1), size=nlanzamientos, replace=TRUE)\nx &lt;- c(0, cumsum(y))\ntiempo &lt;- 0:nlanzamientos\n\ncolores &lt;- rainbow(nsim)\n\nplot(tiempo, x, col=colores[1], type = \"l\", lty = 1, ylim=c(-20, 20))\n\nfor(i in 2:nsim){\n  y &lt;- sample(c(-1,1), size=nlanzamientos, replace=TRUE)\n  x &lt;- c(0, cumsum(y))\n  lines(tiempo, x, col=colores[i])\n}"
  },
  {
    "objectID": "Tema1.html#funciones-de-distribución-asociadas-a-un-proceso",
    "href": "Tema1.html#funciones-de-distribución-asociadas-a-un-proceso",
    "title": "2  Tema 1. Introducción a los procesos estocásticos",
    "section": "2.2 Funciones de distribución asociadas a un proceso",
    "text": "2.2 Funciones de distribución asociadas a un proceso\nDado un proceso estocástico \\((X_t)_{t\\in\\mathbb{T}}\\), cada variable aleatoria \\(X_t\\) tendrá su propia distribución de probabilidad la cual puede ser discreta o continua. Observar un proceso estocástico en un solo tiempo de forma aislada no es útil para describir su comportamiento como función del tiempo, ya que los valores observados en un tiempo pueden condicionar su comportamiento en tiempos distintos. Por ejemplo, en el caso del camino aleatorio simétrico en el que apostamos un euro a cara, si hemos acumulado muchas ganancias en el pasado, la ganancia acumulada seguirá siendo alta en las siguientes jugadas, ya que partimos de una cantidad alta la cual disminuirá a lo sumo en un euro en cada lanzamiento.\nPor ese motivo, es necesario estudiar la distribución de probabilidad conjunta a lo largo de varios tiempos.\n\n\n\n\n\n\nDefinición\n\n\n\nSupongamos que \\((X_t)_{t\\in\\mathbb{T}}\\) es un proceso estocástico. Dada una sucesión finita de tiempos \\(\\{t_1&lt;t_2&lt;\\ldots&lt;t_n\\}\\subset \\mathbb{T}\\), la función \\(F_{t_1,t_2,\\ldots,t_n}\\colon\\mathbb{R}^n\\to[0,1]\\) definida por \\[\nF_{t_1,t_2,\\ldots,t_n}(x_1,x_2,\\ldots,x_n)=\\mathbb{P}(X_{t_1}\\le x_1, X_{t_2}\\le x_2,\\ldots,X_{t_n}\\le x_n),\n\\] se llama función de distribución (marginal) finito dimensional del proceso \\((X_t)_{t\\in\\mathbb{T}}\\).\n\n\nLa función de distribución finito dimensional describe el comportamiento probabilístico del proceso estocástico observado en los distintos tiempos \\(t_1,t_2,\\ldots,t_n\\). La distribución de probabilidad de un proceso está caracterizada por el conjunto de todas las distribuciones finito dimensionales. En particular, dos procesos estocásticos con las mismas funciones de distribución finito dimensionales tendrán un comportamiento probabilístico similar.\nEn el caso de que \\((X_t)_{t\\in\\mathbb{T}}\\) sea de estado discreto, entonces dicho comportamiento probabilístico puede ser descrito por medio la función puntual de probabilidad finito dimensional \\[\nP_{t_1,t_2,\\ldots,t_n}(x_1,x_2,\\ldots,x_n)=\\mathbb{P}(X_{t_1}=x_1, X_{t_2}=x_2,\\ldots,X_{t_n}= x_n).\n\\] En el caso de que \\((X_t)_{t\\in\\mathbb{T}}\\) sea de estado continuo, consideraremos la función de densidad finito dimensional \\(f_{t_1,t_2,\\ldots,t_n}(x_1,x_2,\\ldots,x_n)\\), la cual verifica \\[\n\\mathbb{P}(a_1&lt;X_{t_1}&lt;b_1,\\ldots,a_n&lt;X_{t_n}&lt;b_n)=\\int_{a_n}^{b_n}\\cdots \\int_{a_1}^{b_1}f_{t_1,t_2,\\ldots,t_n}(x_1,x_2,\\ldots,x_n) {\\mathrm dx_1}\\ldots {\\mathrm  dx_n}\n\\] para todo \\(-\\infty\\le a_i&lt;b_i\\le \\infty\\).\n\n\n\n\n\n\nDefinición\n\n\n\nDado un proceso estocástico \\((X_t)_{t\\in\\mathbb{T}}\\) la función media o función de medias \\(\\mu_X\\colon \\mathbb{T}\\to \\mathbb{R}\\) se define como \\[\\mu_X(t)=\\mathbb{E}(X_t).\\]\n\n\n\nPara un proceso estocástico \\((X_{t})_{t=0,1,2,\\ldots}\\) de tiempo discreto, la función media define una sucesión de números reales \\((\\mu_X(t))_{t=0,1,2,\\ldots}\\).\nPara un proceso estocástico \\((X_{t})_{t\\in [0,\\infty)}\\) de tiempo continuo, la función media define una función real \\(t\\mapsto \\mu_X(t)\\colon [0,\\infty)\\to\\mathbb{R}\\).\n\nLa función de medias da una idea de cómo el proceso estocástico se comporta en promedio a lo largo del tiempo.\n\n\n\n\n\n\nEjemplo\n\n\n\nVolvamos al ejemplo donde una moneda es lanzada reiteras veces y \\((X_t)_{t=0,1,2,\\ldots}\\) son las ganancias acumuladas al apostar un euro a cara en cada lanzamiento (paseo aleatorio simétrico). En este caso, \\(\\mu_X(0)=\\mathbb{E}(X_0)=\\mathbb{E}(0)=0\\) y, si \\(t&gt;0\\), \\[ \\mathbb{E}(X_t)=\\mathbb{E}(Y_1+Y_2+\\ldots+Y_t)=\\mathbb{E}(Y_1)+\\mathbb{E}(Y_2)+\\ldots+\\mathbb{E}(Y_t)=0, \\] donde hemos aplicado que \\(\\mathbb{E}(Y_s)=0\\) para todo \\(s\\). En definitiva, la ganancia acumulada promedio es \\(0\\) para cualquier número de lanzamientos efectuado.\n\n\n\n\n\n\n\n\nDefinición\n\n\n\nDado un proceso estocástico \\((X_t)_{t\\in\\mathbb{T}}\\) la función de covarianzas \\(C_X\\colon \\mathbb{T}\\times\\mathbb{T}\\to \\mathbb{R}\\) se define como \\[ C_X(s,t)={\\mathrm  Cov}(X_s,X_t)=\\mathbb{E}\\Big((X_s-\\mu_X(s))(X_t-\\mu_X(t)\\Big)=\\mathbb{E}(X_s X_t)-\\mu_X(s)\\mu_X(t). \\] La función de varianzas \\(\\sigma_X^2\\colon \\mathbb{T}\\to \\mathbb{R}\\) se define como \\[ \\sigma_X^2(t)={\\mathrm  Var}(X_t)=C_X(t,t), \\] y la función de correlaciones \\(\\rho_X\\colon \\mathbb{T}\\times\\mathbb{T}\\to \\mathbb{R}\\) se define como \\[ \\rho_X(s,t)=\\frac{C_X(s,t)}{\\sigma_X(s)\\sigma_X(t)}. \\]\n\n\n\n\n\n\n\n\nEjemplo\n\n\n\nConsideremos el proceso estocástico \\((X_t)_{t\\in [0,\\infty)}\\) definido como \\[\nX_t=A + B t\\quad\\mbox{ para todo }t,\n\\] donde \\(A\\) y \\(B\\) son variables aleatorias \\(N(1,1)\\) independientes. En este caso tenemos \\[\\begin{align*}\nC_X(s,t)&=\\mathbb{E}(X_s X_t)-\\mu_X(s)\\mu_X(t)\\\\\n&=\\mathbb{E}\\big((A + B t)(A + B s)\\Big)\\\\\n&=\\mathbb{E}\\big(A B + A B (s + t) + A B s t)\\Big)\\\\\n&=\\mathbb{E}(A)\\mathbb{E}(B) + \\mathbb{E}(A)\\mathbb{E}(B) (s + t) + \\mathbb{E}(A) \\mathbb{E}(B) s t\\\\\n&=1 + s + t + st.\n\\end{align*}\\]\n\n\n\n\n\n\n\n\nEjemplo\n\n\n\nVolvamos al ejemplo del paseo aleatorio simétrico \\((X_t)_{t=0,1,2,\\ldots}\\). Fijados dos números naturales \\(n,m\\) con \\(n\\le m\\), tenemos \\[\\begin{align*}\nC_X(n,m)&=\\mathbb{E}\\Big(X_n X_m\\Big)\\\\\n&=\\mathbb{E}\\Big(X_n (X_m-X_n + X_n)\\Big)\\\\\n&=\\mathbb{E}\\Big(X_n(X_m-X_n)\\Big) + \\mathbb{E}\\Big(X_n^2\\Big)\\\\\n&=\\mathbb{E}(X_n) \\mathbb{E}(X_m-X_n) + \\mathbb{E}(X_n^2)\\\\\n&=n=\\min(n,m),\n\\end{align*}\\] donde hemos usado que \\(X_n\\) y \\(X_m-X_n\\) son variables aleatorias independientes. Además, obsérvese que, como \\(X_n=Y_1+Y_2+\\ldots + Y_n\\) y las variables \\(Y_1,Y_2,\\ldots,Y_n\\) son independientes, se tiene que \\[ {\\mathrm  Var}(X_n) = {\\mathrm  Var}(Y_1^2)+{^\\mathrm  Var}(Y_2^2)+\\ldots + {\\mathrm  Var}(Y_n^2)=1+1+\\ldots + 1=n, \\] y por tanto \\[ \\mathbb{E}(X_n^2)={\\mathrm  Var}(X_n) +(\\mathbb{E}(X_n))^2=n+0=n. \\]"
  },
  {
    "objectID": "Tema1.html#procesos-estacionarios-y-débilmente-estacionarios",
    "href": "Tema1.html#procesos-estacionarios-y-débilmente-estacionarios",
    "title": "2  Tema 1. Introducción a los procesos estocásticos",
    "section": "2.3 Procesos estacionarios y débilmente estacionarios",
    "text": "2.3 Procesos estacionarios y débilmente estacionarios\nLos procesos estocásticos se pueden dividir entre estacionarios (en sentido estricto), débilmente estacionarios y no estacionarios. Intuitivamente hablando, un proceso estocástico es estacionario (en sentido estricto) si su comportamiento probabilístico o distribución no cambia con el tiempo.\n\n\n\n\n\n\nDefinición\n\n\n\nUn proceso estocástico \\((X_t)_{t\\in\\mathbb{T}}\\) se dice que es estacionario si para toda sucesión finita de tiempos \\(t_1,t_2,\\ldots,t_n\\) y todo \\(s&gt;0\\) se verifica que los vectores aleatorios \\[\n(X_{t_1},X_{t_2},\\ldots,X_{t_n})\\quad\\mbox{ y }\\quad (X_{t_1+s},X_{t_2+s},\\ldots,X_{t_n+s})\n\\] tienen la misma función de distribución, es decir, \\[\nF_{t_1,t_2,\\ldots,t_n}(x_1,x_2,\\ldots,x_n)=F_{t_1+s,t_2+s,\\ldots,t_n+s}(x_1,x_2,\\ldots,x_n)\n\\] para cualesquiera números reales \\(x_1,x_2,\\ldots, x_n\\).\n\n\nEn particular, si un proceso es estacionario, entonces todas las variables aleatorias \\(X_t\\) del proceso tienen la misma distribución, es decir, están idénticamente distribuidas. Esto no implica que los vectores aleatorios que se pueden formar con las variables del proceso en diferentes instantes tengan todos la misma distribución.\nEn la práctica es muy útil saber si un proceso estocástico es estacionario cuando es necesario predecir el comportamiento futuro de dicho proceso. Si sabemos que el proceso es estacionario, entonces observando su comportamiento en el pasado podremos inferir información de su comportamiento en el futuro.\nA continuación introducimos una noción de estacionaridad menos exigente, la cual es también muy útil para predecir comportamientos futuros de procesos estocásticos reales.\n\n\n\n\n\n\nDefinición\n\n\n\nUn proceso estocástico \\((X_t)_{t\\in\\mathbb{T}}\\) se dice que es débilmente estacionario si:\n\n\\(\\mu_X(t)=\\mu_X(0)\\) para todo \\(t\\in\\mathbb{T}\\). Es decir, la función de medias es constante.\n\\(C_X(s,t)=C_X(0,t-s)\\) para todo \\(t,s\\in\\mathbb{T}\\) con \\(s\\le t\\). Es decir, la función de covarianzas depende sólo del salto entre tiempos.\n\n\n\nObsérvese que, en particular, si el proceso es débilmente estacionario tendrá función de varianzas constante.\nDado que la media \\(\\mu_X(t)\\) es determinada por la función de distribución marginal \\(F_t(x)\\), y la covarianza \\(C_X(s,t)\\) es determinada por la función de distribución marginal \\(F_{s,t}(x)\\), todo proceso estacionario será también débilmente estacionario. Sin embargo, es posible que un proceso sea débilmente estacionario pero no estacionario.\n\n\n\n\n\n\nEjemplo\n\n\n\nConsideremos el proceso estocástico \\((X_t)_{t\\in[0,\\infty)}\\) definido por \\[\nX_t=Y\\cos(U+ t),\n\\] donde \\(Y\\) y \\(U\\) son variables aleatorias independientes con \\(Y\\sim N(0,1)\\) y \\(U\\sim U[0,2\\pi]\\). Entonces \\[\n\\mu_X(t)=0,\n\\] y además, para \\(s\\le t\\), \\[\\begin{align*}\nC_X(s,t)&=\\mathbb{E}(X_s X_t)-\\mu_X(s)\\mu_X(t)\\\\\n&=\\mathbb{E}\\big((Y\\cos(U+ s))(Y\\cos(U+ t))\\Big)\\\\\n&=\\mathbb{E}(Y^2)\\mathbb{E}\\Big(\\cos(U+ s)\\cos(U+ t)\\Big)\\\\\n&=\\mathbb{E}\\Big(\\cos(U+ s)\\cos(U+ t)\\Big)\\\\\n&=\\mathbb{E}\\Big(\\tfrac{1}{2}\\cos(2U+ s + t) + \\tfrac{1}{2}\\cos(t - s)\\Big)\\\\\n&=\\mathbb{E}\\Big(\\tfrac{1}{2}\\cos(2U+ s + t)\\Big) + \\tfrac{1}{2}\\cos(t - s)\\\\\n&=\\tfrac{1}{2}\\int_0^{2\\pi} (\\cos(2u+ s + t) \\tfrac{1}{2\\pi})du +  \\tfrac{1}{2}\\cos(t - s)\\\\  \n&=0 +  \\tfrac{1}{2}\\cos(t - s)\\\\\n&=\\tfrac{1}{2}\\cos(t - s).\n\\end{align*}\\] En particular, tenemos que \\(C_X(s,t)=\\tfrac{1}{2}\\cos(t - s)=C_X(0,t-s)\\), de donde deducimos que el proceso estocástico \\((X_t)_{t\\in[0,\\infty)}\\) es débilmente estacionario."
  },
  {
    "objectID": "Tema1.html#procesos-gaussianos",
    "href": "Tema1.html#procesos-gaussianos",
    "title": "2  Tema 1. Introducción a los procesos estocásticos",
    "section": "2.4 Procesos gaussianos",
    "text": "2.4 Procesos gaussianos\nA continuación introducimos una de las familias de procesos estocásticos más importantes: los procesos gaussianos. Este tipo de procesos tienen importantes aplicaciones en Machine Learning.\nRecordemos primero la noción de variable Normal multivariante. Una propiedad importante de las variables normales multivariadas es que su función de densidad (y, por tanto, su distribución) está completamente determinada por el vector de medias y la matriz de covarianzas.\n\n\n\n\n\n\nDefinición\n\n\n\nSe dice que el vector aleatorio \\(\\vec{X}=(X_1,X_2,\\ldots,X_n)\\) sigue una distribución Normal multivariante si su función de densidad viene dada por: \\[\nf_X(\\vec{x}) = \\frac{1}{(2\\pi)^{n/2}\\,\\sqrt{|C_X|}}\n\\exp\\left\\{-\\tfrac{1}{2}(\\vec{x}-\\vec{\\mu}_X)^{T} C_X^{-1} (\\vec{x}-\\vec{\\mu}_X)\\right\\}\n\\quad \\text{para todo } \\vec{x}\\in \\mathbb{R}^n.\n\\] donde \\(\\vec\\mu_X\\) es el vector de medias de \\(\\vec{X}\\) y \\(C_X\\) es la matriz de covarianzas de \\(\\vec{X}\\).\n\n\n\n\n\n\n\n\nPropiedad\n\n\n\nSe puede probar, aunque no es inmediato, que una condición equivalente para que el vector aleatorio \\((X_1,X_2,\\ldots,X_n)\\) siga una distribución Normal multivariante es que, para cualesquiera números reales \\(a_1,a_2,\\ldots,a_n\\), la variable aleatoria real \\[\na_1 X_1 + a_2 X_2 + \\ldots + a_n X_n\n\\] sigue una distribución Normal univariante.\n\n\nOtra importante propiedad de las variables aleatorias normales multivariadas que conviene recordar es que las transformaciones lineales de estas variables también son normales multivariadas. En otras palabras, si \\(\\vec{X}\\) es un vector aleatorio Normal multivariante de tamaño n, \\(A\\) es una matriz constante de tamaño \\(m\\times n\\), y \\(\\vec{b}\\) es un vector constante de tamaño \\(m\\), entonces el vector aleatorio \\(\\vec{Y}=A\\vec{X}+\\vec{b}\\) también es un vector aleatorio Normal multivariante.\n\n\n\n\n\n\nDefinición\n\n\n\nUn proceso estocástico \\((X_t)_{t\\in\\mathbb{T}}\\) se dice que es gaussiano (o Normal) si para toda sucesión de tiempos \\(t_1,t_2,\\ldots, t_n\\in\\mathbb{T}\\) el vector aleatorio \\[(X_{t_1},X_{t_2},\\ldots,X_{t_n})\\] es una variable Normal multivariante.\n\n\nUna importante propiedad de los procesos gaussianos es que las nociones de estacionaridad y estacionaridad débil son equivalentes para este tipo de procesos. En la práctica esto significa que para verificar que un proceso gaussiano es estacionario basta analizar su media y covarianza. Concretamente, tenemos lo siguiente.\n\n\n\n\n\n\nTeorema\n\n\n\nSea \\((X_t)_{t\\in\\mathbb{T}}\\) un proceso estocástico gaussiano. Si \\((X_t)_{t\\in\\mathbb{T}}\\) es débilmente estacionario, entonces es también estacionario."
  },
  {
    "objectID": "Tema1.html#ejemplos-y-simulación",
    "href": "Tema1.html#ejemplos-y-simulación",
    "title": "2  Tema 1. Introducción a los procesos estocásticos",
    "section": "2.5 Ejemplos y simulación",
    "text": "2.5 Ejemplos y simulación\nEn lo que sigue vamos a estudiar y simular en R algunos ejemplos particulares de procesos estocásticos gaussianos, analizando en cada caso si se trata de procesos estacionarios o no estacionarios.\n\n2.5.1 Ruido blanco gaussiano\nUn proceso estocástico \\((X_{t})_{t\\in\\mathbb{T}}\\) se llama ruido blanco gaussiano si las variables aleatorias \\(X_t\\) son independientes y siguen una distribución \\(N(0,\\sigma^2)\\).\nClaramente el ruido blanco gaussiano es un proceso gaussiano. Además, \\(\\mu_X(t)=0\\), \\(C_X(t,s)=0\\) si \\(t\\neq s\\), y \\(C_X(t,t)=\\sigma^2\\). Lo cual en particular implica que el ruido blanco gaussiano es un proceso estacionario.\nPodemos simular en R un trayectoria del ruido blanco gaussiano:\n\nset.seed(11)\nsigma &lt;- 1\ntiempos = seq(from = 0, to = 1, by = 0.001)\nx=rnorm(length(tiempos), 0, sigma)\nplot(tiempos, x, type = \"l\", lty = 1)\n\n\n\n\n\n\n\n\nObtenemos una trayectoria extremadamente irregular. Además, observamos a simple vista un comportamiento estacionario del proceso.\n\n\n2.5.2 Movimiento Browniano\nUn proceso estocástico \\((X_{t})_{t\\in [0,\\infty)}\\), de tiempo continuo, se dice que es un movimiento Browniano o proceso de Wiener si:\n\n\\(X_0=0\\),\nPara todo par de tiempos \\(s\\le t\\), la variable aleatoria \\(X_{t}-X_{s}\\) sigue una distribución \\(N(0,t-s)\\),\nPara cualquier sucesión de tiempos \\(t_1&lt;t_2&lt;\\ldots&lt;t_n\\) se tiene que las variables aleatorias \\[ X_{t_2}-X_{t_1},\\quad X_{t_3}-X_{t_2},\\quad \\ldots,\\quad X_{t_n}-X_{t_{n-1}} \\] son independientes.\nLas trayectorias \\(t\\mapsto X_t(\\omega)\\) son funciones continuas.\n\nEl movimiento Browniano se utiliza en finanzas para modelar la evolución del precio de activos financieros como las acciones o los tipos de cambio. En particular, se aplica a la valoración de opciones financieras mediante el modelo de Black-Scholes, y el análisis de riesgos.\nA continuación vamos a simular una trayectoria del movimiento Browniano. Para ello fijamos un incremento de tiempo \\(\\Delta t&gt;0\\) y un número natural \\(n\\). Deseamos simular una trayectoria en los instantes de tiempo \\(t_0=0\\), \\(t_1=\\Delta t\\), …, \\(t_n=n\\Delta t\\). En vista de la definición de movimiento Browniano, tenemos que los incrementos \\[\n\\Delta X_{t_1}=X_{t_1}-X_{t_0},\\quad \\Delta X_{t_2}=X_{t_2}-X_{t_1},\\quad ...,\\quad \\Delta X_{t_n}=X_{t_n}-X_{t_{n-1}},  \n\\] son variables aleatorias idependientes y siguen todas ellas una distribución \\(N(0,\\Delta t)\\). De este modo, nuestra estrategia será simular los valores de los incrementos mediante la generación de una muestra aleatoria de \\(n\\) variables \\(N(0,\\Delta t)\\) independientes, y reconstruir la trayectoria del proceso a partir de dichos incrementos. Esto podemos lograrlo mediante el siguiente código de R:\n\nset.seed(11)\nn &lt;- 1000\ndt &lt;- 1/n\ntiempo &lt;- seq(from=0, to=1, by=dt)\nincrementos &lt;- rnorm(n, 0, sqrt(dt))\nx &lt;- c(0, cumsum(incrementos))\nplot(tiempo, x, type = \"l\", lty = 1)\n\n\n\n\n\n\n\n\nPara analizar el comportamiento probabilístico, simularemos diez trayectorias del proceso:\n\nset.seed(123)\nnsim &lt;- 10\nn &lt;- 1000\ndt &lt;- 1/n\ntiempos &lt;- seq(from=0, to=1, by=dt)\nincrementos &lt;- rnorm(n, 0, sqrt(dt))\nx &lt;- c(0, cumsum(incrementos))\n\ncolores &lt;- rainbow(nsim)\n\nplot(tiempos, x, ylim=c(-2,2), type = \"l\", lty = 1, col=colores[1])\n\n\nfor(i in 2:nsim){\n  incrementos=rnorm(n, 0, sqrt(dt))\n  x &lt;- c(0, cumsum(incrementos))\n  lines(tiempos, x, col=colores[i])\n}\n\n\n\n\n\n\n\n\nA simple vista observamos un comportamiento no estacionario del proceso. Notamos que a medida que avanza el tiempo, las trayectorias tienden a volverse más dispersas, lo que indica que el comportamiento probabilístico de las trayectorias varía con el tiempo.\nEl movimiento Browniano es un proceso gaussiano. De hecho, la distribución de probabilidad del vector aleatorio \\((X_{t_1},X_{t_2},\\ldots,X_{t_n})\\), para \\(t_1&lt;t_2&lt;\\ldots&lt;t_n\\), es normal multivariada porque se obtiene como una transformación lineal del vector \\((X_{t_1},X_{t_2}-X_{t_1},\\ldots,X_{t_n}-X_{t_{n-1}})\\), el cual es normal multivariado porque sus componentes son independientes y normales. ¿Puedes encontrar dicha transformación lineal?.\nAdemás, \\(\\mu_X(t)=\\mathbb{E}(X_t)=0\\) y, para \\(s\\le t\\), \\[\\begin{align*}\nC_X(s,t)&=\\mathbb{E}\\Big(X_s X_t\\Big)\\\\\n&=\\mathbb{E}\\Big(X_s (X_t-X_s + X_s)\\Big)\\\\\n&=\\mathbb{E}\\Big(X_s(X_t-X_s)\\Big) + \\mathbb{E}\\Big(X_s^2\\Big)\\\\\n&=s=\\min(s,t).\n\\end{align*}\\] En resumen, el movimiento Browniano es un proceso gaussiano con funciones de media y covarianza \\(\\mu_X(t)=0\\), y \\(C_X(s,t)=\\min(s,t)\\), respectivamente. En particular, observamos que este proceso no es estacionario (ni siquiera en el sentido débil), ya que en general no se verifica que \\(C_X(s,t)=C_X(0,t-s)\\). Por ejemplo, \\(C_X(3,4)=\\min(3,4)=3\\); sin embargo, \\(C_X(0,4-3)=\\min(0,1)=0\\).\nA continuación vamos a detallar otra estrategia para simular el movimiente Browniano, la cual se basa en que dicho proceso es gaussiano. Aunque nos vamos a centrar en el caso particular del movimiento Browniano, este procedimiento sirve para simular cualquier proceso gaussiano conocidas sus funciones de media y covarianza. Fijados los tiempos \\(t_1&lt;\\ldots&lt;t_n\\) sabemos que el vector aleatorio \\((X_{t_1},X_{t_2},\\ldots,X_{t_n})\\) sigue una distribución multivariada de media \\(\\mu_X=0\\) y matriz de convarianzas \\(C_X=(c_{i,j})_{n\\times n}\\) donde \\(c_{i,j}:=\\min\\{t_i,t_j\\}\\). De esta manera, podremos simular una trayectoria mediante la obtención de una muestra aleatoria del anterior vector aleatorio. Para ello utilizamos la libreria mvtnorm de R, la cual permite simular variables aleatorias normales multivariadas:\n\nset.seed(23)\nn &lt;- 1000\ndt &lt;- 1/n\ntiempo = seq(from=0, to=1, by=dt)\n\n# Definimos la matriz de covarianzas\nC &lt;- matrix(NA, nrow = n, ncol = n)\nC &lt;- dt*pmin(row(C),col(C))\n\n# Simulamos una normal multivariada \nlibrary(mvtnorm)\nx &lt;- rmvnorm(1, sigma=C)\n\n# Añadimos el valor 0 inicial\nx &lt;- c(0, x)\nplot(tiempo, x, type = \"l\", lty = 1)\n\n\n\n\n\n\n\n\n\n\n2.5.3 Procesos gaussianos estacionarios isotrópicos\nUn tipo particular de proceso gaussiano estacionario son los procesos gaussianos estacionarios isotrópicos. Decimos que un proceso gaussiano estacionario \\((X_t)_{t\\in\\mathbb{T}}\\) es isotrópico si su función de medias es constante, \\(\\mu_X(t)=\\mu\\), y la función de covarianza depende sólo de la distancia \\(|t-s|\\), es decir,\n\\[\nC_X(s,t)=K(|t-s|)\n\\] para cierta función \\(K\\colon [0,\\infty)\\to [0,\\infty)\\) llamada núcleo.\nTomemos por ejemplo \\(\\mu_X(t)=0\\) y el núcleo exponencial cuadrático \\(K_l(x):=\\exp(-x^2/2l^2)\\), donde \\(l\\) es un parámetro de escala. Vamos a simular en R una trayectoria de dicho proceso:\n\nset.seed(112)\nn &lt;- 1000\ndt &lt;- 1/n\ntiempo &lt;- seq(from=0, to=1, by=dt)\n\n\n# Definimos la matriz de covarianzas\nl &lt;- 1\nC &lt;- matrix(NA, nrow = n+1, ncol = n+1)\nC &lt;- dt*abs(row(C)-col(C))\nC &lt;- exp(-C^2/(2*l^2))\n\n# Simulamos una normal multivariada \nlibrary(mvtnorm)\nx &lt;- rmvnorm(1, sigma=C)\nplot(tiempo, x, type = \"l\", lty = 1)\n\n\n\n\n\n\n\n\nPara analizar el comportamiento probabilístico, podemos simular diez trayectorias del proceso:\n\nset.seed(112)\nnsim &lt;- 10\nn &lt;- 1000\ndt &lt;- 1/n\ntiempo &lt;- seq(from=0, to=1, by=dt)\n\n\n# Definimos la matriz de covarianzas\nl &lt;- 1\nC &lt;- matrix(NA, nrow = n+1, ncol = n+1)\nC &lt;- dt*abs(row(C)-col(C))\nC &lt;- exp(-C^2/(2*l^2))\n\n# Simulamos una normal multivariada \nlibrary(mvtnorm)\nx &lt;- rmvnorm(1, sigma=C)\n\ncolores &lt;- rainbow(10)\n\nplot(tiempo, x, type = \"l\", lty = 1, ylim=c(-2.5,2.5), col=colores[1])\n\nfor(i in 2:nsim){\n  x &lt;- rmvnorm(1,sigma=C)\n  lines(tiempo, x, col=colores[i])\n}\n\n\n\n\n\n\n\n\nA diferencia del movimiento Browniano, vemos que las trayectorias presentan un comportamiento estacionario, ya que su distribución es la misma a lo largo del tiempo. Otra diferencia con el movimiento Browniano es que las trayectorias tienen una apariencia suave.\nPodemos cambiar el parámero de escala, tomando \\(l=0.1\\). De este modo obtenemos las trayectorias:\n\n\n\n\n\n\n\n\n\nTomemos ahora el núcleo de Ornstein–Uhlenbeck \\(K_l(x):=\\exp(-|x|/l)\\).\nSimulemos algunas trayectorias en R:\n\nset.seed(114)\nnsim &lt;- 10\nn &lt;- 1000\ndt &lt;- 1/n\ntiempo &lt;- seq(from=0, to=1, by=dt)\n\n\n# Definimos la matriz de covarianzas\nl &lt;- 1\nC &lt;- matrix(NA, nrow = n+1, ncol = n+1)\nC &lt;- dt*abs(row(C)-col(C))\nC &lt;- exp(-C/l)\n\n# Simulamos una normal multivariada \nlibrary(mvtnorm)\nx &lt;- rmvnorm(1, sigma=C)\n\ncolores &lt;- rainbow(10)\n\nplot(tiempo, x, type = \"l\", lty = 1, ylim=c(-2.5,2.5), col=colores[1])\n\nfor(i in 2:nsim){\n  x &lt;- rmvnorm(1,sigma=C)\n  lines(tiempo, x, col=colores[i])\n}\n\n\n\n\n\n\n\n\nVemos que las trayectorias tienen una apariencia más irregular la cual nos recuerda al movimiento Browniano. Sin embargo, en este caso tenemos un proceso estacionario cuyas trayectorias se comportan de manera similar a lo largo del tiempo.\n\n\n2.5.4 Movimiento Browniano fraccional\nOtro proceso gaussiano importante es el movimiento Browniano fraccional, el cual es una generalización del movimiento Browniano clásico. A diferencia de éste, los incrementos del movimiento Browniano fraccional no son independientes.\nDado un número \\(H \\in (0,1)\\), decimos que un proceso estocástico \\((X_t)_{t\\in [0,\\infty)}\\) es un movimiento Browniano fraccional con índice de Hurst \\(H\\) si su función de medias es constantemente cero, \\(\\mu_X(t)=0\\), y su función de covarianzas está dada por\n\\[\nC_X(s,t) = \\frac{1}{2}\\left( t^{2H} + s^{2H} - |t-s|^{2H} \\right).\n\\] El índice de Hurst \\(H\\) describe la irregularidad del movimiento resultante: valores más altos producen trayectorias más suaves. Este proceso fue introducido por para modelizar fenómenos como los mercados financieros.\n\nVamos a simular en R una trayectoria de dicho proceso para H=0.2:\n\nset.seed(23)\nn &lt;- 1000\ndt &lt;- 1/n\ntiempo = seq(from=0, to=1, by=dt)\n\n# Definimos la matriz de covarianzas para H=0.2\nH &lt;- 0.2\nC &lt;- matrix(NA, nrow = n, ncol = n)\nC &lt;- (1/2)*((dt*row(C))^(2*H) + (dt*col(C))^(2*H) - abs(row(C) - col(C))^(2*H))\n\n\n# Simulamos una normal multivariada \nlibrary(mvtnorm)\nx &lt;- rmvnorm(1, sigma=C)\n\n# Añadimos el valor 0 inicial\nx &lt;- c(0, x)\nplot(tiempo, x, type = \"l\", lty = 1)\n\n\n\n\n\n\n\n\nVemos que la trayectoria obtenida menos suave que en el caso del movimiento Browniano usual. Al igual que el movimiento Browniano usual, no es un proceso estacionario."
  },
  {
    "objectID": "index.html#presentación",
    "href": "index.html#presentación",
    "title": "Procesos estocásticos y series temporales",
    "section": "0.1 Presentación",
    "text": "0.1 Presentación\nEl presente libro contiene los apuntes de la asignatura “Procesos estocásticos y series temporales”, la cual es impartida en el Grado en Ciencia e Ingeniería de Datos de la Universidad Politécnica de Cartagena y la Universidad de Murcia."
  },
  {
    "objectID": "index.html#licencia",
    "href": "index.html#licencia",
    "title": "Procesos estocásticos y series temporales",
    "section": "0.2 Licencia",
    "text": "0.2 Licencia\nEste es un libro abierto bajo la licencia\n\nPuedes copiar, redistribuir y adaptar la obra, siempre que des el crédito correspondiente, no la uses con fines comerciales y compartas bajo la misma licencia."
  }
]