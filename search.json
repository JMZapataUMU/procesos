[
  {
    "objectID": "Tema5.html#introducción",
    "href": "Tema5.html#introducción",
    "title": "6  Tema 5. Métodos de Alisado Exponencial",
    "section": "",
    "text": "Si la serie no presenta estacionalidad:\n\nMétodo de alisado exponencial simple: se usa cuando la tendencia se considera constante (localmente).\nMétodo de alisado exponencial doble: se usa cuando la tendencia se considera lineal (localmente).\nMétodo de Holt: se usa cuando la tendencia se considera lineal (localmente).\n\nSi la serie presenta estacionalidad:\n\nMétodo de Holt-Winters para modelos multiplicativos: se usa cuando la serie presenta estacionalidad, la tendencia se considera lineal localmente y ambas componentes se integran con esquema multiplicativo.\nMétodo de Holt-Winters para modelos aditivos: se usa cuando la serie presenta estacionalidad, la tendencia se considera lineal localmente y ambas componentes se integran con esquema aditivo.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Tema 5. Métodos de Alisado Exponencial</span>"
    ]
  },
  {
    "objectID": "Tema5.html#alisado-exponencial-simple",
    "href": "Tema5.html#alisado-exponencial-simple",
    "title": "6  Tema 5. Métodos de Alisado Exponencial",
    "section": "6.2 Alisado Exponencial Simple",
    "text": "6.2 Alisado Exponencial Simple\nEs el método más sencillo de alisado exponencial. Se aplica cuando la serie en estudio no presenta estacionalidad y la tendencia de la serie se considera constante (localmente). Es decir, no se advierte un patrón claro de tendencia ni estacionalidad.\nUn ejemplo ilustrativo sería la serie con el siguiente gráfico:\n\nts.plot(LakeHuron, \n        gpars = list(xlab = \"Year\", \n                   ylab = \"Level LakeHuron in feet\", \n                   lwd = 1.5))\n\n\n\n\n\n\n\n\nEn este caso suponemos que la serie en estudio se expresa de la siguiente forma en cada instante:\n\\[\n\\left\\{\n\\begin{array}{lll}\nx_t=T_t+I_t=a_t+I_t &  & \\text{modelo aditivo} \\\\\nx_t=T_t\\times I_t=a_t\\times I_t &  & \\text{modelo multiplicativo}\n\\end{array}\n\\right.\n\\]\ndonde hemos considerado que la componente de tendencia es constante en cada instante \\(t\\) (constante localmente): \\(T_t=a_t\\), con \\(a_t\\in \\Bbb{R}.\\)\nObsérvese que \\(a_t\\) representa la altura de la serie en cada instante \\(t\\) cuando realizamos su representación gráfica. Por este motivo se dice que \\(a_t\\) representa el nivel de la serie.\nAl no disponer de componente estacional y suponer tendencia constante, nuestro objetivo se reduce a estimar el nivel de la serie en cada instante.\nComo el resto de métodos de alisado exponencial, el alisado exponencial simple se caracteriza por dar más peso a las observaciones más recientes que a las observaciones más antiguas a la hora de realizar predicciones.\nDada una serie de observaciones, \\(\\{x_t\\}_{t=1,2,...,n}\\), en el alisado exponencial simple se obtiene otra serie denominada serie alisada (smoothing series), que denotaremos por \\(\\{A_t\\}_{t=1,2,...,n}\\), y que representa la estimación del nivel de la serie (\\(a_t\\)) en cada instante.\nLa serie alisada en cada instante \\(t\\) se obtiene a partir de la original mediante la siguiente expresión:\n\\[\nA_t=\\widehat{a}_t=\\alpha x_t+\\alpha (1-\\alpha )x_{t-1}+\\alpha (1-\\alpha\n)^2x_{t-2}+...+\\alpha (1-\\alpha )^{t-1}x_1  \n\\tag{6.1}\\]\ndonde \\(\\alpha \\in \\left(0,1\\right)\\) se conoce como parámetro de alisado.\nEs decir, la serie alisada se obtiene, en cada instante, como una media ponderada de las observaciones actual y anteriores de la serie original, donde las observaciones más recientes poseen más peso que las observaciones más antiguas. De hecho, el nombre de alisado exponencial se debe a que el peso de las observaciones decrece exponencialmente a medida que nos separamos del último instante observado (los valores de los pesos \\(\\alpha\\), \\(\\alpha (1-\\alpha )\\), \\(\\alpha (1-\\alpha )^2\\), …, \\(\\alpha (1-\\alpha)^{t-1}\\) decrecen exponencialmente al ser \\(\\alpha \\in \\left(0,1\\right)\\)).\nOtra de las características de los métodos de alisado exponencial es que las series alisadas se pueden obtener de manera recurrente, pudiendo actualizarse cada vez que disponemos de una nueva observación.\nTeniendo en cuenta la expresión (Ecuación 6.1), la serie alisada en el instante \\(t-1\\), viene dada por:\n\\[\nA_{t-1}=\\alpha x_{t-1}+\\alpha (1-\\alpha )x_{t-2}+\\alpha (1-\\alpha\n)^2x_{t-3}+...+\\alpha (1-\\alpha )^{t-2}x_1\n\\]\nde manera que:\n\\[\n(1-\\alpha )A_{t-1}=\\alpha (1-\\alpha )x_{t-1}+\\alpha (1-\\alpha\n)^2x_{t-2}+\\alpha (1-\\alpha )^3x_{t-3}+...+\\alpha (1-\\alpha )^{t-1}x_1\n\\]\ny teniendo en cuenta nuevamente (Ecuación 6.1), se obtiene la siguiente expresión que permite calcular la serie alisada de forma recurrente:\n\\[\n\\boxed{\nA_t = \\alpha x_t + (1 - \\alpha) A_{t-1} \\qquad \\forall t,\\ \\text{con}\\ \\alpha \\in [0, 1]\n}\n\\tag{6.2}\\]\nEs decir, la estimación del nivel en cada instante se puede obtener de forma recurrente:\n\\[\n\\boxed{\na_t = \\alpha x_t + (1 - \\alpha) a_{t-1} \\qquad \\forall t,\\ \\text{con}\\ \\alpha \\in [0, 1]\n}\n\\]\nNota: Haciendo abuso de la notación, hemos usado \\(a_t\\) en la serie alisada para denotar a la estimación del nivel. Además, consideraremos \\(\\alpha \\in \\left[0,1\\right]\\), permitiendo que \\(\\alpha\\) tome los valores \\(0\\) y \\(1\\) en las fórmulas recurrentes para facilitar la interpretación del parámetro de alisado.\nPara aplicar la fórmula recursiva anterior necesitamos disponer, por una parte, del valor del parámetro de alisado \\(\\alpha\\), y por otra parte, del valor inicial de la serie alisada \\(A_0\\) (nivel inicial de la serie \\(a_0\\)).\nComo valor inicial del nivel se suele usar el primer valor de la serie original, es decir:\n\\[\na_0=A_0=x_1\n\\]\no bien la media de las primeras observaciones, es decir:\n\\[\na_0=A_0=\\frac{x_1+...+x_k}k\\qquad \\text{con }k\\text{ pequeño}\n\\]\nCon respecto al parámetro de alisado \\(\\alpha\\), comentar que si se utiliza un valor próximo a uno (\\(\\alpha \\simeq 1\\)) se da mucho peso a la última observación de la serie y muy poco peso a las pasadas. Por el contrario, si se utiliza un parámetro de alisado próximo a cero (\\(\\alpha \\simeq 0\\)), se le da mucho peso al conjunto de las observaciones pasadas y poco a la última observación (véase (Ecuación 6.2)).\nSe ha comprobado empíricamente que un valor de \\(\\alpha =0.2\\) suele dar buenos resultados. Sin embargo, la mayoría del software permite seleccionar el valor de \\(\\alpha\\) que minimiza la suma de cuadrados de los errores de estimación. En R podremos seleccionar como parámetro de suavizado el valor de \\(\\alpha\\) óptimo según dicho criterio (minimiza la suma de cuadrados de los errores de predicción para el instante siguiente).\nNuestro fin último es realizar predicciones de la serie para instantes futuros. Si disponemos de información de la serie hasta el instante \\(T\\), \\(\\{x_t\\}_{t=1,2,...,T}\\), las predicciones de la serie usando el método de alisado exponencial simple vienen dadas por:\n\\[\n\\boxed{\n\\begin{aligned}\n\\widehat{x}_{T+1/T} &= a_T = A_T \\\\\n\\widehat{x}_{T+2/T} &= a_T = A_T \\\\\n\\vdots \\\\\n\\widehat{x}_{T+m/T} &= a_T = A_T \\qquad \\forall m = 1, 2, 3, \\ldots\n\\end{aligned}\n}\n\\]\ndonde \\(\\widehat{x}_{T+m/T}\\) denota el valor de la predicción en el instante \\(T+m\\) cuando disponemos de observaciones de la serie hasta el instante \\(T\\). Es decir, la predicción de la serie en el instante siguiente viene dada por la estimación del nivel en el último instante observado, o lo que es lo mismo, el valor de la serie alisada en el último instante observado. Y ésta también sería la predicción para instantes posteriores.\nSin embargo, a medida que disponemos de información nueva (nuevas observaciones), se calculan los valores de la serie alisada para los nuevos instantes y por tanto se revisan las predicciones de manera automática.\nPodemos decir que el alisado exponencial simple estima en cada instante \\(t\\) el nivel de la serie (altura de la serie), y al suponer tendencia constante las predicciones vienen dadas sólo por el último nivel estimado. En el siguiente gráfico se muestra la serie original (negro), la serie ajustada (azul) usando Alisado Exponencial Simple y las predicciones (rojo) para futuros instantes.\n\nSES &lt;- HoltWinters(LakeHuron, beta = FALSE, gamma = FALSE)\n\nts.plot(LakeHuron, xlim = c(1875, 2000), \n        gpars = list(xlab = \"Year\", \n                   ylab = \"Level LakeHuron in feet\", \n                   lwd = 1.5))\n\nlines(SES$fitted[ , 1], col = \"blue\", lwd = 1.2)\nlines(predict(SES, n.ahead = 20), col = \"red\", lwd = 1.2)",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Tema 5. Métodos de Alisado Exponencial</span>"
    ]
  },
  {
    "objectID": "Tema5.html#alisado-exponencial-doble-o-método-de-brown",
    "href": "Tema5.html#alisado-exponencial-doble-o-método-de-brown",
    "title": "6  Tema 5. Métodos de Alisado Exponencial",
    "section": "6.3 Alisado Exponencial Doble o método de Brown",
    "text": "6.3 Alisado Exponencial Doble o método de Brown\nEste método de alisado se aplica cuando la serie en estudio no presenta estacionalidad y la tendencia de la serie se considera lineal (localmente).\nUn ejemplo ilustrativo sería la serie con el siguiente gráfico:\n\nlibrary(ggplot2)\nts.plot(economics$uempmed, lwd = 1.5)\n\n\n\n\n\n\n\n\nEsto es, suponemos que la serie en estudio se expresa de la siguiente forma en cada instante:\n\\[\n\\left\\{\n\\begin{array}{lll}\nx_t=T_t+I_t=\\left( a_t+b_t\\cdot t\\right) +I_t &  & \\text{modelo aditivo} \\\\\nx_t=T_t\\times I_t=\\left( a_t+b_t\\cdot t\\right) \\times I_t &  & \\text{modelo\nmultiplicativo}\n\\end{array}\n\\right.\n\\]\ndonde hemos considerado que la componente de tendencia es lineal en cada instante \\(t\\) (lineal localmente): \\(T_t=a_t+b_t\\cdot t\\), con \\(a_t\\), \\(b_t\\in \\Bbb{R}.\\)\nObsérvese que \\(a_t\\) representa el nivel de la serie en cada instante \\(t\\), mientras que \\(b_t\\) representa la pendiente de la tendencia lineal en dicho instante.\nAl no disponer de componente estacional y suponer tendencia localmente lineal, nuestro objetivo se reduce a estimar el nivel de la serie y la pendiente de la tendencia en cada instante.\nEl alisado exponencial doble consiste en realizar dos veces el proceso de alisado sobre la serie observada. Es decir, primero se aplica el proceso de alisado simple a la serie original y luego se aplica el proceso de alisado simple sobre la serie alisada previamente. Además, se utiliza el mismo parámetro de alisado en las dos etapas.\nDada una serie de observaciones, \\(\\{x_t\\}_{t=1,2,...,n}\\), en el alisado exponencial doble se obtienen de forma recursiva las dos series alisadas siguientes:\n\\[\n\\boxed{\n\\begin{aligned}\nA_t &= \\alpha x_t + (1 - \\alpha) A_{t-1} \\\\\nA_t^{(2)} &= \\alpha A_t + (1 - \\alpha) A_{t-1}^{(2)}\n\\end{aligned}\n}\n\\]\ndonde \\(\\alpha \\in \\left[0,1\\right]\\) es el parámetro de alisado.\nLas dos series obtenidas por alisado exponencial doble sirven para estimar, en cada instante \\(t\\), el nivel de la serie (\\(a_t\\)) y la pendiente de la tendencia (\\(b_t\\)). Se puede comprobar, con un desarrollo bastante laborioso, que estimaciones del nivel y de la pendiente vienen dadas por:\n\\[\n\\boxed{\n\\begin{aligned}\na_t &= 2A_t - A_t^{(2)} \\\\\nb_t &= \\frac{\\alpha}{1 - \\alpha} \\left( A_t - A_t^{(2)} \\right)\n\\end{aligned}\n}\n\\]\nNota: haciendo abuso de la notación, hemos usado \\(a_t\\) y \\(b_t\\) en las series alisadas para denotar a las estimaciones del nivel y de la tendencia.\nPara aplicar la fórmula recursiva anterior necesitamos disponer, por una parte, del valor del parámetro de alisado \\(\\alpha\\), y por otra parte, de los valores iniciales de las series alisadas \\(A_0\\) y \\(A_0^{(2)}\\) (o equivalentemente de los valores inciales de nivel \\(a_0\\) y pendiente \\(b_0\\)). Como valores iniciales se suelen tomar la ordenada en el origen (\\(a_0=cte)\\) y la pendiente (\\(b_0=pendiente\\)) de la recta que ajusta a la serie por mínimos cuadrados usando todos los datos.\nCon respecto al parámetro de alisado \\(\\alpha\\), nuevamente podemos seleccionar aquel que minimice la suma de cuadrados de los errores de estimación.\nNuestro fin último es realizar predicciones de la serie para instantes futuros. Si disponemos de información de la serie hasta el instante \\(T\\), \\(\\{x_t\\}_{t=1,2,...,T}\\), las predicciones de la serie usando el método de alisado exponencial doble vienen dadas por:\n\\[\n\\boxed{\n\\begin{aligned}\n\\widehat{x}_{T+1/T} &= a_T + b_T \\cdot 1 \\\\\n\\widehat{x}_{T+2/T} &= a_T + b_T \\cdot 2 \\\\\n&\\vdots \\\\\n\\widehat{x}_{T+m/T} &= a_T + b_T \\cdot m \\qquad \\forall\\, m = 1, 2, 3, \\ldots\n\\end{aligned}\n}\n\\]\nEs decir, la predicción de la serie en el instante siguiente viene dada por la estimación del nivel en el último instante observado más la estimación de la pendiente en el último instante observado.\nIgual que en el alisado simple, a medida que disponemos de información nueva (nuevas observaciones), se calculan los valores de las series alisadas para los nuevos instantes y por tanto se revisan las predicciones de manera automática.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Tema 5. Métodos de Alisado Exponencial</span>"
    ]
  },
  {
    "objectID": "Tema5.html#método-de-holt-winters-aditivo",
    "href": "Tema5.html#método-de-holt-winters-aditivo",
    "title": "6  Tema 5. Métodos de Alisado Exponencial",
    "section": "6.6 Método de Holt-Winters aditivo",
    "text": "6.6 Método de Holt-Winters aditivo\nEste método de alisado se aplica en los mismos casos que el método anterior, salvo que los componentes de estacionalidad y tendencia se integran de forma aditiva. Por tanto, la serie en estudio se expresa de la siguiente forma en cada instante:\n\\[\nx_t = T_t + S_t + I_t = (a_t + b_t \\cdot t) + S_t + I_t\n\\quad \\text{modelo aditivo}\n\\]\ndonde \\(a_t\\) representa el nivel de la serie en cada instante \\(t\\), \\(b_t\\) representa la pendiente de la tendencia lineal en dicho instante y \\(S_t\\) la componente estacional de la serie, que supondremos de período \\(L\\).\nSiguiendo la idea del método anterior, en cada instante \\(t\\) necesitamos estimar el nivel de la serie (\\(a_t\\)), la pendiente de la tendencia (\\(b_t\\)) y el factor estacional (\\(S_t\\)).\nEn este caso se usarán tres series alisadas y tres parámetros de alisado que denotaremos por \\(\\alpha \\in [0, 1]\\), \\(\\beta \\in [0, 1]\\) y \\(\\gamma \\in [0, 1]\\).\nEn el método de Holt-Winters aditivo, la estimación del nivel en el instante \\(t\\) viene dada por la siguiente serie alisada:\n\\[\n\\boxed{\na_t = \\alpha (x_t - S_{t-L}) + (1 - \\alpha)(a_{t-1} + b_{t-1})\n}\n\\]\nEs decir, se obtiene como una media ponderada de la última observación desestacionalizada y del valor de (nivel + pendiente) en el instante anterior.\nPor otra parte, la estimación de la pendiente en el instante \\(t\\) viene dada por la siguiente serie alisada:\n\\[\n\\boxed{\nb_t = \\beta (a_t - a_{t-1}) + (1 - \\beta)b_{t-1}\n}\n\\]\nEs decir, se obtiene como una media ponderada del último incremento de nivel y de la pendiente en el instante anterior.\nFinalmente, la estimación del factor estacional en el instante \\(t\\) viene dada por la siguiente serie alisada:\n\\[\n\\boxed{\nS_t = \\gamma (x_t - a_t) + (1 - \\gamma) S_{t-L}\n}\n\\]\nPara aplicar la fórmula recursiva anterior necesitamos disponer de los parámetros de alisado \\(\\alpha \\in [0, 1]\\), \\(\\beta \\in [0, 1]\\) y \\(\\gamma \\in [0, 1]\\), así como de los valores iniciales de nivel (\\(a_0\\)), pendiente (\\(b_0\\)) y factores estacionales (\\(S_0\\), \\(S_{-1}\\), …, \\(S_{-L+1}\\)).\nComo valores iniciales para el nivel y la pendiente (\\(a_0\\) y \\(b_0\\)) se suelen tomar la ordenada en el origen (\\(a_0 = \\text{cte}\\)) y la pendiente (\\(b_0 = \\text{pendiente}\\)) de la recta que ajusta a la serie desestacionalizada por mínimos cuadrados usando todos los datos.\nComo valores iniciales de los factores estacionales se suelen tomar los índices de variación estacional (IVE) obtenidos al desestacionalizar la serie (visto en análisis clásico).\nCon respecto a los parámetros de alisado, podemos seleccionar aquellos que minimicen la suma de cuadrados de los errores de estimación.\n\n6.6.1 Predicciones con el método de Holt-Winters aditivo\nLas predicciones con el método de Holt-Winters aditivo se obtienen de la siguiente forma:\nsi disponemos de información de la serie hasta el instante \\(T\\), \\(\\{x_t\\}_{t=1,2,\\ldots,T}\\), las predicciones vienen dadas por:\n\\[\n\\boxed{\n\\begin{aligned}\n\\widehat{x}_{T+1/T} &= (a_T + b_T \\cdot 1) + S_{T+1-L} \\\\\n\\widehat{x}_{T+2/T} &= (a_T + b_T \\cdot 2) + S_{T+2-L} \\\\\n\\vdots \\\\\n\\widehat{x}_{T+m/T} &= (a_T + b_T \\cdot m) + S_{T+m-L}\n\\qquad \\forall m = 1, 2, \\ldots, L\n\\end{aligned}\n}\n\\]\nComo siempre, a medida que disponemos de nuevas observaciones, se calculan los valores de las series alisadas para los nuevos instantes y, por tanto, se revisan las predicciones de manera automática.\nEn el siguiente gráfico se muestra la serie original (negro), la serie ajustada (azul) usando Holt-Winters aditivo y las predicciones (rojo) para futuros instantes.\n\ndata &lt;- log(AirPassengers)\nHolt_Winter_aditivo &lt;- HoltWinters(data, seasonal = \"additive\")\nforecasted_values &lt;- predict(Holt_Winter_aditivo, n.ahead = 24)\nextended_data &lt;- ts(c(data, forecasted_values), start = start(data), frequency = frequency(data))\n\nts.plot(extended_data, col = \"red\")\nlines(log(AirPassengers), lwd = 1.5)\nlines(Holt_Winter_aditivo$fitted[ , 1], col = \"blue\", lwd = 1.2)\nlines(predict(Holt_Winter_aditivo, n.ahead = 24), col = \"red\", lwd = 1.2)",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Tema 5. Métodos de Alisado Exponencial</span>"
    ]
  },
  {
    "objectID": "Tema1.html#conceptos-básicos-y-ejemplos",
    "href": "Tema1.html#conceptos-básicos-y-ejemplos",
    "title": "2  Tema 1. Introducción a los procesos estocásticos",
    "section": "2.1 Conceptos básicos y ejemplos",
    "text": "2.1 Conceptos básicos y ejemplos\nA lo largo de este tema, vamos a fijar un espacio de probabilidad \\((\\Omega,\\mathcal{F},\\mathbb{P})\\) y un subconjunto \\(\\mathbb{T}\\subset [0,\\infty)\\).\n\n\n\n\n\n\nDefinición\n\n\n\nUn proceso estocástico \\((X_t)_{t\\in\\mathbb{T}}\\) es una colección de variables aleatorias reales \\(X_t\\) definidas en el espacio de probabilidad \\((\\Omega,\\mathcal{F},\\mathbb{P})\\).\n\n\nInterpretamos \\(t\\) como el tiempo (medido en cierta unidad).\n\nSi \\(\\mathbb{T}\\) es contable (por ejemplo, \\(\\mathbb{T}=\\{0&lt;1&lt;2&lt;\\ldots\\}\\), diremos que el proceso estocástico \\((X_t)_{t\\in\\mathbb{T}}\\) es de tiempo discreto.\nSi \\(\\mathbb{T}\\) es un intervalo (por ejemplo, \\(\\mathbb{T}=[0,T]\\) o \\(\\mathbb{T}=[0,\\infty)\\), diremos que el proceso estocástico es de tiempo continuo.\n\nPara cada \\(t\\in\\mathbb{T}\\) tenemos una variable aleatoria \\(X_t\\). La variable aleatoria \\(X_t\\) tomará un valor numérico \\(X_t(\\omega)\\) para cada \\(\\omega\\in\\Omega\\). A los posibles valores que toma un proceso estocástico se les llama estados.\n\nSi para cada \\(t\\in \\mathbb{T}\\) la variable aleatoria \\(X_t\\) es de tipo discreto, diremos que el proceso estocástico \\((X_t)_{t\\in\\mathbb{T}}\\) es de estado discreto.\nSi para cada \\(t\\in \\mathbb{T}\\) la variable aleatoria \\(X_t\\) es de tipo continuo, diremos que el proceso estocástico \\((X_t)_{t\\in\\mathbb{T}}\\) es de estado continuo.\n\n\n\n\n\n\nTipos de procesos estocásticos\n\n\n\n\nEn lo que sigue, siempre supondremos que \\(0\\in\\mathbb{T}\\). Esta condición no es realmente restrictiva, ya que podemos desplazar el tiempo por una constante para garantizar que dicha condición se cumpla.\n\n\n\n\n\n\nDefinición\n\n\n\nDado un proceso estocástico \\((X_t)_{t\\in\\mathbb{T}}\\), para cada realización \\(\\omega\\in\\Omega\\), la colección de números reales \\((X_t(\\omega))_{t\\in\\mathbb{T}}\\) se llama trayectoria del proceso.\n\n\n\nPara un proceso estocástico \\((X_{t})_{t=0,1,2,\\ldots}\\) de tiempo discreto, cada trayectoria define una sucesión de números reales \\((x_t)_{t=0,1,2,\\ldots}\\).\n\n\n\nPara un proceso estocástico \\((X_{t})_{t\\in [0,\\infty)}\\) de tiempo continuo, cada trayectoria define una función real \\(t\\mapsto x(t)\\colon [0,\\infty)\\to\\mathbb{R}\\).\n\nCada trayectoria corresponde a una observación particular de la evolución del valor de un proceso estocástico en el tiempo.\n\n\n\n\n\n\nEjemplo\n\n\n\nSupón que inviertes 100 euros en una cuenta bancaria con tipo de interés anual \\(R\\), compuesto anualmente. Es decir, si \\(X_t\\) es la cantidad de dinero en el año \\(t\\), entonces \\[\nX_t=100\\cdot(1+R)^t\\quad\\mbox{ para }t=0,1,2,\\ldots.\n\\] Supongamos también que el valor de \\(R&gt;0\\) es fijado cuando metes el dinero en la cuenta y sigue una distribución \\(\\mathrm{Exp}(1)\\).\nPara cada observación particular \\(R=r\\) de la variable \\(R\\) tendremos una trayectoria del proceso estocástico \\((X_t)_{t=0,1,2,\\ldots}\\). Podemos simular y dibujar cinco trayectorias de este proceso estocástico mediante el siguiente código en R:\n\nset.seed(112) \nnsim &lt;- 5  \nr &lt;- rexp(nsim, 1) \ntiempo &lt;- 0:10\nx &lt;- 100*(1+r[1])^tiempo\n\ncolores &lt;- rainbow(nsim)\n\nplot(tiempo, x, col=colores[1], type = \"l\", lty = 1)\n\nfor(i in 2:nsim){\n  x &lt;- 100*(1+r[i])^tiempo\n  lines(tiempo, x, col=colores[i])\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEjemplo\n\n\n\nUna moneda es lanzada reiteradas veces. En cada lanzamiento, apostamos un euro a cara, de modo que ganamos un euro si sale cara y perdemos un euro si sale cruz. De esta manera, si \\(X_t\\) es la ganancia acumulada en el lanzamiento \\(t\\), tendremos que \\(X_0=0\\) y \\[\nX_t=X_{t-1}+Y_t\\quad\\mbox{ para }t=1,2,3,\\ldots,\n\\] donde las variables \\(Y_1,Y_2,Y_3\\ldots\\) son indendientes y verfican \\(\\mathbb{P}(Y_t=1)=\\frac{1}{2}=\\mathbb{P}(Y_t=-1)\\).\n\n\nEl proceso del ejemplo anterior es un caso particular de un tipo de proceso el cual introducimos a continuación.\n\n\n\n\n\n\nDefinición\n\n\n\nSea una \\(Y_1,Y_2,Y_3,\\ldots\\) una sucesión de variables independientes de modo que \\(\\mathbb{P}(Y_t=1)=p\\) y \\(\\mathbb{P}(Y_t=1)=1-p\\). Al proceso estocástico \\((x_t)_{t=0,1,2,\\ldots}\\) con \\(X_0=0\\) y \\[\nX_t=X_{t-1}+Y_t\\quad\\mbox{ para }t=1,2,3,\\ldots,\n\\] se le llama paseo aleatorio (simple). Cuando \\(p=1/2\\) se dice se llama paseo aleatorio simétrico.\n\n\nPara cada secuencia de lanzamientos observados, tendremos una trayectoria diferente del proceso estocástico \\((X_t)_{t=0,1,2,\\ldots}\\). Podemos simular y dibujar veinte trayectorias de este proceso estocástico mediante el siguiente código en R:\n\nset.seed(145)\nnsim &lt;- 20\nnlanzamientos &lt;- 100\ny &lt;- sample(c(-1,1), size=nlanzamientos, replace=TRUE)\nx &lt;- c(0, cumsum(y))\ntiempo &lt;- 0:nlanzamientos\n\ncolores &lt;- rainbow(nsim)\n\nplot(tiempo, x, col=colores[1], type = \"l\", lty = 1, ylim=c(-20, 20))\n\nfor(i in 2:nsim){\n  y &lt;- sample(c(-1,1), size=nlanzamientos, replace=TRUE)\n  x &lt;- c(0, cumsum(y))\n  lines(tiempo, x, col=colores[i])\n}"
  },
  {
    "objectID": "Tema1.html#funciones-de-distribución-asociadas-a-un-proceso",
    "href": "Tema1.html#funciones-de-distribución-asociadas-a-un-proceso",
    "title": "2  Tema 1. Introducción a los procesos estocásticos",
    "section": "2.2 Funciones de distribución asociadas a un proceso",
    "text": "2.2 Funciones de distribución asociadas a un proceso\nDado un proceso estocástico \\((X_t)_{t\\in\\mathbb{T}}\\), cada variable aleatoria \\(X_t\\) tendrá su propia distribución de probabilidad la cual puede ser discreta o continua. Observar un proceso estocástico en un solo tiempo de forma aislada no es útil para describir su comportamiento como función del tiempo, ya que los valores observados en un tiempo pueden condicionar su comportamiento en tiempos distintos. Por ejemplo, en el caso del camino aleatorio simétrico en el que apostamos un euro a cara, si hemos acumulado muchas ganancias en el pasado, la ganancia acumulada seguirá siendo alta en las siguientes jugadas, ya que partimos de una cantidad alta la cual disminuirá a lo sumo en un euro en cada lanzamiento.\nPor ese motivo, es necesario estudiar la distribución de probabilidad conjunta a lo largo de varios tiempos.\n\n\n\n\n\n\nDefinición\n\n\n\nSupongamos que \\((X_t)_{t\\in\\mathbb{T}}\\) es un proceso estocástico. Dada una sucesión finita de tiempos \\(\\{t_1&lt;t_2&lt;\\ldots&lt;t_n\\}\\subset \\mathbb{T}\\), la función \\(F_{t_1,t_2,\\ldots,t_n}\\colon\\mathbb{R}^n\\to[0,1]\\) definida por \\[\nF_{t_1,t_2,\\ldots,t_n}(x_1,x_2,\\ldots,x_n)=\\mathbb{P}(X_{t_1}\\le x_1, X_{t_2}\\le x_2,\\ldots,X_{t_n}\\le x_n),\n\\] se llama función de distribución (marginal) finito dimensional del proceso \\((X_t)_{t\\in\\mathbb{T}}\\).\n\n\nLa función de distribución finito dimensional describe el comportamiento probabilístico del proceso estocástico observado en los distintos tiempos \\(t_1,t_2,\\ldots,t_n\\). La distribución de probabilidad de un proceso está caracterizada por el conjunto de todas las distribuciones finito dimensionales. En particular, dos procesos estocásticos con las mismas funciones de distribución finito dimensionales tendrán un comportamiento probabilístico similar.\nEn el caso de que \\((X_t)_{t\\in\\mathbb{T}}\\) sea de estado discreto, entonces dicho comportamiento probabilístico puede ser descrito por medio la función puntual de probabilidad finito dimensional \\[\nP_{t_1,t_2,\\ldots,t_n}(x_1,x_2,\\ldots,x_n)=\\mathbb{P}(X_{t_1}=x_1, X_{t_2}=x_2,\\ldots,X_{t_n}= x_n).\n\\] En el caso de que \\((X_t)_{t\\in\\mathbb{T}}\\) sea de estado continuo, consideraremos la función de densidad finito dimensional \\(f_{t_1,t_2,\\ldots,t_n}(x_1,x_2,\\ldots,x_n)\\), la cual verifica \\[\n\\mathbb{P}(a_1&lt;X_{t_1}&lt;b_1,\\ldots,a_n&lt;X_{t_n}&lt;b_n)=\\int_{a_n}^{b_n}\\cdots \\int_{a_1}^{b_1}f_{t_1,t_2,\\ldots,t_n}(x_1,x_2,\\ldots,x_n) {\\mathrm dx_1}\\ldots {\\mathrm  dx_n}\n\\] para todo \\(-\\infty\\le a_i&lt;b_i\\le \\infty\\).\n\n\n\n\n\n\nDefinición\n\n\n\nDado un proceso estocástico \\((X_t)_{t\\in\\mathbb{T}}\\) la función media o función de medias \\(\\mu_X\\colon \\mathbb{T}\\to \\mathbb{R}\\) se define como \\[\\mu_X(t)=\\mathbb{E}(X_t).\\]\n\n\n\nPara un proceso estocástico \\((X_{t})_{t=0,1,2,\\ldots}\\) de tiempo discreto, la función media define una sucesión de números reales \\((\\mu_X(t))_{t=0,1,2,\\ldots}\\).\nPara un proceso estocástico \\((X_{t})_{t\\in [0,\\infty)}\\) de tiempo continuo, la función media define una función real \\(t\\mapsto \\mu_X(t)\\colon [0,\\infty)\\to\\mathbb{R}\\).\n\nLa función de medias da una idea de cómo el proceso estocástico se comporta en promedio a lo largo del tiempo.\n\n\n\n\n\n\nEjemplo\n\n\n\nVolvamos al ejemplo donde una moneda es lanzada reiteras veces y \\((X_t)_{t=0,1,2,\\ldots}\\) son las ganancias acumuladas al apostar un euro a cara en cada lanzamiento (paseo aleatorio simétrico). En este caso, \\(\\mu_X(0)=\\mathbb{E}(X_0)=\\mathbb{E}(0)=0\\) y, si \\(t&gt;0\\), \\[ \\mathbb{E}(X_t)=\\mathbb{E}(Y_1+Y_2+\\ldots+Y_t)=\\mathbb{E}(Y_1)+\\mathbb{E}(Y_2)+\\ldots+\\mathbb{E}(Y_t)=0, \\] donde hemos aplicado que \\(\\mathbb{E}(Y_s)=0\\) para todo \\(s\\). En definitiva, la ganancia acumulada promedio es \\(0\\) para cualquier número de lanzamientos efectuado.\n\n\n\n\n\n\n\n\nDefinición\n\n\n\nDado un proceso estocástico \\((X_t)_{t\\in\\mathbb{T}}\\) la función de covarianzas \\(C_X\\colon \\mathbb{T}\\times\\mathbb{T}\\to \\mathbb{R}\\) se define como \\[ C_X(s,t)={\\mathrm  Cov}(X_s,X_t)=\\mathbb{E}\\Big((X_s-\\mu_X(s))(X_t-\\mu_X(t)\\Big)=\\mathbb{E}(X_s X_t)-\\mu_X(s)\\mu_X(t). \\] La función de varianzas \\(\\sigma_X^2\\colon \\mathbb{T}\\to \\mathbb{R}\\) se define como \\[ \\sigma_X^2(t)={\\mathrm  Var}(X_t)=C_X(t,t), \\] y la función de correlaciones \\(\\rho_X\\colon \\mathbb{T}\\times\\mathbb{T}\\to \\mathbb{R}\\) se define como \\[ \\rho_X(s,t)=\\frac{C_X(s,t)}{\\sigma_X(s)\\sigma_X(t)}. \\]\n\n\n\n\n\n\n\n\nEjemplo\n\n\n\nConsideremos el proceso estocástico \\((X_t)_{t\\in [0,\\infty)}\\) definido como \\[\nX_t=A + B t\\quad\\mbox{ para todo }t,\n\\] donde \\(A\\) y \\(B\\) son variables aleatorias \\(N(1,1)\\) independientes. En este caso tenemos \\[\\begin{align*}\nC_X(s,t)&=\\mathbb{E}(X_s X_t)-\\mu_X(s)\\mu_X(t)\\\\\n&=\\mathbb{E}\\big((A + B t)(A + B s)\\Big)\\\\\n&=\\mathbb{E}\\big(A B + A B (s + t) + A B s t)\\Big)\\\\\n&=\\mathbb{E}(A)\\mathbb{E}(B) + \\mathbb{E}(A)\\mathbb{E}(B) (s + t) + \\mathbb{E}(A) \\mathbb{E}(B) s t\\\\\n&=1 + s + t + st.\n\\end{align*}\\]\n\n\n\n\n\n\n\n\nEjemplo\n\n\n\nVolvamos al ejemplo del paseo aleatorio simétrico \\((X_t)_{t=0,1,2,\\ldots}\\). Fijados dos números naturales \\(n,m\\) con \\(n\\le m\\), tenemos \\[\\begin{align*}\nC_X(n,m)&=\\mathbb{E}\\Big(X_n X_m\\Big)\\\\\n&=\\mathbb{E}\\Big(X_n (X_m-X_n + X_n)\\Big)\\\\\n&=\\mathbb{E}\\Big(X_n(X_m-X_n)\\Big) + \\mathbb{E}\\Big(X_n^2\\Big)\\\\\n&=\\mathbb{E}(X_n) \\mathbb{E}(X_m-X_n) + \\mathbb{E}(X_n^2)\\\\\n&=n=\\min(n,m),\n\\end{align*}\\] donde hemos usado que \\(X_n\\) y \\(X_m-X_n\\) son variables aleatorias independientes. Además, obsérvese que, como \\(X_n=Y_1+Y_2+\\ldots + Y_n\\) y las variables \\(Y_1,Y_2,\\ldots,Y_n\\) son independientes, se tiene que \\[ {\\mathrm  Var}(X_n) = {\\mathrm  Var}(Y_1^2)+{\\mathrm  Var}(Y_2^2)+\\ldots + {\\mathrm  Var}(Y_n^2)=1+1+\\ldots + 1=n, \\] y por tanto \\[ \\mathbb{E}(X_n^2)={\\mathrm  Var}(X_n) +(\\mathbb{E}(X_n))^2=n+0=n. \\]"
  },
  {
    "objectID": "Tema1.html#procesos-estacionarios-y-débilmente-estacionarios",
    "href": "Tema1.html#procesos-estacionarios-y-débilmente-estacionarios",
    "title": "2  Tema 1. Introducción a los procesos estocásticos",
    "section": "2.3 Procesos estacionarios y débilmente estacionarios",
    "text": "2.3 Procesos estacionarios y débilmente estacionarios\nLos procesos estocásticos se pueden dividir entre estacionarios (en sentido estricto), débilmente estacionarios y no estacionarios. Intuitivamente hablando, un proceso estocástico es estacionario (en sentido estricto) si su comportamiento probabilístico o distribución no cambia con el tiempo.\n\n\n\n\n\n\nDefinición\n\n\n\nUn proceso estocástico \\((X_t)_{t\\in\\mathbb{T}}\\) se dice que es estacionario si para toda sucesión finita de tiempos \\(t_1,t_2,\\ldots,t_n\\) y todo \\(s&gt;0\\) se verifica que los vectores aleatorios \\[\n(X_{t_1},X_{t_2},\\ldots,X_{t_n})\\quad\\mbox{ y }\\quad (X_{t_1+s},X_{t_2+s},\\ldots,X_{t_n+s})\n\\] tienen la misma función de distribución, es decir, \\[\nF_{t_1,t_2,\\ldots,t_n}(x_1,x_2,\\ldots,x_n)=F_{t_1+s,t_2+s,\\ldots,t_n+s}(x_1,x_2,\\ldots,x_n)\n\\] para cualesquiera números reales \\(x_1,x_2,\\ldots, x_n\\).\n\n\nEn particular, si un proceso es estacionario, entonces todas las variables aleatorias \\(X_t\\) del proceso tienen la misma distribución, es decir, están idénticamente distribuidas. Esto no implica que los vectores aleatorios que se pueden formar con las variables del proceso en diferentes instantes tengan todos la misma distribución.\nEn la práctica es muy útil saber si un proceso estocástico es estacionario cuando es necesario predecir el comportamiento futuro de dicho proceso. Si sabemos que el proceso es estacionario, entonces observando su comportamiento en el pasado podremos inferir información de su comportamiento en el futuro.\nA continuación introducimos una noción de estacionaridad menos exigente, la cual es también muy útil para predecir comportamientos futuros de procesos estocásticos reales.\n\n\n\n\n\n\nDefinición\n\n\n\nUn proceso estocástico \\((X_t)_{t\\in\\mathbb{T}}\\) se dice que es débilmente estacionario si:\n\n\\(\\mu_X(t)=\\mu_X(0)\\) para todo \\(t\\in\\mathbb{T}\\). Es decir, la función de medias es constante.\n\\(C_X(s,t)=C_X(0,t-s)\\) para todo \\(t,s\\in\\mathbb{T}\\) con \\(s\\le t\\). Es decir, la función de covarianzas depende sólo del salto entre tiempos.\n\n\n\nObsérvese que, en particular, si el proceso es débilmente estacionario tendrá función de varianzas constante.\nDado que la media \\(\\mu_X(t)\\) es determinada por la función de distribución marginal \\(F_t(x)\\), y la covarianza \\(C_X(s,t)\\) es determinada por la función de distribución marginal \\(F_{s,t}(x)\\), todo proceso estacionario será también débilmente estacionario. Sin embargo, es posible que un proceso sea débilmente estacionario pero no estacionario.\n\n\n\n\n\n\nEjemplo\n\n\n\nConsideremos el proceso estocástico \\((X_t)_{t\\in[0,\\infty)}\\) definido por \\[\nX_t=Y\\cos(U+ t),\n\\] donde \\(Y\\) y \\(U\\) son variables aleatorias independientes con \\(Y\\sim N(0,1)\\) y \\(U\\sim U[0,2\\pi]\\). Entonces \\[\n\\mu_X(t)=0,\n\\] y además, para \\(s\\le t\\), \\[\\begin{align*}\nC_X(s,t)&=\\mathbb{E}(X_s X_t)-\\mu_X(s)\\mu_X(t)\\\\\n&=\\mathbb{E}\\big((Y\\cos(U+ s))(Y\\cos(U+ t))\\Big)\\\\\n&=\\mathbb{E}(Y^2)\\mathbb{E}\\Big(\\cos(U+ s)\\cos(U+ t)\\Big)\\\\\n&=\\mathbb{E}\\Big(\\cos(U+ s)\\cos(U+ t)\\Big)\\\\\n&=\\mathbb{E}\\Big(\\tfrac{1}{2}\\cos(2U+ s + t) + \\tfrac{1}{2}\\cos(t - s)\\Big)\\\\\n&=\\mathbb{E}\\Big(\\tfrac{1}{2}\\cos(2U+ s + t)\\Big) + \\tfrac{1}{2}\\cos(t - s)\\\\\n&=\\tfrac{1}{2}\\int_0^{2\\pi} (\\cos(2u+ s + t) \\tfrac{1}{2\\pi})du +  \\tfrac{1}{2}\\cos(t - s)\\\\  \n&=0 +  \\tfrac{1}{2}\\cos(t - s)\\\\\n&=\\tfrac{1}{2}\\cos(t - s).\n\\end{align*}\\] En particular, tenemos que \\(C_X(s,t)=\\tfrac{1}{2}\\cos(t - s)=C_X(0,t-s)\\), de donde deducimos que el proceso estocástico \\((X_t)_{t\\in[0,\\infty)}\\) es débilmente estacionario."
  },
  {
    "objectID": "Tema1.html#procesos-gaussianos",
    "href": "Tema1.html#procesos-gaussianos",
    "title": "2  Tema 1. Introducción a los procesos estocásticos",
    "section": "2.4 Procesos gaussianos",
    "text": "2.4 Procesos gaussianos\nA continuación introducimos una de las familias de procesos estocásticos más importantes: los procesos gaussianos. Este tipo de procesos tienen importantes aplicaciones en Machine Learning.\nRecordemos primero la noción de variable Normal multivariante. Una propiedad importante de las variables normales multivariadas es que su función de densidad (y, por tanto, su distribución) está completamente determinada por el vector de medias y la matriz de covarianzas.\n\n\n\n\n\n\nDefinición\n\n\n\nSe dice que el vector aleatorio \\(\\vec{X}=(X_1,X_2,\\ldots,X_n)\\) sigue una distribución Normal multivariante si su función de densidad viene dada por: \\[\nf_X(\\vec{x}) = \\frac{1}{(2\\pi)^{n/2}\\,\\sqrt{|C_X|}}\n\\exp\\left\\{-\\tfrac{1}{2}(\\vec{x}-\\vec{\\mu}_X)^{T} C_X^{-1} (\\vec{x}-\\vec{\\mu}_X)\\right\\}\n\\quad \\text{para todo } \\vec{x}\\in \\mathbb{R}^n.\n\\] donde \\(\\vec\\mu_X\\) es el vector de medias de \\(\\vec{X}\\) y \\(C_X\\) es la matriz de covarianzas de \\(\\vec{X}\\).\n\n\n\n\n\n\n\n\nPropiedad\n\n\n\nSe puede probar, aunque no es inmediato, que una condición equivalente para que el vector aleatorio \\((X_1,X_2,\\ldots,X_n)\\) siga una distribución Normal multivariante es que, para cualesquiera números reales \\(a_1,a_2,\\ldots,a_n\\), la variable aleatoria real \\[\na_1 X_1 + a_2 X_2 + \\ldots + a_n X_n\n\\] sigue una distribución Normal univariante.\n\n\nOtra importante propiedad de las variables aleatorias normales multivariadas que conviene recordar es que las transformaciones lineales de estas variables también son normales multivariadas. En otras palabras, si \\(\\vec{X}\\) es un vector aleatorio Normal multivariante de tamaño n, \\(A\\) es una matriz constante de tamaño \\(m\\times n\\), y \\(\\vec{b}\\) es un vector constante de tamaño \\(m\\), entonces el vector aleatorio \\(\\vec{Y}=A\\vec{X}+\\vec{b}\\) también es un vector aleatorio Normal multivariante.\n\n\n\n\n\n\nDefinición\n\n\n\nUn proceso estocástico \\((X_t)_{t\\in\\mathbb{T}}\\) se dice que es gaussiano (o Normal) si para toda sucesión de tiempos \\(t_1,t_2,\\ldots, t_n\\in\\mathbb{T}\\) el vector aleatorio \\[(X_{t_1},X_{t_2},\\ldots,X_{t_n})\\] es una variable Normal multivariante.\n\n\nUna importante propiedad de los procesos gaussianos es que las nociones de estacionaridad y estacionaridad débil son equivalentes para este tipo de procesos. En la práctica esto significa que para verificar que un proceso gaussiano es estacionario basta analizar su media y covarianza. Concretamente, tenemos lo siguiente.\n\n\n\n\n\n\nTeorema\n\n\n\nSea \\((X_t)_{t\\in\\mathbb{T}}\\) un proceso estocástico gaussiano. Si \\((X_t)_{t\\in\\mathbb{T}}\\) es débilmente estacionario, entonces es también estacionario."
  },
  {
    "objectID": "Tema1.html#ejemplos-y-simulación",
    "href": "Tema1.html#ejemplos-y-simulación",
    "title": "2  Tema 1. Introducción a los procesos estocásticos",
    "section": "2.5 Ejemplos y simulación",
    "text": "2.5 Ejemplos y simulación\nEn lo que sigue vamos a estudiar y simular en R algunos ejemplos particulares de procesos estocásticos gaussianos, analizando en cada caso si se trata de procesos estacionarios o no estacionarios.\n\n2.5.1 Ruido blanco gaussiano\nUn proceso estocástico \\((X_{t})_{t\\in\\mathbb{T}}\\) se llama ruido blanco gaussiano si las variables aleatorias \\(X_t\\) son independientes y siguen una distribución \\(N(0,\\sigma^2)\\).\nClaramente el ruido blanco gaussiano es un proceso gaussiano. Además, \\(\\mu_X(t)=0\\), \\(C_X(t,s)=0\\) si \\(t\\neq s\\), y \\(C_X(t,t)=\\sigma^2\\). Lo cual en particular implica que el ruido blanco gaussiano es un proceso estacionario.\nPodemos simular en R un trayectoria del ruido blanco gaussiano:\n\nset.seed(11)\nsigma &lt;- 1\ntiempos = seq(from = 0, to = 1, by = 0.001)\nx=rnorm(length(tiempos), 0, sigma)\nplot(tiempos, x, type = \"l\", lty = 1)\n\n\n\n\n\n\n\n\nObtenemos una trayectoria extremadamente irregular. Además, observamos a simple vista un comportamiento estacionario del proceso.\n\n\n2.5.2 Movimiento Browniano\nUn proceso estocástico \\((X_{t})_{t\\in [0,\\infty)}\\), de tiempo continuo, se dice que es un movimiento Browniano o proceso de Wiener si:\n\n\\(X_0=0\\),\nPara todo par de tiempos \\(s\\le t\\), la variable aleatoria \\(X_{t}-X_{s}\\) sigue una distribución \\(N(0,t-s)\\),\nPara cualquier sucesión de tiempos \\(t_1&lt;t_2&lt;\\ldots&lt;t_n\\) se tiene que las variables aleatorias \\[ X_{t_2}-X_{t_1},\\quad X_{t_3}-X_{t_2},\\quad \\ldots,\\quad X_{t_n}-X_{t_{n-1}} \\] son independientes.\nLas trayectorias \\(t\\mapsto X_t(\\omega)\\) son funciones continuas.\n\nEl movimiento Browniano se utiliza en finanzas para modelar la evolución del precio de activos financieros como las acciones o los tipos de cambio. En particular, se aplica a la valoración de opciones financieras mediante el modelo de Black-Scholes, y el análisis de riesgos.\nA continuación vamos a simular una trayectoria del movimiento Browniano. Para ello fijamos un incremento de tiempo \\(\\Delta t&gt;0\\) y un número natural \\(n\\). Deseamos simular una trayectoria en los instantes de tiempo \\(t_0=0\\), \\(t_1=\\Delta t\\), …, \\(t_n=n\\Delta t\\). En vista de la definición de movimiento Browniano, tenemos que los incrementos \\[\n\\Delta X_{t_1}=X_{t_1}-X_{t_0},\\quad \\Delta X_{t_2}=X_{t_2}-X_{t_1},\\quad ...,\\quad \\Delta X_{t_n}=X_{t_n}-X_{t_{n-1}},  \n\\] son variables aleatorias idependientes y siguen todas ellas una distribución \\(N(0,\\Delta t)\\). De este modo, nuestra estrategia será simular los valores de los incrementos mediante la generación de una muestra aleatoria de \\(n\\) variables \\(N(0,\\Delta t)\\) independientes, y reconstruir la trayectoria del proceso a partir de dichos incrementos. Esto podemos lograrlo mediante el siguiente código de R:\n\nset.seed(11)\nn &lt;- 1000\ndt &lt;- 1/n\ntiempo &lt;- seq(from=0, to=1, by=dt)\nincrementos &lt;- rnorm(n, 0, sqrt(dt))\nx &lt;- c(0, cumsum(incrementos))\nplot(tiempo, x, type = \"l\", lty = 1)\n\n\n\n\n\n\n\n\nPara analizar el comportamiento probabilístico, simularemos diez trayectorias del proceso:\n\nset.seed(123)\nnsim &lt;- 10\nn &lt;- 1000\ndt &lt;- 1/n\ntiempos &lt;- seq(from=0, to=1, by=dt)\nincrementos &lt;- rnorm(n, 0, sqrt(dt))\nx &lt;- c(0, cumsum(incrementos))\n\ncolores &lt;- rainbow(nsim)\n\nplot(tiempos, x, ylim=c(-2,2), type = \"l\", lty = 1, col=colores[1])\n\n\nfor(i in 2:nsim){\n  incrementos=rnorm(n, 0, sqrt(dt))\n  x &lt;- c(0, cumsum(incrementos))\n  lines(tiempos, x, col=colores[i])\n}\n\n\n\n\n\n\n\n\nA simple vista observamos un comportamiento no estacionario del proceso. Notamos que a medida que avanza el tiempo, las trayectorias tienden a volverse más dispersas, lo que indica que el comportamiento probabilístico de las trayectorias varía con el tiempo.\nEl movimiento Browniano es un proceso gaussiano. De hecho, la distribución de probabilidad del vector aleatorio \\((X_{t_1},X_{t_2},\\ldots,X_{t_n})\\), para \\(t_1&lt;t_2&lt;\\ldots&lt;t_n\\), es normal multivariada porque se obtiene como una transformación lineal del vector \\((X_{t_1},X_{t_2}-X_{t_1},\\ldots,X_{t_n}-X_{t_{n-1}})\\), el cual es normal multivariado porque sus componentes son independientes y normales. ¿Puedes encontrar dicha transformación lineal?.\nAdemás, \\(\\mu_X(t)=\\mathbb{E}(X_t)=0\\) y, para \\(s\\le t\\), \\[\\begin{align*}\nC_X(s,t)&=\\mathbb{E}\\Big(X_s X_t\\Big)\\\\\n&=\\mathbb{E}\\Big(X_s (X_t-X_s + X_s)\\Big)\\\\\n&=\\mathbb{E}\\Big(X_s(X_t-X_s)\\Big) + \\mathbb{E}\\Big(X_s^2\\Big)\\\\\n&=s=\\min(s,t).\n\\end{align*}\\] En resumen, el movimiento Browniano es un proceso gaussiano con funciones de media y covarianza \\(\\mu_X(t)=0\\), y \\(C_X(s,t)=\\min(s,t)\\), respectivamente. En particular, observamos que este proceso no es estacionario (ni siquiera en el sentido débil), ya que en general no se verifica que \\(C_X(s,t)=C_X(0,t-s)\\). Por ejemplo, \\(C_X(3,4)=\\min(3,4)=3\\); sin embargo, \\(C_X(0,4-3)=\\min(0,1)=0\\).\nA continuación vamos a detallar otra estrategia para simular el movimiente Browniano, la cual se basa en que dicho proceso es gaussiano. Aunque nos vamos a centrar en el caso particular del movimiento Browniano, este procedimiento sirve para simular cualquier proceso gaussiano conocidas sus funciones de media y covarianza. Fijados los tiempos \\(t_1&lt;\\ldots&lt;t_n\\) sabemos que el vector aleatorio \\((X_{t_1},X_{t_2},\\ldots,X_{t_n})\\) sigue una distribución multivariada de media \\(\\mu_X=0\\) y matriz de convarianzas \\(C_X=(c_{i,j})_{n\\times n}\\) donde \\(c_{i,j}:=\\min\\{t_i,t_j\\}\\). De esta manera, podremos simular una trayectoria mediante la obtención de una muestra aleatoria del anterior vector aleatorio. Para ello utilizamos la libreria mvtnorm de R, la cual permite simular variables aleatorias normales multivariadas:\n\nset.seed(23)\nn &lt;- 1000\ndt &lt;- 1/n\ntiempo = seq(from=0, to=1, by=dt)\n\n# Definimos la matriz de covarianzas\nC &lt;- matrix(NA, nrow = n, ncol = n)\nC &lt;- dt*pmin(row(C),col(C))\n\n# Simulamos una normal multivariada \nlibrary(mvtnorm)\nx &lt;- rmvnorm(1, sigma=C)\n\n# Añadimos el valor 0 inicial\nx &lt;- c(0, x)\nplot(tiempo, x, type = \"l\", lty = 1)\n\n\n\n\n\n\n\n\n\n\n2.5.3 Procesos gaussianos estacionarios isotrópicos\nUn tipo particular de proceso gaussiano estacionario son los procesos gaussianos estacionarios isotrópicos. Decimos que un proceso gaussiano estacionario \\((X_t)_{t\\in\\mathbb{T}}\\) es isotrópico si su función de medias es constante, \\(\\mu_X(t)=\\mu\\), y la función de covarianza depende sólo de la distancia \\(|t-s|\\), es decir,\n\\[\nC_X(s,t)=K(|t-s|)\n\\] para cierta función \\(K\\colon [0,\\infty)\\to [0,\\infty)\\) llamada núcleo.\nTomemos por ejemplo \\(\\mu_X(t)=0\\) y el núcleo exponencial cuadrático \\(K_l(x):=\\exp(-x^2/2l^2)\\), donde \\(l\\) es un parámetro de escala. Vamos a simular en R una trayectoria de dicho proceso:\n\nset.seed(112)\nn &lt;- 1000\ndt &lt;- 1/n\ntiempo &lt;- seq(from=0, to=1, by=dt)\n\n\n# Definimos la matriz de covarianzas\nl &lt;- 1\nC &lt;- matrix(NA, nrow = n+1, ncol = n+1)\nC &lt;- dt*abs(row(C)-col(C))\nC &lt;- exp(-C^2/(2*l^2))\n\n# Simulamos una normal multivariada \nlibrary(mvtnorm)\nx &lt;- rmvnorm(1, sigma=C)\nplot(tiempo, x, type = \"l\", lty = 1)\n\n\n\n\n\n\n\n\nPara analizar el comportamiento probabilístico, podemos simular diez trayectorias del proceso:\n\nset.seed(112)\nnsim &lt;- 10\nn &lt;- 1000\ndt &lt;- 1/n\ntiempo &lt;- seq(from=0, to=1, by=dt)\n\n\n# Definimos la matriz de covarianzas\nl &lt;- 1\nC &lt;- matrix(NA, nrow = n+1, ncol = n+1)\nC &lt;- dt*abs(row(C)-col(C))\nC &lt;- exp(-C^2/(2*l^2))\n\n# Simulamos una normal multivariada \nlibrary(mvtnorm)\nx &lt;- rmvnorm(1, sigma=C)\n\ncolores &lt;- rainbow(10)\n\nplot(tiempo, x, type = \"l\", lty = 1, ylim=c(-2.5,2.5), col=colores[1])\n\nfor(i in 2:nsim){\n  x &lt;- rmvnorm(1,sigma=C)\n  lines(tiempo, x, col=colores[i])\n}\n\n\n\n\n\n\n\n\nA diferencia del movimiento Browniano, vemos que las trayectorias presentan un comportamiento estacionario, ya que su distribución es la misma a lo largo del tiempo. Otra diferencia con el movimiento Browniano es que las trayectorias tienen una apariencia suave.\nPodemos cambiar el parámero de escala, tomando \\(l=0.1\\). De este modo obtenemos las trayectorias:\n\n\n\n\n\n\n\n\n\nTomemos ahora el núcleo de Ornstein–Uhlenbeck \\(K_l(x):=\\exp(-|x|/l)\\).\nSimulemos algunas trayectorias en R:\n\nset.seed(114)\nnsim &lt;- 10\nn &lt;- 1000\ndt &lt;- 1/n\ntiempo &lt;- seq(from=0, to=1, by=dt)\n\n\n# Definimos la matriz de covarianzas\nl &lt;- 1\nC &lt;- matrix(NA, nrow = n+1, ncol = n+1)\nC &lt;- dt*abs(row(C)-col(C))\nC &lt;- exp(-C/l)\n\n# Simulamos una normal multivariada \nlibrary(mvtnorm)\nx &lt;- rmvnorm(1, sigma=C)\n\ncolores &lt;- rainbow(10)\n\nplot(tiempo, x, type = \"l\", lty = 1, ylim=c(-2.5,2.5), col=colores[1])\n\nfor(i in 2:nsim){\n  x &lt;- rmvnorm(1,sigma=C)\n  lines(tiempo, x, col=colores[i])\n}\n\n\n\n\n\n\n\n\nVemos que las trayectorias tienen una apariencia más irregular la cual nos recuerda al movimiento Browniano. Sin embargo, en este caso tenemos un proceso estacionario cuyas trayectorias se comportan de manera similar a lo largo del tiempo.\n\n\n2.5.4 Movimiento Browniano fraccional\nOtro proceso gaussiano importante es el movimiento Browniano fraccional, el cual es una generalización del movimiento Browniano clásico. A diferencia de éste, los incrementos del movimiento Browniano fraccional no son independientes.\nDado un número \\(H \\in (0,1)\\), decimos que un proceso estocástico \\((X_t)_{t\\in [0,\\infty)}\\) es un movimiento Browniano fraccional con índice de Hurst \\(H\\) si es un proceso gaussiano, su función de medias es constantemente cero, \\(\\mu_X(t)=0\\), y su función de covarianzas está dada por \\[\nC_X(s,t) = \\frac{1}{2}\\left( t^{2H} + s^{2H} - |t-s|^{2H} \\right).\n\\] El índice de Hurst \\(H\\) describe la irregularidad del movimiento resultante: valores más altos producen trayectorias más suaves. Este proceso fue introducido por Mandelbrot y Van Ness (1968) para modelizar fenómenos como los mercados financieros.\n\nCuando \\(H = \\tfrac{1}{2}\\), el proceso coincide con el movimiento Browniano usual.\nCuando \\(H &gt; \\tfrac{1}{2}\\), los incrementos están positivamente correlados.\nCuando \\(H &lt; \\tfrac{1}{2}\\), los incrementos están negativamente correlados.\n\nVamos a simular en R una trayectoria de dicho proceso para H=0.2:\n\nset.seed(23)\nn &lt;- 1000\ndt &lt;- 1/n\ntiempo = seq(from=0, to=1, by=dt)\n\n# Definimos la matriz de covarianzas para H=0.2\nH &lt;- 0.2\nC &lt;- matrix(NA, nrow = n, ncol = n)\nC &lt;- (1/2)*((dt*row(C))^(2*H) + (dt*col(C))^(2*H) - abs(row(C) - col(C))^(2*H))\n\n\n# Simulamos una normal multivariada \nlibrary(mvtnorm)\nx &lt;- rmvnorm(1, sigma=C)\n\n# Añadimos el valor 0 inicial\nx &lt;- c(0, x)\nplot(tiempo, x, type = \"l\", lty = 1)\n\n\n\n\n\n\n\n\nVemos que la trayectoria obtenida menos suave que en el caso del movimiento Browniano usual. Al igual que el movimiento Browniano usual, no es un proceso estacionario."
  },
  {
    "objectID": "Tema2.html#cadenas-de-markov-de-tiempo-discreto",
    "href": "Tema2.html#cadenas-de-markov-de-tiempo-discreto",
    "title": "3  Tema 2. Cadenas de Markov",
    "section": "3.1 Cadenas de Markov de tiempo discreto",
    "text": "3.1 Cadenas de Markov de tiempo discreto\n\nDefinición 3.1 (Cadena de Markov) Un proceso estocástico \\((X_n)_{n=0,1,2,\\ldots}\\) de tiempo discreto se dice que es una cadena de Markov si se verifica que\n\\[\n\\begin{aligned}\n\\mathbb{P}\\bigl(X_{n+1}=a_{n+1}\\mid X_n=a_n,X_{n-1}=a_{n-1},\\ldots, X_0=a_0\\bigr)\n&= \\mathbb{P}\\bigl(X_{n+1}=a_{n+1}\\mid X_n=a_n\\bigr)\n\\end{aligned}\n\\tag{3.1}\\]\npara todo \\(n\\) y toda sucesión \\(a_0,a_1,\\ldots,a_{n+1}\\) de posibles valores del proceso.\n\nLa condición (Ecuación 3.1) arriba se llama propiedad de Markov. La interpretación es que la probabilidad de cualquier valor futuro del proceso, dado el valor actual, no está influenciada por ningún valor pasado. Se dice que las cadenas de Markov son procesos estocásticos sin memoria.\nAl conjunto \\(\\mathcal{S}\\) de todos los valores posibles de la cadena de Markov se le llama espacio de estados. Como las cadenas de Markov son de tiempo y estado discretos, el espacio de estados \\(\\mathcal{S}\\) es un conjunto finito o infinito numerable.\n\n\n\n\n\n\nEjemplo (PageRank)\n\n\n\nPageRank es un algoritmo creado y desarrollado por la compañía tecnológica estadounidense Google para ordenar las apariciones de las páginas en cada búsqueda, dando preferencia a aquellas páginas que sean más “importantes” o “populares”. Para medir esto, se analiza la cadena de Markov resultante de un individuo o “surfeador de la web” que va pulsando links al azar en un conjunto de páginas de internet. Por ejemplo, supongamos que el surfeador de la web navega haciendo clics al azar en las páginas A,B,C,D donde:\n\nA tiene enlace a B,\nB tiene enlaces a A y C,\nC tiene enlace a A,\nD tienes enlaces a las otras tres páginas.\n\nEste proceso da lugar a una cadena de Markov con espacio de estados \\(\\{A,B,C,D\\}\\), el cuál puede ser descrito mediante el siguiente grafo.\n\n\n\n\n\n\n\n\n\nAdemás, tenemos las siguientes probabilidades de transición entre estados.\n\n\n\n\nA\nB\nC\nD\n\n\n\n\nA\n0%\n100%\n0%\n0%\n\n\nB\n50%\n0%\n50%\n0%\n\n\nC\n100%\n0%\n0%\n0%\n\n\nD\n33.3333%\n33.3333%\n33.3333%\n0%\n\n\n\nClaramente este proceso da lugar a una cadena de Markov, ya que, en cada paso, las probabilidades de visitar una página u otra, sólo depende de en qué página se encuentre el surfeador, sin importar qué páginas haya visitado anteriormente.\nEl algoritmo PageRank trata de determinar la probabilidad con la que una página es visitada a medida que el surfeador hace más y más clics, considerando como más importantes aquellas páginas para las que esta probabilidad sea mayor. Éste es el criterio usado para ordenar las páginas en cada búsqueda en Google. Analizaremos este problema en detalle al final del tema.\n\n\n\n\n\n\n\n\nEjemplo (Paseo aleatorio)\n\n\n\nEl paseo aleatorio simétrico \\((X_n)_{n=0,1,2,\\ldots}\\) es una cadena de Markov con espacio de estados infinito\n\\[\n\\mathcal{S}=\\mathbb{Z}={\\ldots,-3,-2,-1,0,1,2,3,\\ldots}.\n\\]\nEn este caso, para todo \\(i\\in\\mathcal{S}\\)\n\\[\n\\mathbb{P}(X_{n+1}=i+1\\mid X_n=i)=\\mathbb{P}(X_{n+1}=i-1\\mid X_n=i)=\\frac{1}{2},\n\\]\n\\[\n\\mathbb{P}(X_{n+1}=j\\mid X_n=i)=0\\quad\\mbox{ si }j\\neq i\\pm 1.\n\\]\n\n\n\nDefinición 3.2 (Probabilidades de transición) Supongamos que \\((X_n)_{n=0,1,2,\\ldots}\\) es una cadena de Markov con espacio de estados \\(\\mathcal{S}\\). Las probabilidades de transición son la probabilidades \\[\np_{x,y}(n)=\\mathbb{P}(X_n=y\\mid X_{n-1}=x),\n\\] donde \\(x,y\\in\\mathcal{S}\\) y \\(n=1,2,3,\\ldots\\).\n\n\nDefinición 3.3 (Cadena de Markov homogénea) Decimos que la cadena de Markov \\((X_n)_{n=0,1,2,\\ldots}\\) es homogénea si las probabilidades de transición no dependen del tiempo. En tal caso, definimos\n\\[\n\\begin{aligned}\np_{x,y}=&\\mathbb{P}(X_n=y|X_{n-1}=x)\\\\\n=&\\mathbb{P}(X_1=y|X_{0}=x)\n\\end{aligned}\n\\]\ndonde hemos eliminado \\(n\\) de la notación.\n\nEn el resto de este tema vamos a trabajar con cadenas de Markov homogéneas con un número de estados finito. Por lo que a partir de ahora, cada vez que nos refiramos a una cadena estaremos hablando de una cadena de Markov con esas características.\nEn general, usaremos que \\((X_n)_{n=0,1,2,\\ldots}\\) es una cadena con espacio de estados finito que denotaremos por \\(\\mathcal{S}=\\{1,2,3,\\ldots,N\\}\\).\n\nDefinición 3.4 (Matriz de transición) Definimos la matriz de transición de \\((X_n)_{n=0,1,2,\\ldots}\\) como\n\\[\nP=(p_{i,j})_{i,j=1,2,\\ldots,N}= \\left[\n\\begin{array}{cccc}\np_{1,1} & p_{1,2} & \\ldots & p_{1,N}\\\\\np_{2,1} & p_{2,2} & \\ldots & p_{2,N}\\\\\n\\ldots & \\ldots  & \\ldots & \\ldots\\\\\np_{N,1} & p_{N,2} & \\ldots & p_{N,N}\\\\\n\\end{array}\n\\right]\n\\]\n\nObsérvese que las entradas de la fila 1 describen todas las probabilidades posibles condicionadas a empezar en el estado \\(i=1\\). Por tanto, la suma de todas ellas debe ser igual a \\(1\\). Obviamente, lo mismo es cierto para el resto de filas, es decir, \\(p_{i,1}+p_{i,2}+\\ldots+p_{i,N}=1\\) para cada \\(i\\). Por tanto, en una matriz de transición, la suma de todos los elementos de cualquier fila debe de ser 1. Sin embargo, esta condición no tiene por qué verificarse para las columna de una matriz de transición.\n\n\n\n\n\n\nEjemplo (Urnas de Ehrenfest)\n\n\n\nSupongamos que tenemos dos urnas, \\(U_1\\) y \\(U_2\\). En ellas están distribuidas \\(N\\) bolas numeradas. En cada paso, se elige un número al azar entre \\(\\{1,2,\\ldots,N\\}\\). A continuación se observa en qué urna está la bola con el número elegido y se cambia de urna. Denotemos por \\(X_n\\) el número de bolas contenidas en la urna \\(U_1\\) en tiempo \\(n\\). De esta manera, definimos una cadena \\((X_n)_{n=0,1,2,\\ldots}\\) con espacio de estados \\(\\mathcal{S}=\\{0,1,2,\\ldots,N\\}\\) y probabilidades de transición\n\\[\n\\begin{aligned}\n\\mathbb{P}&(X_n=i+1|X_{n-1}=i)=\\frac{N-i}{N},\\\\\n\\mathbb{P}&(X_n=i-1|X_{n-1}=i)=\\frac{i}{N},\\\\\n\\mathbb{P}&(X_n=j|X_{n-1}=i)=0\\quad\\mbox{ si }j\\neq i\\pm 1.\n\\end{aligned}\n\\]\nPor ejemplo, si \\(N=3\\) tenemos espacio de estados \\(\\{0,1,2,3\\}\\) y matriz de transición\n\\[\nP =\\left[\n  \\begin{array}{cccc}\n0 & 1 & 0 & 0\\\\\n1/3 & 0 & 2/3 & 0\\\\\n0 & 2/3  & 0 & 1/3\\\\\n0 & 0 & 1 & 0\\\\\n  \\end{array}\n  \\right].\n\\]\n\n\n\n\n\n\n\n\nEjemplo (Ruina del jugador)\n\n\n\nConsideremos un individuo que juega a la ruleta, que posee una riqueza inicial de \\(X_0\\) euros, y que apuesta 1 euro a rojo en cada jugada con probabilidad de ganar \\(p\\). El jugador seguirá apostando hasta que, o bien alcance una riqueza objetivo \\(M\\), o bien hasta que se arruine. El proceso \\((X_n)_{n=0,1,2,\\ldots}\\) de la riqueza acumulada hasta la jugada \\(n\\) es una cadena de Markov con espacio de estados finito \\(\\mathcal{S}=\\{0,1,\\ldots,M\\}\\).\n\n\n\n\n\n\n\n\n\nEn este caso, el proceso de la fortuna acumulada \\((X_n)_{n=0,1,2,\\ldots}\\) es una cadena con espacio de estados \\(\\{0,1,2,\\ldots,M\\}\\) y matriz de transición\n\\[\nP = \\left[\n  \\begin{array}{ *{8}{c} }\n      1 &  0  &  0  & 0  & \\ldots & 0 & 0 & 0\\\\\n    1-p &  0  &  p  & 0  & \\ldots & 0 & 0 & 0 \\\\\n     0  & 1-p &  0  & p  & \\ldots & 0 & 0 & 0 \\\\\n     \\vdots  &  \\vdots  & \\vdots & \\vdots  & \\vdots & \\vdots & \\vdots & \\vdots \\\\\n     0  &  0  & 0 & 0  & \\ldots & 0 & p & 0 \\\\\n     0  &  0  & 0 & 0  & \\ldots & 1-p & 0 & p \\\\\n     0  &  0  &  0  & 0 &  \\ldots & 0 & 0 & 1 \\\\\n  \\end{array}\n  \\right].\n\\]"
  },
  {
    "objectID": "Tema2.html#matriz-de-transición-de-n-pasos",
    "href": "Tema2.html#matriz-de-transición-de-n-pasos",
    "title": "3  Tema 2. Cadenas de Markov",
    "section": "3.2 Matriz de transición de n pasos",
    "text": "3.2 Matriz de transición de n pasos\nEn esta sección, sea \\((X_n)_{n=0,1,2,\\ldots}\\) una cadena con espacio de estados \\(\\mathcal{S}=\\{1,2,\\ldots,N\\}\\). En general, definimos lo siguiente.\n\nDefinición 3.5 (Probabilidad de transición de n pasos) Dados dos estados \\(i,j\\in\\mathcal{S}\\), definimos la probabilidad de transición de \\(n\\) pasos\n\\[\np_{i,j}^{(n)}=\\mathbb{P}(X_n=j\\mid X_{0}=i).\n\\]\nDefinimos la matriz de transición de \\(n\\) pasos de \\((X_n)_{n=0,1,2,\\ldots}\\) como\n\\[\nP^{(n)}=\\Big(p_{i,j}{(n)}\\Big)_{i,j=1,2,\\ldots,N}= \\left[\n\\begin{array}{cccc}\np_{1,1}^{(n)} & p_{1,2}^{(n)} & \\ldots & p_{1,N}^{(n)}\\\\\np_{2,1}^{(n)} & p_{2,2}^{(n)} & \\ldots & p_{2,N}^{(n)}\\\\\n\\ldots & \\ldots  & \\ldots & \\ldots\\\\\np_{N,1}^{(n)} & p_{N,2}^{(n)} & \\ldots & p_{N,N}^{(n)}\\\\\n\\end{array}\n\\right].\n\\]\n\nPara entender cómo calcular la matriz de transición de n pasos analicemos el siguiente ejemplo. Consideremos la cadena \\((X_n)_{n=0,1,2,\\ldots}\\) dada por el grafo:\n\n\n\n\n\n\n\n\n\nEsta cadena tiene matriz de transición\n\\[\nP= \\left[\n\\begin{array}{cccc}\n1/2 & 1/2 & 0 & 0\\\\\n1/3 & 0 & 2/3 & 0\\\\\n1/2 & 0 & 0 & 1/2\\\\\n0 & 0 & 0 & 1\n\\end{array}\n\\right]\n\\]\nQueremos ver lo que ocurre tras dos pasos del proceso.\nPor ejemplo, veamos la probabilidad de llegar al estado 1 desde el estado 1 en dos pasos\n\\[\np_{1,1}^{(2)}=\\mathbb{P}(111) + \\mathbb{P}(121)=p_{1,1}\\cdot p_{1,1} + p_{1,2}\\cdot p_{2,1}=\\tfrac{1}{2}\\cdot\\tfrac{1}{2} + \\tfrac{1}{2}\\cdot\\tfrac{1}{3}=\\tfrac{5}{12}\n\\]\nIncluyendo todos los posibles caminos, incluso aquellos que no existen en el grafo, podemos poner\n\\[\n\\begin{aligned}\np_{1,1}^{(2)}&=\\mathbb{P}(111) + \\mathbb{P}(121)+\\mathbb{P}(131)+\\mathbb{P}(141)\\\\\n&=p_{1,1}\\cdot p_{1,1} + p_{1,2}\\cdot p_{2,1} + p_{1,3}\\cdot p_{3,1} + p_{1,4}\\cdot p_{4,1}\\\\\n&=\\tfrac{1}{2}\\cdot \\tfrac{1}{2} + \\tfrac{1}{2}\\cdot \\tfrac{1}{3} + 0 + 0=\\tfrac{5}{12}.\n\\end{aligned}\n\\]\nEscrito de esta manera, vemos que \\(p_{1,1}^{(2)}\\) es la primera entrada de la matriz \\(P^2=P\\cdot P\\). Es más, tenemos que \\(P^2=(p^{(2)}_{i,j})_{i,j\\in\\{1,2,3,4\\}}\\).\nEn general, tenemos lo siguiente.\n\nTeorema 3.1 La matriz de transición de \\(n\\) pasos vendrá dada por \\(n\\)-ésima potencia de \\(P\\). Es decir,\n\\[\nP^n=(p_{i,j}^{(n)})_{i,j=1,2,\\ldots,N}.\n\\]\n\nComo consecuencia del teorema anterior, se tiene la relación:\n\\[\n\\pi^{(n)}=\\pi{(0)} \\cdot P^n\n\\]\ndonde:\n\\[\n\\pi^{(0)}=(\\pi^{(0)}_1, ...,\\pi^{(0)}_N)\n\\]\ndenota el vector de probabilidades iniciales de cada estado, es decir, \\(\\pi^{(0)}_j=\\mathbb{P}(X_0=j)\\) y\n\\[\n\\pi^{(n)}=(\\pi^{(n)}_1, ...,\\pi^{(n)}_N)\n\\]\ndenota el vector de probabilidades de cada estado en el instante \\(n\\), es decir, \\(\\pi^{(n)}_j=\\mathbb{P}(X_n=j)\\), para todo \\(j=1,2,...,N\\).\nTeniendo en cuenta el teorema anterior junto al hecho de que \\(P^{m+n}=P^m P^n\\), tenemos lo siguiente.\n\nCorolario 3.1 (Ecuaciones de Chapman-Kolmogorov) \\[\np_{i,j}^{(n+m)}=\\sum_{k=1}^N p_{i,k}^{(n)} p_{k,j}^{(m)}.\n\\]"
  },
  {
    "objectID": "Tema2.html#clasificación-de-los-estados",
    "href": "Tema2.html#clasificación-de-los-estados",
    "title": "3  Tema 2. Cadenas de Markov",
    "section": "3.3 Clasificación de los estados",
    "text": "3.3 Clasificación de los estados\nSea \\((X_n)_{n=0,1,2,\\ldots}\\) una cadena con espacio de estados \\(\\mathcal{S}\\). Dados dos estados \\(x,y\\in\\mathcal{S}\\), definimos \\[ r_{x,y}=\\mathbb{P}(X_n=y\\mbox{ para algún }n\\ge 1\\mid X_0=x). \\] Esto es, \\(r_{x,y}\\) es la probabilidad de que la cadena alcance el estado \\(y\\) (en algún tiempo futuro) si la cadena se inicia en el estado \\(x\\).\n\nDefinición 3.6 Sean \\(x,y\\in\\mathcal{S}\\) con \\(x\\neq y\\).\n\nDecimos que \\(y\\) es accesible desde \\(x\\) si \\(r_{x,y}&gt;0\\). En tal caso escribimos \\(x\\to y\\).\nDecimos que \\(x\\) se comunica con \\(y\\) si son accesibles entre sí (es decir, \\(x\\to y\\), \\(y\\to x\\)). En tal caso escribimos \\(x\\leftrightarrow y\\).\n\nPor convenio, se considera que cualquier estado \\(x\\) es accesible desde sí mismo (\\(x\\to x\\)), y que se comunica consigo mismo (\\(x\\leftrightarrow x\\)), incluyendo el caso de que \\(r_{x,x}=0\\).\n\nCada cadena puede ser representada con un grafo. Podemos ver la accesibilidad simplemente observando si en el grafo existe un camino desde \\(x\\) hasta \\(y\\) respetando la dirección de las flechas. Cuando haya caminos en ambas direcciones, significará que ambos estados se comunican.\nPor ejemplo, consideremos la cadena dada por el grafo en la Figura Figura 3.1. Vemos por ejemplo que \\(1\\to 3\\) ya que podemos ir desde 1 hasta 3, siguiendo la dirección de las flechas, pasando por 4 y 2. Sin embargo, \\(3 \\nrightarrow 1\\), ya que de 3 sólo se puede volver a saltar a sí mismo. Por otro lado, \\(1\\leftrightarrow 2\\) ya que podemos conectar ambos estados por caminos tanto empezando en 1 como empezando en 2.\n\n\n\n\n\nFigura 3.1: Observando las flechas podemos analizar la accesibilidad y la conexión entre estados\n\n\n\n\nEn general, si un estado \\(y\\) es accesible desde un estado \\(x\\), siempre será posible encontrar un camino desde \\(x\\) hasta \\(y\\) de modo que dicho camino no pase por un mismo estado dos veces. Para ello, basta considerar cualquier camino desde \\(x\\) hasta \\(y\\), y si algún estado \\(z\\) aparece dos veces en el camino, eliminamos el tramo del camino desde la primera aparición de dicho estado hasta la última aparición del mismo, de modo que aparezca una sola vez. Dicho camino, al no pasar dos veces por un mismo estado, tendrá como mucho tantos pasos como estados tenga la cadena. En definitiva, tenemos lo siguiente.\n\nProposición 3.1 Supongamos que el espacio de estados \\(\\mathcal{S}\\) tiene \\(N\\) elementos. Entonces,\n\\[\nx\\to y\\quad\\mbox{ si, y sólo si, }\\quad p_{x,y}^{(n)}&gt;0\\mbox{ para algún }n\\le N.\n\\]\n\nLa relación entre estados definida por la propiedad de estar comunicados es una relación de equivalencia. Es decir, tenemos lo siguiente.\n\nProposición 3.2 Sean \\(x,y\\in\\mathcal{S}\\) dos estados. Se verifican las siguiente propiedades:\n\n\\(x\\leftrightarrow x\\).\nSi \\(x\\leftrightarrow y\\) entonces \\(y\\leftrightarrow x\\).\nSi \\(x\\leftrightarrow y\\) e \\(y \\leftrightarrow z\\), entonces \\(x \\leftrightarrow z\\).\n\n\nEn una cadena, siempre podemos agrupar los estados en clases de modo que dos estados en una misma clase estén comunicados y elementos de clases distintas no estén comunicados. Más específicamente, tenemos lo siguiente.\n\nProposición 3.3 Dado el espacio de estados \\(\\mathcal{S}\\), siempre es posible dividirlo en clases disjuntas \\[\n\\mathcal{S}=C_1\\cup C_2\\cup\\ldots\\cup C_n\n\\tag{3.2}\\]\ndonde para todo \\(x,y\\in\\mathcal{S}\\) se verifica \\[x\\leftrightarrow y\\quad\\mbox{ si }x,y\\in C_i,\\] \\[x\\nleftrightarrow y\\quad\\mbox{ si }x\\in C_i\\mbox{, }y\\in C_j,\\: i\\neq j.\\]\n\nLas clases en (Ecuación 3.2) se llaman clases irreducibles. La proposición anterior nos dice que cada cadena admite siempre una descomposición en clases irreducibles. Una cadena se dice que es irreducible si sólo posee una clase irreducible, es decir, todos sus estados se comunican entre sí.\nLas clases irreducibles pueden ser fácilmente identificadas mirando el grafo de la cadena. Observando de nuevo el grafo de la cadena en la Figura Figura 3.1, vemos que \\(1\\to 5\\) pero \\(5 \\nrightarrow 1\\), por lo que están en clases diferentes. Por otro lado, \\(1\\to 4\\), \\(4\\to 2\\), \\(2\\to 1\\), por lo que están en la misma clase. Finalmente, \\(3\\) no está comunicado con nadie, luego forma él solo una clase. En la Figura Figura 3.2, podemos ver las tres clases irreducibles de la cadena que hemos identificado.\n\n\n\n\n\nFigura 3.2: Tenemos en distinto color las tres clases irreducibles\n\n\n\n\nA continuación vamos a introducir un criterio para clasificar los distintos estados de una cadena.\n\nDefinición 3.7 Sea \\(x\\in\\mathcal{S}\\).\n\nDecimos que \\(x\\) es recurrente si \\(r_{x,x}=1\\).\nDecimos que \\(x\\) es transitorio si \\(r_{x,x}&lt;1\\).\nDecimos que \\(x\\) es absorbente si \\(p_{x,x}=1\\).\n\n\nSi \\(x\\) es recurrente, tendremos que una vez que la cadena alcanza el estado \\(x\\) entonces tendremos total certeza de que volverá a alcanzar el estado \\(x\\) en el futuro.\nSi \\(x\\) es transitorio, tendremos que una vez que la cadena alcanza el estado \\(x\\) entonces no tendremos certeza de que la cadena vuelva a alcanzar el estado \\(x\\) de nuevo.\nSi \\(x\\) es absorbente, tendremos que una vez que la cadena alcanza el estado \\(x\\) con toda certeza permanezca en el estado \\(x\\) en el futuro. En particular, todo estado absorbente es también recurrente.\nMirando de nuevo al grafo de la Figura Figura 3.2 arriba, vemos que el estado 3 es absorbente (y por tanto recurrente), ya que si comenzamos en él sólo llegaremos a él mismo. Los estados 5 y 6 son recurrentes. Por ejemplo, vemos que si empezamos en 5 no podremos llegar a ningún otro estado excepto 6 y él mismo. Además, la única manera para que, empezando en 5, no se vuelva a visitar 5 es que la cadena se cambie al estado 6 y permanezca en ese estado en lo sucesivo. Pero la probabilidad de que eso ocurra es \\(\\frac{1}{2}\\cdot \\frac{1}{2}\\cdot \\frac{1}{2}\\cdot \\ldots=0\\). Así que, con probabilidad 1 se volverá en algún momento a 5, y por lo tanto es recurrente. El mismo argumento es aplicable a 6. Finalmente, los estados 1, 2 y 4 son transitorios ya que desde esos estados se accede a zonas de las que no se puede volver.\nA continuación, enunciamos, sin demostración, algunos resultados sobre el comportamiento de los estados recurrentes.\n\nTeorema 3.2 Si \\(x\\to y\\) y \\(x\\) es recurrente, entonces \\(y\\) también es recurrente y, además, \\(r_{x,y}=1=r_{y,x}\\).\n\nEl teorema de arriba nos dice que si \\(y\\) es accesible desde un estado recurrente, entonces se realizarán viajes de ida y vuelta entre \\(x\\) e \\(y\\), una y otra vez.\n\nTeorema 3.3 Toda cadena de Markov homogénea posee al menos un estado recurrente.\n\nComo consecuencia de los dos teoremas anteriores tenemos.\n\nCorolario 3.2 Todos los estados de una cadena de Markov irreducible son recurrentes. Además, \\(r_{x,y}=1\\) para cualesquiera dos estados \\(x,y\\) de la cadena.\n\nEn el caso de cadenas no irreducibles tendremos los siguiente.\n\nCorolario 3.3 Supongamos que una cadena de Markov tiene descomposición en clases irreducibles\n\\[ C_1\\cup C_2\\cup \\ldots \\cup C_n. \\]\nEntonces si existe \\(x\\in C_i\\) el cual es recurrente (resp. transitorio), entonces todos los \\(y\\in C_i\\) son también recurrentes (resp. transitorios).\n\nObsérvese que, en la Figura Figura 3.2 arriba, los estados 1, 2 y 4 están todos en una misma clase y son transitorios; los estados 5 y 6 están los dos en una misma clase y son recurrentes; finalmente, el estado 3 es absorbente y formará él solo una clase irreducible.\nEn las cadenas de Markov frecuentemente se observan patrones cíclicos, donde una sucesión de estados se recorre en un camino en forma de bucle empezando y acabando en un mismo estado. Esto da lugar al siguiente concepto.\n\nDefinición 3.8 (Periodo) Un estado \\(x\\in\\mathcal{S}\\) se dice que tiene periodo \\(d\\) si \\(p^{(n)}_{x,x}=0\\) para todo \\(n\\) que no sea divisible por \\(d\\), y además \\(d\\) es el mayor número con esta propiedad. En el caso de que \\(p^{(n)}_{x,x}=0\\) para todo \\(n\\) (es decir, si \\(r_{x,x}=0\\)), entonces diremos que el periodo de \\(x\\) es infinito. Un estado \\(x\\) con periodo 1 se dice que es aperiódico.\n\nEn otras palabras, un estado \\(x\\) tiene periodo \\(d\\) si la cadena puede volver al estado \\(x\\) sólo en un número de pasos que sea múltiplo de \\(d\\). En el caso de que la cadena no vuelva nunca más a \\(x\\), el periodo es infinito.\nUna importante propiedad es la siguiente.\n\nSi \\(x\\leftrightarrow y\\), entonces \\(x\\) e \\(y\\) tienen el mismo periodo.\n\nPor definición en una cadena irreducible todos los estados se comunican, por lo que tenemos lo siguiente.\n\nCorolario 3.4 En una cadena irreducible todos los estados tienen el mismo periodo.\n\nDado que todos los estados de una cadena irreducible tienen el mismo periodo, tiene sentido introducir lo siguiente.\n\nDefinición 3.9 Se dice que una cadena irreducible tiene periodo \\(d\\) si uno de sus estados (y por tanto todos) tienen periodo \\(d\\). Se dice que una cadena es aperiódica si uno de sus estados (y por tanto todos) es aperiódico.\n\nEn el caso de cadenas no irreducibles tendremos los siguiente.\n\nCorolario 3.5 Supongamos que una cadena de Markov tiene descomposición en clases irreducibles \\[ C_1\\cup C_2\\cup \\ldots \\cup C_n. \\] Todos los estados pertenecientes a una misma clase \\(C_i\\) tienen el mismo periodo.\n\nVeremos más adelante que conocer si una cadena irreducible es aperíodica es importante en el estudio límite de las cadenas de Markov. Para determinar si un estado es aperiódico aplicaremos un simple método que explicaremos a continuación.\nRecuerda que dos números n y m son coprimos si su máximo común divisor es 1. Supongamos que podemos encontrar dos números coprimos \\(n\\) y \\(m\\) tal que \\(p_{x,x}^{(n)}&gt;0\\) y \\(p_{x,x}^{(m)}&gt;0\\). En este caso, por definición de periodo, \\(d\\) debe dividir a \\(n\\) y \\(m\\). Como \\(n\\) y \\(m\\) son coprimos, necesariamente tendremos que \\(d=1\\). Por tanto, para determinar si un estado \\(x\\) es aperiódico, trataremos de buscar en el grafo dos caminos de \\(x\\) en sí mismo de modo que los números de pasos dados en sendos caminos sean coprimos.\nPara ilustrar este método, volvamos al ejemplo en la Figura Figura 3.2 arriba. Claramente el estado 3 es aperiódico por ser absorbente. Por otro lado, partiendo del estado 1, podremos volver a dicho estado en tres pasos siguiendo el camino \\(1\\to 4 \\to 2 \\to 1\\). Pero, partiendo de 1, también podemos volver a \\(1\\) en cuatro pasos a través del camino \\(1\\to 4 \\to 4 \\to 2 \\to 1\\) en el que pasamos dos veces por 4. Como 3 y 4 son coprimos, necesariamente tendremos que el estado 1 es aperiódico. Además, los estados 2 y 4 también serán aperiódicos por estar en la misma clase irreducible que 1. Un argumento similar muestra que los estados 5 y 6, los cuales están en la misma clase irreducible, son aperiódicos también."
  },
  {
    "objectID": "Tema2.html#número-de-visitas",
    "href": "Tema2.html#número-de-visitas",
    "title": "3  Tema 2. Cadenas de Markov",
    "section": "3.4 Número de visitas",
    "text": "3.4 Número de visitas\nEn esta sección vamos a estudiar el número medio de veces que una cadena de Markov alcanza un estado determinado a lo largo del tiempo. En lo que sigue consideramos una cadena \\((X_n)_{n=0,1,2,\\ldots}\\) con espacio de estados \\(\\mathcal{S}\\). Dado \\(x\\in\\mathcal{S}\\), la probabilidad de que la cadena vuelva a \\(x\\) habiendo empezando en \\(x\\) es \\(r_{x,x}\\). Por tanto, si empezamos en \\(x\\), la probabilidad de no volver nunca más a \\(x\\) es \\(1-r_{x,x}\\). Teniendo en cuenta ambas cosas, tenemos que \\[\n\\mathbb{P}(\\mbox{``visitar $x$ exactamente $k$ veces''}|X_0=x)=r_{x,x}^k(1-r_{x,x}),\n\\tag{3.3}\\] donde no estamos contando la visita a \\(x\\) en tiempo \\(0\\).\n\n\n\n\n\n\nComentario\n\n\n\nRecordemos que una variable aleatoria discreta \\(Y\\) sigue una distribución geométrica de parámetro \\(p\\in [0,1]\\) si \\[ \\mathbb{P}(Y=k)=(1-p)^{k}p\\quad\\mbox{ para }k=0,1,2,3\\ldots \\]\nEn ese caso, \\[ \\mathbb{E}(Y)=\\frac{1-p}{p}. \\] Obsérvese que la anterior esperanza es infinita si \\(p=0\\). Para los demás valores de \\(p\\) tendremos valores finitos.\n\n\nA partir de (Ecuación 3.3), vemos que el número de visitas a \\(x\\) partiendo de \\(x\\) sigue una distribución Geométrica de parámetro \\(p=1-r_{x,x}\\). En particular, el número esperado de visitas a \\(x\\) si salimos de \\(x\\) es \\[ \\mathbb{E}(\\mbox{``número de visitas a $x$''}\\mid X_0=x)=\\frac{r_{x,x}}{1-r_{x,x}}. \\] Además, la expresión arriba es finita si, y sólo si, \\(r_{x,x}&lt;1\\), en cuyo caso \\(x\\) es transitorio. En caso contrario, tendremos un estado recurrente y el número esperado de visitas será infinito.\nConsideremos ahora un estado \\(y\\) distinto de \\(x\\), de modo que \\(y\\) es accesible desde \\(x\\). Queremos calcular ahora el número medio de visitas a \\(y\\) empezando en \\(x\\). Si partimos de \\(x\\), tenemos dos posibilidades, o bien la cadena alcanza el estado \\(y\\) produciendose al menos una visita, lo cual ocurre con probabilidad \\(r_{x,y}\\); o bien no lo visita nunca, lo cual ocurre con probabilidad \\(1-r_{x,y}\\). De esta manera, el número esperado de visitas a \\(y\\) si salimos de \\(x\\) es \\[\\begin{align*}\n\\mathbb{E}(\\mbox{``número de visitas a $y$''}|X_0=x)&=r_{x,y}\\cdot\\Big(1+ \\mathbb{E}(\\mbox{``número de visitas a $y$ con $n&gt;1$''}|X_1=y)\\Big) + (1-r_{x,y})\\cdot 0\\\\\n&=r_{x,y}\\left(1+ \\frac{r_{y,y}}{1-r_{y,y}}\\right)\\\\\n&=\\frac{r_{x,y}}{1-r_{y,y}}.\n\\end{align*}\\] De nuevo podemos observar que la esperanza anterior es finita si, y sólo si, \\(r_{y,y}&lt;1\\), en cuyo caso \\(y\\) es transitorio.\nResumimos los resultados obtenidos en el siguiente enunciado."
  },
  {
    "objectID": "Tema2.html#número-de-visitas-1",
    "href": "Tema2.html#número-de-visitas-1",
    "title": "3  Tema 2. Cadenas de Markov",
    "section": "3.5 Número de visitas",
    "text": "3.5 Número de visitas\nSupongamos que \\(x,y\\) son dos estados (posiblemente iguales) de modo que \\(x\\to y\\). Entonces,\n\\[\n\\mathbb{E}(\\mbox{``número de visitas a $y$''}\\mid X_0=x)=\\frac{r_{x,y}}{1-r_{y,y}}.\n\\]\nAdemás, la esperanza anterior es finita si y sólo si \\(y\\) es transitorio."
  },
  {
    "objectID": "Tema2.html#probabilidades-de-absorción-y-tiempos-medios-de-llegada",
    "href": "Tema2.html#probabilidades-de-absorción-y-tiempos-medios-de-llegada",
    "title": "3  Tema 2. Cadenas de Markov",
    "section": "3.6 Probabilidades de absorción y tiempos medios de llegada",
    "text": "3.6 Probabilidades de absorción y tiempos medios de llegada\nCuando se estudian las cadenas de Markov, es habitual preguntarse por la probabilidad de que la cadena alcance cierto estado absorbente y también por el tiempo medio en el que se alcanza dicho estado. Por ejemplo, en el caso de la ruina del jugador, podríamos plantearnos cómo de probable es alcanzar las ganancias que el jugador ha fijado antes de retirarse, cuál es la probabilidad de arruinarse, o cuánto tiempo tardarán en producirse dichos sucesos. A continuación, introduciremos los conceptos de probabilidad de absorción y tiempo medio de llegada, y veremos cómo se calculan.\n\n3.6.1 Probabilidades de absorción\nSupongamos que tenemos una cadena con todos sus estados transitorios o absorbentes. Por ejemplo, supongamos que tenemos la cadena dada el siguiente grafo:\n\n\n\n\n\n\n\n\n\nEsta cadena tiene matriz de transición\n\\[\nP= \\left[\n\\begin{array}{cccc}\n1 & 0 & 0 & 0\\\\\n1/3 & 0 & 2/3 & 0\\\\\n0 & 1/2 & 0 & 1/2\\\\\n0 & 0 & 0 & 1\n\\end{array}\n\\right].\n\\]\nPor otro lado, en dicha cadena encontramos tres clases irreducibles: En primer lugar una clase \\(C_1\\) formada por sólo el estado absorbente 1, una clase \\(C_2\\) con los estados transitorios 2 y 3, y una clase \\(C_3\\) con sólo el estado absorbente 4.\nNos planteamos calcular las probabilidades de que cualquier estado sea absorbido por el estado absorbente 1. En concreto, dependiendo de que la cadena de Markov se encuentre en 1, 2, 3, o 4, las probabilidades de absorción en 1 vendrán dadas por \\(r_{1,1}\\), \\(r_{2,1}\\), \\(r_{3,1}\\), o \\(r_{4,1}\\), respectivamente.\nClaramente, \\(r_{1,1}=1\\) y \\(r_{4,1}=0\\). Para encontrar \\(r_{2,1}\\) procedemos como sigue. Puesto que desde el estado 2 se accede, en un solo paso, al estado 1 o al estado 3, tendremos\n\\[r_{2,1}=p_{2,1}r_{1,1} + p_{2,3}r_{3,1}=\\frac{1}{3}r_{1,1}+\\frac{2}{3}r_{3,1}.\\]\nPor otro lado, para hallar \\(r_{3,1}\\), usamos que desde el estado 3 se accede, en un solo paso, al estado 4 o al estado 2. De este modo\n\\[r_{3,1}=p_{3,4}r_{4,1} + p_{3,2}r_{2,1}=\\frac{1}{2}r_{4,1}+\\frac{1}{2}r_{2,1}.\\]\nPoniendo todo junto, tenemos el siguente sistema de ecuaciones\n\\[\n\\begin{cases}\nr_{1,1}&=1,\\\\\nr_{2,1}&=\\frac{1}{3}r_{1,1}+\\frac{2}{3}r_{3,1},\\\\\nr_{3,1}&=\\frac{1}{2}r_{4,1}+\\frac{1}{2}r_{2,1},\\\\\nr_{4,1}&=0.\n\\end{cases}\n\\]\nResolviendo el sistema anterior obtenemos\n\\[r_{1,1}=1,\\quad r_{2,1}=\\frac{1}{2},\\quad r_{3,1}=\\frac{1}{4},\\quad r_{4,1}=0.\\]\nCon una argumentación similar, es posible encontrar las probabilidades \\(r_{1,4}\\), \\(r_{2,4}\\), \\(r_{3,4}\\), o \\(r_{4,4}\\) de ser absorbido en el estado 4 si la cadena se encuentra en 1, 2, 3, o 4, respectivamente. ¿Puedes hallar dichas probabilidades?\nCon una argumentación similar, es posible encontrar las probabilidades \\(r_{1,4}\\), \\(r_{2,4}\\), \\(r_{3,4}\\), o \\(r_{4,4}\\) de ser absorbido en el estado 4 si la cadena se encuentra en 1, 2, 3, o 4, respectivamente. ¿Puedes hallar dichas probabilidades?\nEn general, si \\((X_n)_{n=0,1,2,\\ldots}\\) es una cadena con todos sus estados absorbentes o transitorios, entonces las probabilidades de absorción de un estado absorbente \\(a\\in\\mathcal{S}\\) se pueden calcular usando que:\n\n\\(r_{a,a}=1\\),\n\\(r_{x,a}=0\\) para cualquier otro estado absorbente \\(x\\in\\mathcal{S}\\),\npara cualquier estado transitorio \\(x\\in\\mathcal{S}\\),\n\n\\[\n    r_{x,a}=\\sum_{y\\in \\mathcal{S}} p_{x,y} r_{y,a}.\n\\]\n\n\n3.6.2 Tiempos medios de llegada\nSupongamos que tenemos ahora una cadena con un solo estado absorbente y todos los demás transitorios. Por ejemplo, consideremos la cadena dada por el grafo\n\n\n\n\n\n\n\n\n\nDefinimos \\(\\tau_{1,3}\\) como el número de pasos promedio necesarios para alcanzar estado absorbente 3 partiendo de 1, es decir,\n\\[\n\\tau_{1,3}=\\mathbb{E}[\\mbox{``Número de pasos hasta la primera visita a $3$''}|X_0=1].\n\\]\nDel mismo modo, podemos definir \\(\\tau_{2,3}\\) y \\(\\tau_{3,3}\\).\nObviamente \\(\\tau_{3,3}=0\\). Para calcular \\(\\tau_{1,3}\\), tenemos que tener en cuenta que, si la cadena se encuentra en el estado \\(1\\), en el primer paso dado o bien vuelve al estado 1, o bien va al estado 2. De esa manera,\n\\[\n\\tau_{1,3}=1+p_{1,1}\\tau_{1,3} +p_{1,2}\\tau_{2,3}=1+\\frac{1}{2}\\tau_{1,3} +\\frac{1}{2}\\tau_{2,3}.\n\\]\nSi estamos en el estado 2, daremos el primer paso o bien a 1, o bien a 3. Luego,\n\\[\n\\tau_{2,3}=1+p_{2,1}\\tau_{1,3} +p_{2,3}\\tau_{3,3}=1+\\frac{1}{3}\\tau_{1,3} +\\frac{2}{3}\\tau_{3,3}.\n\\]\nPoniendo todo junto, obtenemos el siguiente sistema de ecuaciones\n\\[\n\\begin{cases}\n\\tau_{1,3}&=1+\\frac{1}{2}\\tau_{1,3} +\\frac{1}{2}\\tau_{2,3},\\\\\n\\tau_{2,3}&=1+\\frac{1}{3}\\tau_{1,3} +\\frac{2}{3}\\tau_{3,3},\\\\\n\\tau_{3,3}&=0.\n\\end{cases}\n\\]\nResolviendo el sistema anterior, obtenemos\n\\[\n\\tau_{1,3}=\\frac{9}{2},\\quad\n\\tau_{2,3}=\\frac{5}{2},\\quad\n\\tau_{3,3}=0.\n\\]\nEn general, si \\((X_n)_{n=0,1,2,\\ldots}\\) una cadena con un solo estado absorbente \\(a\\in\\mathcal{S}\\) y todos los demás estados transitorios, entonces los tiempos medios de llegada a \\(a\\in\\mathcal{S}\\) se pueden calcular usando que:\n\n\\(\\tau_{a,a}=0\\),\npara cualquier estado \\(x\\in\\mathcal{S}\\) distinto de \\(a\\),\n\n\\[\n\\tau_{x,a}=1+\\sum_{y\\in \\mathcal{S}} p_{x,y} \\tau_{y,a}.\n\\]"
  },
  {
    "objectID": "Tema2.html#comportamiento-asintótico",
    "href": "Tema2.html#comportamiento-asintótico",
    "title": "3  Tema 2. Cadenas de Markov",
    "section": "3.7 Comportamiento asintótico",
    "text": "3.7 Comportamiento asintótico\nComo hemos visto, en una cadena irreducible, todos los estados son recurrentes. Tenemos que es posible pasar de cualquier estado a cualquier otro. De hecho la cadena pasará infinitas veces por todos los estado con probabilidad 1. Nos preguntamos sobre cuál es la probabilidad de que a largo plazo la cadena se encuentre en un estado particular. En otras palabras, queremos saber con qué frecuencia la cadena visitará dicho estado a medida que avanzamos en el tiempo.\nEn lo que sigue, consideramos una cadena \\((X_n)_{n=0,1,2,\\ldots}\\) irreducible con espacio de estados \\(\\mathcal{S}=\\{1,2,\\ldots,N\\}\\).\nPara cada \\(n=0,1,2,\\ldots\\) y \\(j\\in \\mathcal{S}\\) consideramos la probabilidad de que la cadena se encuentre en el estado \\(j\\) en \\(n\\) pasos, es decir,\n\\[\n\\pi^{(n)}_j=\\mathbb{P}(X_n=j).\n\\]\nDe hecho podemos considerar el vector\n\\[\\pi^{(n)}=(\\pi^{(n)}_1, \\pi^{(n)}_2,\\ldots, \\pi^{(n)}_N).\\]\nAl considerar la probabilidad de \\(n\\) pasos para todos los posibles estados, el vector \\(\\pi^{(n)}\\) verificará además que sus componentes suman \\(1\\), es decir, \\(\\sum_{j=1}^N \\pi^{(n)}_j=1\\).\nDado un estado \\(j\\in\\mathcal{S}\\), teniendo en cuenta la probabilidad de empezar en cada uno de los estados, tendremos que\n\\[\n\\begin{aligned}\n\\pi^{(n)}_j&=\\sum_{i=1}^N \\mathbb{P}(X_0=i)\\cdot \\mathbb{P}(X_n=j|X_0=i)\\\\\n&=\\sum_{i=1}^N \\pi^{(0)}_i\\cdot p^{(n)}_{i,j}.\n\\end{aligned}\n\\]\nLo cual conduce a la siguiente ecuación matricial\n\\[\n\\begin{aligned}\n\\pi^{(n)}=\\pi^{(0)} \\cdot P^n.\n\\end{aligned}\n\\tag{3.4}\\]\nSupongamos que existe el límite \\(\\lim_{n\\to\\infty}\\pi^{(n)}=\\pi\\). El vector \\(\\pi=(\\pi_1,\\pi_2,\\ldots,\\pi_N)\\) se llama distribución límite de la cadena de Markov. Puesto que \\(\\sum_{j=1}^N \\pi^{(n)}_j=1\\), la distribución límite necesariamente verificará\n\\[\n\\sum_{j=1}^N \\pi_j=1.\n\\]\nPor otro lado, usando (Ecuación 3.4), tenemos\n\\[\n\\begin{aligned}\n\\pi&=\\lim_{n\\to\\infty}\\pi^{(n+1)}\\\\\n&=\\lim_{n\\to\\infty}( \\pi^{(0)} \\cdot P^{n+1})\\\\\n&=(\\lim_{n\\to\\infty} \\pi^{(0)} \\cdot P^{n})\\cdot P \\\\\n&=(\\lim_{n\\to\\infty}\\pi^{(n)}) \\cdot P\\\\\n&=\\pi\\cdot P.\n\\end{aligned}\n\\tag{3.5}\\]\nLa distribución límite \\(\\pi\\) cumple la ecuación matricial\n\\[\n\\begin{aligned}\n\\pi=\\pi\\cdot P.\n\\end{aligned}\n\\tag{3.6}\\]\nPodemos interpretar esta ecuación de manera intuitiva de la siguiente forma. Supongamos que en un instante de tiempo \\(n\\) la variable aleatoria \\(X_n\\) está distribuida según \\(\\pi\\). Al dar un paso en la cadena, la distribución de \\(X_{n+1}\\) será \\(\\pi P\\). Ahora bien, si se cumple que \\(\\pi=\\pi P\\), entonces \\(X_{n+1}\\) sigue teniendo la distribución \\(\\pi\\). Es decir, tras la transición la distribución no cambia. Esto significa que la cadena de Markov ha alcanzado una distribución estable en el tiempo. A una distribución \\(\\pi\\) verificando (Ecuación 3.6) se llama distribución estacionaria de la cadena de Markov.\nHemos argumentado arriba que la distribución límite, si existe, debe cumplir las ecuaciones (Ecuación 3.5) y (Ecuación 3.6). Por otra parte, es posible demostrar que si una cadena irreducible es aperiódica entonces la distribución límite existe. Por tanto, tenemos lo siguiente.\n\nTeorema 3.4 Supongamos que \\((X_n)_{n=0,1,2,\\ldots}\\) es una cadena irreducible aperiódica. Entonces, la distribución límite existe y está determinada por las ecuaciones\n\\[\n\\begin{cases}\n\\pi=\\pi P,\\\\\n\\sum_{j=1}^N \\pi_j=1.\n\\end{cases}\n\\]\n\nDe esta manera, para encontrar la distribución límite de una cadena, bastará con comprobar que la cadena es irreducible y aperiódica, lo cual garantiza la existencia de una distribución límite, y luego resolver las ecuaciones anteriores para determinarla.\n\n\n\n\n\n\nEjemplo\n\n\n\nConsideremos una cadena de Markov con sólo dos estados \\(\\mathcal{S}=\\{1,2\\}\\), y con matriz de transición \\[ P=\\left[\n\\begin{array}{cc}\n\\frac{2}{3} & \\frac{1}{3}\\\\\n\\frac{1}{2} & \\frac{1}{2}\n\\end{array}\n\\right]. \\] Esta cadena es irreducible y aperiódica ya que todos los estados están comunicados en un solo paso. Por tanto, existirá la distribución límite \\(\\pi=(\\pi_1,\\pi_2)\\), la cual será también una distribución estacionaria. Para hallar dicha distribución, hemos de resolver la ecuación matricial \\[ \\left[\\begin{array}{cc}\\pi_1 & \\pi_2 \\end{array}\\right]\\left[\n\\begin{array}{cc}\n\\frac{2}{3} & \\frac{1}{3}\\\\\n\\frac{1}{2} & \\frac{1}{2}\n\\end{array}\n\\right]=\\left[\\begin{array}{cc}\\pi_1 & \\pi_2 \\end{array}\\right], \\] junto con la condición \\(\\pi_1+\\pi_2=1\\). Esto nos conduce al sistema de ecuaciones:\n\\[\n\\begin{cases}\n\\frac{1}{3}\\pi_1 - \\frac{1}{2}\\pi_2&=0,\\\\\n-\\frac{1}{3}\\pi_1 + \\frac{1}{2}\\pi_2&=0,\\\\\n\\pi_1+\\pi_2&=1.\n\\end{cases}\n\\]\nResolviendo obtenemos la distribución límite \\[ \\pi_1=\\frac{3}{5}=0.6,\\quad \\pi_2=\\frac{2}{5}=0.4. \\]\nDicha distribución límite es posible aproximarla por “fuerza bruta” tomando potencias sucesivas de la matriz de transición. Lo haremos con ayuda de R:\n\nP &lt;- rbind(c(2/3, 1/3),\n           c(1/2, 1/2))\nP2 &lt;- P%*%P\nP3 &lt;- P2%*%P\nP4 &lt;- P3%*%P\nP5 &lt;- P4%*%P\nP6 &lt;- P5%*%P\nP7 &lt;- P6%*%P\nP8 &lt;- P7%*%P\nP9 &lt;- P8%*%P\nP10 &lt;- P9%*%P\n\nP\n\n          [,1]      [,2]\n[1,] 0.6666667 0.3333333\n[2,] 0.5000000 0.5000000\n\nP2\n\n          [,1]      [,2]\n[1,] 0.6111111 0.3888889\n[2,] 0.5833333 0.4166667\n\nP3\n\n          [,1]      [,2]\n[1,] 0.6018519 0.3981481\n[2,] 0.5972222 0.4027778\n\nP4\n\n          [,1]      [,2]\n[1,] 0.6003086 0.3996914\n[2,] 0.5995370 0.4004630\n\nP5\n\n          [,1]      [,2]\n[1,] 0.6000514 0.3999486\n[2,] 0.5999228 0.4000772\n\nP6\n\n          [,1]      [,2]\n[1,] 0.6000086 0.3999914\n[2,] 0.5999871 0.4000129\n\nP7\n\n          [,1]      [,2]\n[1,] 0.6000014 0.3999986\n[2,] 0.5999979 0.4000021\n\nP8\n\n          [,1]      [,2]\n[1,] 0.6000002 0.3999998\n[2,] 0.5999996 0.4000004\n\nP9\n\n          [,1]      [,2]\n[1,] 0.6000000 0.4000000\n[2,] 0.5999999 0.4000001\n\nP10\n\n     [,1] [,2]\n[1,]  0.6  0.4\n[2,]  0.6  0.4\n\n\nVemos que al tomar sucesivas potencias de la matriz de transición, el valor de la matriz se va estabilizando y sus filas se van aproximando a la distribución estacionaria \\(\\pi\\) que hemos obtenido anteriormente. Recordemos que la potencia n-ésima de la matriz de transición corresponde a la matriz de transición de n pasos. Luego es lógico que al ir tomando potencias de la matriz de transición, obtengamos valores cada vez más cercanos a la distribución límite. Vemos también que la probabilidad límite no depende del valor inicial de la cadena, ya que todas las filas convergen a los mismos valores."
  },
  {
    "objectID": "Tema2.html#algoritmo-pagerank",
    "href": "Tema2.html#algoritmo-pagerank",
    "title": "3  Tema 2. Cadenas de Markov",
    "section": "3.8 Algoritmo PageRank",
    "text": "3.8 Algoritmo PageRank\nVolvamos al ejemplo que vimos al principio del tema donde analizamos la cadena de Markov del algoritmo PageRank de Google. Recordemos que dicha cadena describía a un “surfeador de internet” que pulsaba al azar los links de un conjunto de páginas. El algoritmo PageRank se usa para ordenar la aparición de las páginas en cada búsqueda en Google, dando preferencia a aquellas páginas cuya probabilidad sea mayor en la distribución límite. Es decir, aquellas con mayor probabilidad serán las que sean más visitadas a largo plazo.\nEn nuestro ejemplo, el “surfeador de la web” navega al azar entre las páginas A, B, C y D, donde:\n\nA tiene enlace a B,\nB tiene enlaces a A y C,\nC tiene enlace a A,\nD tienes enlaces a las otras tres páginas.\n\nDe esta manera, el espacio de estados es \\(\\{A,B,C,D\\}\\), y la matriz de transición será\n\\[\nP= \\left[\n\\begin{array}{cccc}\n0 & 1 & 0 & 0\\\\\n1/2 & 0 & 1/2 & 0\\\\\n1 & 0 & 0 & 0\\\\\n1/3 & 1/3 & 1/3 & 0\n\\end{array}\n\\right].\\]\nComo hemos dicho, estamos interesados en determinar la distribución límite de la cadena de Markov definida por el surfeador. El problema es que dicha cadena podría no ser irreducible, por lo que la distribución límite podría no existir. De hecho, en nuestro ejemplo en particular, la cadena no es irreducible ya que, si bien todas las páginas son accesibles desde D, dicha página no es accesible desde el resto de las páginas.\nPara solucionar este problema, el algoritmo de PageRank supone que, en cualquier paso, el surfeador de la web se puede “aburrir”, y empezar a navegar de nuevo en cualquiera de las páginas del conjunto al azar. La probabilidad con la que, tras cada paso, el surfeador se aburre es un número fijo \\(p\\). A la probabilidad complementaria \\(d=1-p\\) se le llama factor de amortiguamiento (damping factor). Por regla general se suele tomar factor de amortiguamiento \\(d=0.85\\).\nEn nuestro caso particular, si el surfeador se encuentra, por ejemplo, en la página \\(B\\) podría seguir navegando y ir a cualquiera de las páginas a las que tiene enlace, es decir, A o C, o podría aburrirse y saltar a cualquiera de las páginas del conjunto A,B,C, o D.\nLa cadena de Markov así obtenida es irreducible ya que desde cada página se puede pasar a cualquier otra página ya que existe la posibilidad de aburrirse. Además, será aperiódica ya que dichos saltos pueden darse en un solo paso. Al ser una cadena irreducible y aperiódica tendrá una distribución límite.\nDesde un punto de vista más práctico, añadir la posibilidad de que el surfeador se pueda aburrir, hace que éste no pueda quedarse “atrapado” en un grupo de páginas particular conectadas entre sí, pero no a las demás, haciendo que el algoritmo desestime otras páginas que también podrían ser importantes.\nEn general, supongamos que el surfeador navega al azar entre \\(n\\) páginas con matriz de transición \\(P\\). Entonces, al considerar un factor de amortiguación \\(d\\) obtenemos una nueva matriz de transición la cual viene dada por: \\[\nM=d\\cdot P + (1-d)\\cdot \\frac{1}{n} J_n,\n\\tag{3.7}\\] donde \\(J_n\\) es la matriz cuadrada de tamaño \\(n\\) con todas sus entradas igual a 1. La nueva matriz de transición \\(M\\) representa que, en cada paso, con probabilidad \\(d\\) el surfeador actuará de acuerdo a la cadena con matriz de transición \\(P\\), y con probabilidad \\(1-d\\) el surfeador actuará de acuerdo a la cadena consisten en elegir cualquiera de las n páginas al azar, cuya matriz de transición es \\(\\dfrac{1}{n}J_n\\).\nEn nuestro ejemplo, tomando \\(d=0.85\\), calculamos con ayuda de R la matriz de transición:\n\nP &lt;- rbind(c(0, 1, 0, 0),\n           c(1/2, 0, 1/2, 0),\n           c(1, 0, 0, 0),\n           c(1/3, 1/3, 1/3, 0))\n\nd &lt;- 0.85\nn &lt;- 4\nM &lt;- d*P + (1-d)*(1/n)*matrix(1, n, n)\n\nObtenemos\n\\[\nM= \\left[\n\\begin{array}{cccc}\n0.0375  & 0.8875 & 0.0375 & 0.0375\\\\\n0.4625 & 0.0375 & 0.4625 & 0.0375\\\\\n0.8875 & 0.0375 & 0.0375 & 0.0375\\\\\n0.3208333 & 0.3208333 & 0.3208333 & 0.0375\n\\end{array}\n\\right].\n\\]\nSabemos que la cadena dada por la anterior matriz de transición posee distribución límite. Podemos calcular su valor exacto resolviendo las ecuaciones correspondientes (veremos en las prácticas cómo hacerlo fácilmente en R). Sin embargo, por comodidad aproximaremos la distribución límite mediante el cálculo de potencias de la matriz de transición. Para ello podemos implementar el siguiente método iterativo en R:\n\nM_nueva &lt;- M\n\n# Fijamos un error maximo \nerror_max &lt;- 10^-15\n\n# Inicializamos la variable de error\nerror &lt;- 1\n\nwhile (error&gt; error_max) {\n  M_nueva &lt;- M_nueva%*%M\n  error &lt;- max(abs(M_nueva - M_nueva%*%M))\n}\n\n# La solución es \nM_nueva[1,]\n\n[1] 0.3824972 0.3732476 0.2067552 0.0375000\n\n\nObtenemos:\n\\[\\pi_A=0.3824972,\\quad \\pi_B=0.3732476,\\quad \\pi_C=0.2067552,\\quad \\pi_D=0.0375.\\]\nEsto quiere decir que, a largo plazo, el surfeador gastará el 38.25% del tiempo en la página A; 37.32% del tiempo en la página B; 20.68% del tiempo en la página C; y el 3.75% del tiempo en la página D. Por tanto, el algoritmo PageRank ordenará las páginas en función de estas probabilidades, mostrando las páginas en el orden: A, B, C, D."
  },
  {
    "objectID": "Tema3.html#procesos-de-conteo",
    "href": "Tema3.html#procesos-de-conteo",
    "title": "4  Tema 3. Procesos de Poisson",
    "section": "4.1 Procesos de conteo",
    "text": "4.1 Procesos de conteo\n\nDefinición 4.1 (Proceso de conteo) Un proceso estocástico en tiempo continuo \\((N_t)_{t\\in [0,\\infty)}\\) se dice que es un proceso de conteo si se verifica:\n\n\\(N_t\\ge 0\\).\n\\(N_t\\) toma valores enteros.\nSi \\(s&lt;t\\) entonces \\(N_s\\le N_t\\).\n\n\nEn particular, son procesos estocásticos de tiempo continuo y estado discreto. El valor \\(N_t\\) se interpreta como el número de veces que ocurre el evento aleatorio en estudio durante el intervalo de tiempo \\([0,t]\\). En particular, si \\(s&lt;t\\), entonces \\(N_t-N_s\\) representa el número de veces que ocurre el evento aleatorio durante el intervalo de tiempo \\((s,t]\\). Para fijar ideas, vamos a considerar que estamos contando las llegadas de clientes a un establecimiento. Por ejemplo, si \\(N_1=4\\) tendremos que han llegado 4 clientes durante el intervalo de tiempo \\([0,1]\\). Si \\(N_2-N_1=3\\), tendremos que han llegado 3 clientes durante el intervalo de tiempo \\((1,2]\\). El tiempo podría medirse por ejemplo en horas.\n\n\n\n\n\nTrayectoria de un proceso de conteo. En cada tiempo \\(t\\), \\(N_t\\) representa el número de llegadas ocurridas en el intervalo [0,t]\n\n\n\n\n\nDefinición 4.2 Un proceso estocástico \\((X_t)_{t\\in[0,\\infty)}\\) se dice que tiene incrementos independientes si para toda sucesión de tiempos \\(0\\le t_1&lt;t_2&lt;\\ldots&lt; t_n\\) las variables aleatorias\n\\[\nX_{t_2}-X_{t_1},\\quad\nX_{t_3}-X_{t_2},\\quad\n\\ldots,\\quad\nX_{t_n}-X_{t_{n-1}},\\quad\n\\]\nson independientes.\n\nUn ejemplo de proceso con incrementos independientes es el movimiento Browniano. Para un proceso de conteo \\((N_t)_{t\\in [0,\\infty)}\\) con incrementos independientes contando las llegadas de clientes (o cualquier otro evento aleatorio), se tendrá que los números de llegadas en intervalos disjuntos\n\\[\n(t_1,t_2],\\quad (t_2,t_3],\\quad \\ldots,\\quad (t_{n-1},t_n]\n\\]\nson independientes.\nSupongamos que queremos calcular la probabilidad de que haya 2 llegadas en el intervalo \\((1,2]\\) y 3 llegadas en el intervalo \\((2,3]\\). Como los intervalos \\((1,2]\\) y \\((2,3]\\) son disjuntos, tendremos\n\\[\n\\mathbb{P}\\Big(\\mbox{ 2 llegadas en }(1,2]\\mbox{ y 3 llegadas en }(2,3]\\Big)=\n\\mathbb{P}\\Big(\\mbox{ 2 llegadas en }(1,2]\\Big)\\cdot\\mathbb{P}\\Big(\\mbox{ 2 llegadas en }(2,3]\\Big).\n\\]"
  },
  {
    "objectID": "Tema3.html#proceso-de-poisson",
    "href": "Tema3.html#proceso-de-poisson",
    "title": "4  Tema 3. Procesos de Poisson",
    "section": "4.2 Proceso de Poisson",
    "text": "4.2 Proceso de Poisson\nEl proceso de conteo más usado es el proceso de Poisson. En esta sección veremos su definición y principales propiedades. Antes de introducir este concepto, necesitamos recordar la distribución de Poisson.\n\n4.2.1 Distribución de Poisson\n\nDefinición 4.3 Una variable aleatoria discreta \\(X\\) se dice que tiene distribución de Poisson de parámetro \\(\\lambda&gt;0\\) si toma valores en \\(\\{0,1,2,3,\\ldots\\}\\) y tiene función puntual de probabilidad\n\\[\n\\mathbb{P}(X=k)=\\frac{\\lambda^k e^{-\\lambda}}{k!}\\quad\\mbox{ para todo }k\\in\\{0,1,2,\\ldots\\}.\n\\]\nEn ese caso escribimos \\(X\\sim{\\rm Poisson}(\\lambda)\\).\n\nAlgunas propiedades de la distribución de Poisson que conviene recordar son las siguientes.\n\nProposición 4.1 Supongamos que \\(X\\sim{\\rm Poisson}(\\lambda)\\). Entonces \\(\\mathbb{E}(X)=\\lambda\\) y \\({\\rm Var}(X)=\\lambda\\).\n\nLa suma de variables Poisson independientes es Poisson. Más concretamente, tenemos lo siguiente.\n\nProposición 4.2 Supongamos que \\(X_1,X_2,\\ldots,..,X_n\\) son variables aleatorias independientes con \\(X_i\\sim{\\rm Poisson}(\\lambda_i)\\). Entonces \\[\nX_1+X_2+\\ldots+X_n\\sim{\\rm Poisson}(\\lambda_1+\\lambda_2+\\ldots+\\lambda_n).\n\\]\n\nLas variables Poisson pueden ser interpretadas como el límite en distribución de variables aleatorias binomiales. Más específicamente tenemos lo siguiente.\n\nProposición 4.3 Consideremos una sucesión de variables aleatorias \\(Y_1,Y_2,\\ldots\\), donde \\(Y_n\\sim{\\rm Binomial}(n,p_n)\\) con \\(p_n=\\lambda/n\\) para cierto \\(\\lambda&gt;0\\). Entonces la función puntual de probabilidad de \\(Y_n\\) converge a la función puntual de probabilidad de una variable \\({\\rm Poisson}(\\lambda)\\), es decir,\n\\[\n\\lim_{n\\to\\infty}\\mathbb{P}(Y_n=k)=\\frac{\\lambda^k e^{-\\lambda}}{k!}\\quad\\mbox{ para todo }k\\in\\{0,1,2,\\ldots\\}.\n\\]\n\nDemostración.\nFijado \\(k\\in\\{0,1,2,\\ldots\\}\\), como \\(Y_n\\sim{\\rm Binomial}(n,p_n)\\), tenemos\n\\[\n\\begin{aligned}\n\\mathbb{P}(Y_n=k)&=\\binom{n}{k} p_n^k (1-p_n)^{n-k}\\\\\n&=\\frac{n!}{(n-k)!k!} \\left(\\frac{\\lambda}{n}\\right)^k \\left(1-\\frac{\\lambda}{n}\\right)^{n-k}\\\\\n&=\\frac{n!}{(n-k)!k!} \\left(\\frac{\\lambda}{n}\\right)^k \\left(1-\\frac{\\lambda}{n}\\right)^{n}\\left(1-\\frac{\\lambda}{n}\\right)^{-k}\\\\\n&=\\frac{n!}{(n-k)! n^k}\\frac{\\lambda^k}{k!} \\left(1-\\frac{\\lambda}{n}\\right)^{n}\\left(1-\\frac{\\lambda}{n}\\right)^{-k}.\n\\end{aligned}\n\\tag{4.1}\\]\nPor otro lado, observamos que\n\\[\n\\lim_{n\\to\\infty}\\left(1-\\frac{\\lambda}{n}\\right)^{n}=e^{-\\lambda},\n\\]\n\\[\n\\lim_{n\\to\\infty}\\left(1-\\frac{\\lambda}{n}\\right)^{-k}=1,\n\\]\n\\[\n\\begin{aligned}\n\\lim_{n\\to\\infty}\\frac{n!}{(n-k)! n^k}&=\\lim_{n\\to\\infty}\\left(\\frac{n}{n}\\cdot\\frac{n-1}{n}\\cdot\\frac{n-2}{n}\\cdot\\ldots \\cdot\\frac{n-(k-1)}{n}\\right)\\\\\n&=\\lim_{n\\to\\infty}\\left(1\\cdot\\left(1-\\frac{1}{n}\\right)\\cdot\\left(1-\\frac{2}{n}\\right)\\cdot\\ldots \\cdot\\left(1-\\frac{k-1}{n}\\right)\\right)=1,\n\\end{aligned}\n\\]\ndonde para calcular el último límite hemos usado que tenemos un número constante \\(k\\) de factores que convergen a \\(1\\).\nTomando límites cuando \\(n\\to\\infty\\) en Ecuación 4.1 teniendo en cuenta las anteriores igualdades, obtenemos el resultado deseado.\\(\\square\\)\n\n\n4.2.2 Definición de proceso de Poisson\nEl proceso de Poisson se usa para contar la ocurrencia de un evento aleatorio cuyas observaciones se dan en el tiempo con una frecuencia promedio constante \\(\\lambda\\). Por ejemplo, supongamos que mediante la observación se llega a la conclusión de que a un establecimiento llegan, de media, 5 clientes por hora. Puesto que las llegadas son aleatorias, cada hora llegará un número de clientes que no tiene por qué ser exactamente igual a 5; sin embargo, dicha cifra se verificará en promedio al avanzar el tiempo.\n\nDefinición 4.4 (Proceso de Poisson) Un proceso de conteo \\((N_t)_{t\\in [0,\\infty)}\\) se dice que es un proceso de Poisson con tasa \\(\\lambda&gt;0\\) si se verifican las siguientes condiciones:\n\n\\(N_0=0\\),\n\\(N_t\\) tiene incrementos independientes,\nPara cada \\(t,s\\ge 0\\) se verifica que \\(N_{t+s}-N_s\\sim {\\rm Poisson}(\\lambda t)\\).\n\n\nPara justificar la definición anterior pensemos en los clientes que llegan al establecimiento. Supongamos que llegan de media \\(\\lambda\\) clientes por hora. Sea \\(N_t\\) el número de clientes que han llegado a la tienda tras \\(t\\) horas. Queremos encontrar qué distribución debería seguir la variable aleatoria \\(N_t\\).\nPara simplificar el problema, vamos a suponer en primer lugar que, dado \\(n\\in\\mathbb{N}\\), los clientes van llegando en instantes de tiempo equiespaciados\n\\[\n0&lt;\\frac{t}{n}&lt;\\frac{2t}{n}&lt;\\frac{3t}{n}&lt;\\ldots&lt; t,\n\\]\nde forma que al final de cada intervalo \\(\\left(\\frac{kt}{n},\\frac{(k+1)t}{n}\\right]\\) podrá llegar un solo cliente con probabilidad \\(p\\), o no llegará ninguno con probabilidad \\(1-p\\). Además, consideramos que la llegada o no de un cliente en cada intervalo ocurre de forma independiente de lo que haya pasado en los intervalos anteriores.\nBajo estos supuestos, tenemos que el número total \\(N_t\\) de clientes llegados en el intervalo de tiempo \\([0,t]\\) sigue una distribución \\({\\rm Binomial}(n,p)\\). En particular, como llegan de media \\(\\lambda\\) clientes por hora, tendremos que\n\\[\n\\lambda t=\\mathbb{E}(N_t)=n p.\n\\]\nNecesariamente, se tiene que verificar que \\(p=\\lambda t/n\\). De esta manera obtenemos la probabilidad de llegada de un cliente en cada intervalo, la cual depende del número de subdivisiones \\(n\\) en el que dividimos el intervalo de tiempo.\nPara pasar a tiempo continuo, tomemos límites cuando \\(n\\to\\infty\\). De este modo, como consecuencia de la Proposición Proposición 4.3, obtenemos que\n\\[\n\\mathbb{P}(N_t=k)=\\frac{(t\\lambda)^k e^{-\\lambda t}}{k!},\\quad k\\in\\{0,1,2,\\ldots\\}.\n\\]\nConcluimos que \\(N_t\\) sigue una distribución \\({\\rm Poisson}(\\lambda t)\\), lo cual justifica el punto 3 de la definición de Proceso de Poisson.\nEs lógico considerar que los clientes que llegan en dos intervalos de tiempo disjuntos sean independientes, por lo que el proceso de conteo correspondiente debería tener incrementos independientes. Por lo cual, la condición 2 de la definición anterior es natural.\nComo hemos observado arriba tenemos que \\(\\mathbb{E}(N_t)=\\lambda t\\), lo cual es también consecuencia de la condición 3. En particular, la tasa \\(\\lambda\\) de un proceso de Poisson nos informa del número medio de llegadas por unidad de tiempo.\n\n\n\n\n\n\nEjemplo\n\n\n\nA una gasolinera llegan de media 10 coches por hora. Supongamos que la llegada de coches a la gasolinera sigue un proceso de Poisson. Calcula:\n\nProbabilidad de que lleguen 2 coches entre las 9:00 y las 9:20.\nProbabilidad de que lleguen 3 coches entre las 9:00 y las 9:20 y 7\n\ncoches entre 10:20 y las 11:00.\nSolución: Consideramos el proceso \\((N_t)_{t\\ge 0}\\) de conteo de coches tras \\(t\\) horas. Como llegan una media de 10 coches por hora, tendremos que \\(\\lambda=10\\).\n\nSea \\(X=\\mbox{``Núm. de coches entre las 9:00 y las 9:20''}\\). Debido a la condición 3 de la definición de proceso de Poisson, tenemos que \\(X\\sim {\\rm Poisson}(10/3)\\) ya que entre las 9:00 y las 9:20 ha pasado 1/3 de hora. Por tanto,\n\n\\[\n\\mathbb{P}(X=2)=\\frac{e^{-10/3}\\cdot (10/3)^2}{2!}=0.1982.\n\\]\nAlternativamente, podemos usar el siguiente código en R para calcular el resultado anterior mediante la función puntual de probabilidad de la Poisson:\n\nt &lt;- 1/3\n\nlambda &lt;- 10\n\n# Evaluamos la función puntual de probabilidad de la Poisson\n\ndpois(2, t*lambda)\n\n[1] 0.1981889\n\n\n\nSea \\(Y=\\mbox{``Núm. de coches entre las 10:20 y las 11:00''}\\). Tenemos que \\(Y\\sim {\\rm Poisson}(20/3)\\) y, además, \\(X,Y\\) son independientes. Entonces,\n\n\\[\\begin{align*}\n\n\\mathbb{P}(X=3,Y=7)&=\\mathbb{P}(X=3)\\mathbb{P}(Y=7)\\\\\n\n&=\\frac{e^{-10/3}\\cdot (10/3)^3}{3!} \\frac{e^{-20/3}\\cdot (20/3)^7}{7!}=0.0325.\n\n\\end{align*}\\]\nAlternativamente, podemos usar el siguiente código de R para calcular el resultado anterior:\n\nt &lt;- 1/3\n\ns &lt;- 2/3\n\nlambda &lt;- 10\n\n# Evaluamos la función puntual de probabilidad de la Poisson\n\ndpois(3, t*lambda)*dpois(7, s*lambda)\n\n[1] 0.03254399"
  },
  {
    "objectID": "Tema3.html#tiempos-de-ocurrencia-llegada-en-un-proceso-de-poisson",
    "href": "Tema3.html#tiempos-de-ocurrencia-llegada-en-un-proceso-de-poisson",
    "title": "4  Tema 3. Procesos de Poisson",
    "section": "4.3 Tiempos de ocurrencia (llegada) en un Proceso de Poisson",
    "text": "4.3 Tiempos de ocurrencia (llegada) en un Proceso de Poisson\nHemos visto que los procesos de Poisson surgen de manera natural cuando se trata de contar las llegadas de clientes a un establecimiento. En esta sección vamos a estudiar qué distribución de probabilidad sigue el tiempo aleatorio que pasa entre la llegada de dos clientes consecutivos.\n\n4.3.1 Distribución exponencial\nRecordemos que una variable aleatoria continua \\(\\tau\\) tiene distribución exponencial de parámetro \\(\\lambda&gt;0\\), en cuyo caso escribimos \\(\\tau\\sim {\\rm Exp}(\\lambda)\\), si toma valores reales positivos y tiene función de densidad\n\\[\nf(t)=\\lambda e^{-\\lambda t},\\quad t&gt;0.\n\\]\nRecordemos además que si \\(\\tau\\sim{\\rm Exp}(\\lambda)\\), entonces la función de distribución de \\(\\tau\\) es \\(F(t)=1-e^{-\\lambda t}\\).\nEn particular,\n\\[\n\\mathbb{P}(\\tau&gt;t)=1-F(t)=e^{-\\lambda t}.\n\\]\nLas variables exponenciales suelen interpretarse como el tiempo de espera para la observación de un evento aleatorio. Por ejemplo, la llegada del primer cliente a una tienda, el tiempo de fallo de un sistema, el tiempo de quiebra de una entidad financiera, tiempo en el que una acción alcanza un determinado nivel, etc.\n\nProposición 4.4 Si \\(\\tau\\sim{\\rm Exp}(\\lambda)\\), entonces\n\\[\n\\mathbb{E}(\\tau)=\\frac{1}{\\lambda},\\quad {\\rm Var}(\\tau)=\\frac{1}{\\lambda^2}.\n\\]\n\nSi pensamos en la llegada del primer cliente a un establecimiento, la proposición anterior nos dice que el tiempo medio que esperaremos en observar llegar dicho cliente será \\(1/\\lambda\\).\nPor otro lado, tendremos que \\(\\mathbb{P}(\\tau\\le t)\\) es la probabilidad que el primer cliente llegue en algún instante del intervalo de tiempo \\([0,t]\\). Por tanto, \\(\\mathbb{P}(\\tau&gt;t)\\) es la probabilidad de que ningún cliente llegue durante el intervalo de tiempo \\([0,t]\\).\nUna importante propiedad de las variables exponenciales es que no tienen memoria, es decir, tenemos lo siguiente.\n\n\n4.3.2 Falta de memoria\nSi \\(\\tau\\sim {\\rm Exp}(\\lambda)\\), entonces\n\\[\n\\mathbb{P}(\\tau&gt;s)=\\mathbb{P}(\\tau&gt;t+s|\\tau&gt;t)\n\\] para todo \\(t,s&gt;0\\).\n\nLa anterior propiedad, conocida como falta de memoria de la distribución exponencial, quiere decir que la probabilidad de que en el intervalo de tiempo \\([0,s]\\) no haya ninguna llegada, es igual a la probabilidad de que en el intervalo de tiempo \\([t,t+s]\\) de igual longitud no haya ninguna llegada si en el intervalo de tiempo previo \\([0,t]\\) no ha habido llegadas, es decir,\n\\[\n\\mathbb{P}\\left(\\text{no hay llegadas en }[0,s]\\right)=\n\\mathbb{P}\\left(\\text{no hay llegadas en }[t,t+s]|\\text{no hay llegadas en }[0,t] \\right).\n\\]\nPor ejemplo, si en 30 minutos no ha llegado ningún cliente a la tienda, la probabilidad de esperar 10 minutos más y no ver ningún cliente es la misma que si no hubiéramos esperado los 30 minutos iniciales.\n\n4.3.3 Modelización de tiempos de llegada y entre llegadas consecutivas\nEl siguiente resultado, para el cual no damos la demostración, caracteriza a los procesos de Poisson en términos de tiempos de espera exponenciales.\n\nTeorema 4.1 (Caracterización proceso de Poisson) Un proceso estocástico \\((N_{t})_{t\\in[0,\\infty)}\\) es un proceso de Poisson con tasa \\(\\lambda\\) si y sólo si existe una sucesión \\(\\tau_1,\\tau_2,\\tau_3,\\ldots\\) de variables aleatorias independientes con distribución \\({\\rm Exp}(\\lambda)\\) tal que\n\\[\nN_t=\\max\\{n\\colon \\tau_1+\\tau_2+\\ldots+\\tau_n\\le t\\}.\n\\tag{4.2}\\]\n\nPodemos pensar en \\(\\tau_i\\) como el tiempo de espera entre las llegadas, es decir, \\(\\tau_1\\) es el tiempo transcurrido hasta la primera llegada, \\(\\tau_2\\) es el tiempo trascurrido entre la primera y la segunda llegada, \\(\\tau_3\\) es el tiempo entre la segunda y la tercera llegada, etc. De esta manera, \\(T_n=\\tau_1+\\tau_2+\\ldots+\\tau_n\\) es el tiempo transcurrido hasta la n-ésima llegada. En particular, la condición (Ecuación 4.2) puede ser reescrita como\n\\[\nN_t=\\max\\{n\\colon T_n\\le t\\}.\n\\]\nSi, por ejemplo, \\(N_t=4\\), la condición anterior nos dice que\n\\[\nT_4 \\le t &lt; T_5.\n\\]\nEn términos de llegadas, tenemos que en el instante \\(t\\) habrán llegado los cuatro primeros clientes, pero no el quinto.\nRecordemos que \\(\\lambda\\) era el promedio de llegadas por unidad de tiempo. Por otro lado, como \\(\\mathbb{E}(\\tau)=1/\\lambda\\), tendremos que esperar de media \\(1/\\lambda\\) unidades de tiempo entre cada dos llegadas sucesivas.\n\n\n\n\n\n\nEjemplo\n\n\n\nA la bandeja de entrada de mi email llegan de media 2 emails por hora (o un email cada media hora). Supongamos que abro el correo a las 8:00 am. Calcula:\n\nLa probabilidad de que el primer email llegue más tarde de las 8:30.\nLa probabilidad de que el primer email llegue más tarde de las 11:00 si no ha llegado ningún correo hasta las 9:00.\n\nSolución: Consideremos los tiempos \\(\\tau_1,\\tau_2,\\tau_3,\\ldots\\) entre llegadas de emails, medidos en horas.\n\nTenemos que \\(\\tau_1\\sim {\\rm Exp}(2)\\), luego\n\n\\[\n\\mathbb{P}(\\tau_1&gt;0.5)=e^{-2\\cdot 0.5}=0.3679.\n\\]\nAlternativamente, podemos usar R para calcular la probabilidad anterior mediante la función de distribución de la exponencial:\n\nlambda &lt;- 2\n\n# Evaluamos la función de distribución de la exponencial\n\n1-pexp(0.5, lambda)\n\n[1] 0.3678794\n\n\n\nUsando que \\(\\tau_1\\) no tiene memoria\n\n\\[\n\\mathbb{P}(\\tau_1&gt;3|\\tau_1&gt;1)=\\mathbb{P}(\\tau_1&gt;2)=e^{-2\\cdot 2}= 0.0183.\n\\]\nAlternativamente, podemos usar R para calcular la probabilidad anterior.\n\nlambda &lt;- 2\n\n1 - pexp(2, lambda)\n\n[1] 0.01831564\n\n\n\n\nRecordemos que una variable aleatoria continua \\(T\\) tiene distribución gamma, en cuyo caso escribimos \\(T\\sim \\Gamma(k,\\lambda)\\), si toma valores positivos y tiene función de densidad\n\\[\nf(t)=\\frac{\\lambda^k}{\\Gamma(k)} t^{k-1} e^{-\\lambda t},\\quad t&gt;0,\n\\]\ndonde \\(\\Gamma(k)\\) es la función Gamma, la cual viene dada por \\(\\Gamma(k)=(k-1)!\\) cuando \\(k\\) es entero.\nLa distribución gamma se obtiene cuando sumamos variables independientes con distribución exponencial. Concretamente, tenemos lo siguiente.\n\nProposición 4.5 Supongamos que \\(\\tau_1,\\tau_2,\\tau_3,\\ldots\\) son variables independientes con distribución \\({\\rm Exp}(\\lambda)\\). Entonces se verifica que\n\\[\nT_n=\\tau_1+\\tau_2+\\ldots+\\tau_n\\sim \\Gamma(n,\\lambda).\n\\]\n\nLa anterior propiedad es muy útil para calcular probabilidades relativas a tiempos de llegada, ya que nos da la distribución del tiempo de llegada \\(T_n\\) del n-ésimo cliente.\n\n\n\n\n\n\nEjemplo\n\n\n\nVolviendo al ejemplo anterior. Calcula:\n\nLa probabilidad de que el cuarto email llegue pasadas las 10:00 am.\nLa probabilidad de que el cuarto email llegue más de 3 horas después del segundo email si el segundo email llega después de las 9:00 am.\n\nSolución:\n\nComo \\(T_4=\\tau_1+\\tau_2+\\tau_3+\\tau_4\\sim\\Gamma(n=4,\\lambda=2)\\), tenemos\n\n\\[\n\\mathbb{P}(T_4&gt;2)=\\int_2^\\infty \\frac{2^4 t^3 e^{-2t}}{3!}{\\rm d}t=\\frac{8}{3}\\int_2^\\infty t^3 e^{-2t}{\\rm d}t=0.4435,\n\\]\ndonde la anterior integral puede ser calculada a mano mediante integración por partes, o con ayuda del ordenador.\nAlternativamente, usando R tenemos.\n\nn &lt;- 4\n\nlambda &lt;- 2\n\n# Evaluamos la función de distribución de la distribución gamma\n\n1 - pgamma(2, n, lambda)\n\n[1] 0.4334701\n\n\n\nComo \\(\\tau_3,\\tau_4\\) son independientes de \\(\\tau_2,\\tau_1\\), por ser las \\(\\tau_i\\) independientes entre sí, tenemos que\n\n\\[\n\\begin{aligned}\n\\mathbb{P}(\\tau_3+\\tau_4&gt;3|\\tau_1+\\tau_2&gt;1)&=\\mathbb{P}(\\tau_3+\\tau_4&gt;3)\\\\\n&=\\int_3^\\infty 4 t e^{-2t} {\\rm d}t=0.0173,\n\\end{aligned}\n\\]\ndonde hemos usado que \\(\\tau_3+\\tau_4\\sim \\Gamma(n=2,\\lambda=2)\\). Además, la anterior integral puede ser calculada a mano mediante integración por partes, o con ayuda del ordenador.\nAlternativamente, usando R tenemos.\n\nn &lt;- 2\n\nlambda &lt;- 2\n\n1 - pgamma(3, n, lambda)\n\n[1] 0.01735127\n\n\n\n\n\n\n4.3.4 Simulación de procesos de Poisson\nSimular procesos de Poisson es sencillo usando los tiempos entre llegadas. Para ello basta simular los tiempos entre llegadas como variables aleatorias exponenciales independientes y contabilizar el número de llegadas ocurridas.\nVeamos un ejemplo en R:\n\n# Valores para simulación\n\nlambda &lt;- 2  # tasa (llegadas por unidad de tiempo)\n\nT &lt;- 10      # Intervalo de tiempo en el que observamos el proceso\n\n# Simulación de los tiempos entre llegadas\n\nset.seed(123)\n\ntau &lt;- NULL\n\ni &lt;- 1\n\nwhile(sum(tau) &lt; T){\n\n    tau[i] &lt;- rexp(n = 1, rate = lambda)\n\n    i &lt;- i+1\n\n}\n\n# Calculamos los valores  del proceso de Poisson\n\ntiempos &lt;- c(0,cumsum(tau))\n\nN &lt;- 0:length(tau)\n\n# Dibujamos la trayectoria\n\nplot(tiempos, N, type = \"s\",\n\n     xlab = \"Tiempo\", ylab = \"Llegadas\", xlim=c(0, 10))\n\n\n\n\nSimulación de la trayectoria de un proceso de Poisson"
  },
  {
    "objectID": "Tema3.html#transformaciones-de-procesos-de-poisson",
    "href": "Tema3.html#transformaciones-de-procesos-de-poisson",
    "title": "4  Tema 3. Procesos de Poisson",
    "section": "4.4 Transformaciones de procesos de Poisson",
    "text": "4.4 Transformaciones de procesos de Poisson\nEn esta sección vamos a ver dos tipos de transformaciones de procesos de Poisson, la superposición y la separación.\n\n4.4.1 Superposición de procesos de Poisson independientes\nConsideremos dos procesos de Poisson \\((N^1_t)_{t\\in[0,\\infty)}\\) y \\((N^2_t)_{t\\in[0,\\infty)}\\) independientes con tasas \\(\\lambda_1\\) y \\(\\lambda_2\\), respectivamente. Consideremos el proceso \\((N_t)_{t\\in[0,\\infty)}\\) definido como\n\\[\nN_t=N^1_t+N^2_t\\quad\\mbox{ para todo }t\\in[0,\\infty).\n\\]\nDados \\(t,s\\ge 0\\), se tiene que los incrementos\n\\[\nN_{t+s}^1-N_{s}^1\\sim {\\rm Poisson}(\\lambda_1 t),\\quad N_{t+s}^2-N_{s}^2\\sim {\\rm Poisson}(\\lambda_2 t),\n\\]\ny son variables aleatorias independientes. Por tanto, debido a la Proposición Proposición 4.2 tenemos que\n\\[\nN_{t+s}-N_t=(N^1_{t+s}-N^1_{s})+(N^2_{t+s}-N^2_{s})\n\\] sigue una distribución \\({\\rm Poisson}((\\lambda_1+\\lambda_2) t)\\). Es más, \\(N_0=N^1_0+N^2_0=0\\), y el proceso \\(N_t\\) tiene incrementos independientes (por tenerlos \\(N^1\\) y \\(N^2\\)). Dado que se verifican todas las condiciones de la definición de proceso de Poisson, podemos concluir que el proceso \\((N_t)_{t\\in[0,\\infty)}\\) es de Poisson con tasa \\(\\lambda_1+\\lambda_2\\).\nEn general, tendremos lo siguiente.\n\nTeorema 4.2 (Superposición) Sean \\((N_t^1),(N_t^2),\\ldots,(N_t^m)\\) procesos de Poisson independientes con tasas \\(\\lambda_1,\\lambda_2,\\ldots,\\lambda_m\\), respectivamente. Sea además\n\\[\nN_t=N_t^1+N_t^2+\\ldots+N_t^m\\quad\\mbox{ para todo }t\\in[0,\\infty).\n\\]\nEntonces el proceso \\((N_t)_{t\\in[0,\\infty)}\\) es un proceso de Poisson con tasa \\(\\lambda_1+\\lambda_2+\\ldots+\\lambda_m\\).\n\nA continuación simulamos en R la superposición de dos procesos de Poisson independientes:\n\n# Valores para simulación de los procesos\n\nlambda1 &lt;- 2  # tasa del primer proceso de Poisson\n\nlambda2 &lt;- 0.5  # tasa del segundo proceso de Poisson\n\nT &lt;- 10      # Intervalo de tiempo en el que observamos el proceso\n\n# Simulación de los tiempos entre llegadas\n\nset.seed(123)\n\ntau1 &lt;- NULL\n\ntau2 &lt;- NULL\n\ni &lt;- 1\n\nwhile(sum(tau1) &lt; T){\n\n  tau1[i] &lt;- rexp(n = 1, rate = lambda1)\n\n  i &lt;- i+1\n\n}\n\ni &lt;- 1\n\nwhile(sum(tau2) &lt; T){\n\n  tau2[i] &lt;- rexp(n = 1, rate = lambda2)\n\n  i &lt;- i+1\n\n}\n\n# Definimos los timpos y los valores correspondientes del proceso de Poisson 1\n\ntiempos1 &lt;- c(0,cumsum(tau1))\n\nN1 &lt;- 0:length(tau1)\n\n# Definimos los tiempos y los valores correspondientes del proceso de Poisson 2\n\ntiempos2 &lt;- c(0,cumsum(tau2))\n\nN2 &lt;- 0:length(tau2)\n\n# Definimos los tiempos y los valores correspondientes del proceso superposición\n\ntiempos &lt;- union(tiempos1, tiempos2)\n\ntiempos &lt;- sort(tiempos)\n\nN &lt;- 0:(length(tiempos)-1)\n\n# Dibujamos la trayectoria del proceso 1\n\nplot(tiempos1, N1, type = \"s\",\n\n     xlab = \"Tiempo\", ylab = \"Llegadas\", xlim = c(0,10), ylim=c(0, max(N)))\n\n# Dibujamos la trayectoria del proceso 2\n\nlines(tiempos2, N2, type = \"s\", col=\"blue\")\n\n# Dibujamos la trayectoria del proceso superposición\n\nlines(tiempos, N, type = \"s\", col=\"red\")\n\n# Añadimos una leyenda\n\nlegend(0, 25, legend=c(\"Proceso 1\", \"Proceso 2\", \"Superposición\"),\n\n       col=c(\"black\", \"blue\", \"red\"), lty=c(1, 1, 1))\n\n\n\n\nSuperposición de dos procesos de Poisson\n\n\n\n\n\n\n4.4.2 Separación de procesos de Poisson\nImaginemos una cafetería en los Pirineos donde los clientes, de España y de Francia, van llegando de acuerdo a un proceso de Poisson \\((N_t)_{t\\in[0,\\infty)}\\) con tasa de 10 clientes por hora. Supongamos además que el 60% de los clientes son españoles y el 40% de los clientes son franceses. De este manera, los clientes españoles tendrán su propio proceso de conteo \\((N_t^1)_{t\\in[0,\\infty)}\\) y, de la misma manera, los clientes franceses tendrán otro proceso de conteo \\((N_t^2)_{t\\in[0,\\infty)}\\). Nos preguntamos qué tipo de procesos son \\((N_t^1)_{t\\in[0,\\infty)}\\) y \\((N_t^2)_{t\\in[0,\\infty)}\\).\nEn general, un proceso de Poisson \\((N_t)_{t\\in[0,\\infty)}\\) puede ser separado en dos procesos \\((N_t^1)_{t\\in[0,\\infty)}\\) y \\((N_t^2)_{t\\in[0,\\infty)}\\) contando llegadas de “tipo 1” y “tipo 2”, de acuerdo a una sucesión \\(Y_1,Y_2,\\ldots\\) de variables aleatorias independientes entre sí, e independientes del proceso \\((N_t)_{t\\in [0,\\infty)}\\), tal que\n\\[\\mathbb{P}(Y_i=1)=p\\quad\\mbox{ y }\\quad\\mathbb{P}(Y_i=2)=1-p.\\]\nIntuitivamente, para cada llegada \\(i\\), podemos pensar en la variable aleatoria \\(Y_i\\) como un lanzamiento de moneda (no equilibrada si \\(p\\neq 1/2\\)) realizado al producirse dicha llegada, de modo que si se obtiene cara (valor 1) se clasifica la llegada como de tipo 1, y si se obtiene cruz (valor 2) se clasifica la clasifica como de tipo 2.\nDe esta manera, si \\(T_n=\\tau_1+\\tau_2+\\ldots+\\tau_n\\) es el tiempo transcurrido hasta la n-ésima llegada, entonces los procesos \\((N_t^1)_{t\\in[0,\\infty)}\\) y \\((N_t^2)_{t\\in[0,\\infty)}\\) contando las llegadas de tipo 1 y las llegadas de tipo 2 hasta tiempo \\(t\\) vendrán respectivamente dados por\n\\[\nN_t^1=\\#\\{n\\colon Y_n=1,\\:T_n\\le t\\},\\quad N_t^2=\\#\\{n\\colon Y_n=2,\\:T_n\\le t\\},\n\\tag{4.3}\\]\ndonde # denota el cardinal de un conjunto.\nTenemos el siguiente resultado.\n\nTeorema 4.3 (Separación) Sea \\((N_t)_{t\\in[0,\\infty)}\\) un proceso de Poisson con tasa \\(\\lambda\\). Consideremos que cada llegada es de tipo 1 con probabilidad \\(p\\) o de tipo 2 con probabilidad \\(1-p\\), independientemente de las demás llegadas y de \\((N_t)_{t\\in[0,\\infty)}\\). Entonces, los procesos \\((N_t^1)_{t\\in[0,\\infty)}\\) y \\((N_t^2)_{t\\in[0,\\infty)}\\) contando las llegadas de tipo 1 y las llegadas de tipo 2, respectivamente, verifican:\n\n\\((N_t^1)_{t\\in[0,\\infty)}\\) es un proceso de Poisson con tasa \\(\\lambda p\\).\n\\((N_t^2)_{t\\in[0,\\infty)}\\) es un proceso de Poisson con tasa \\(\\lambda (1-p)\\).\n\\((N_t^1)_{t\\in[0,\\infty)}\\) y \\((N_t^2)_{t\\in[0,\\infty)}\\) son procesos de Poisson independientes.\n\n\nVolvamos al ejemplo de la cafetería en los Pirineos. Dijimos que llegan una media de 10 clientes por hora, por lo que el correspondiente proceso de Poisson \\((N_t)_{t\\in [0,\\infty)}\\) tendrá tasa \\(\\lambda=10\\). Al ser el 60% de los clientes que llegan españoles y el 40% franceses, tendremos que los clientes españoles llegarán a la cafetería siguiendo un proceso de Poisson con tasa \\(10\\cdot 0.6=6\\), y los clientes franceses llegarán a la cafetería siguiendo un proceso de Poisson con tasa \\(10\\cdot 0.4=4\\).\nA continuación simulamos en R la separación del proceso de clientes en españoles y franceses:\n\n# Valores para simulación de los procesos\n\nlambda &lt;- 10  # tasa del proceso de Poisson\n\np &lt;- 0.6  # tasa del segundo proceso de Poisson\n\nT &lt;- 10      # Intervalo de tiempo en el que observamos el proceso\n\n# Simulación de los tiempos entre llegadas y tipos de llegadas\n\nset.seed(123)\n\ntau &lt;- NULL\n\ny &lt;- NULL\n\ni &lt;- 1\n\nwhile(sum(tau) &lt; T){\n\n  tau[i] &lt;- rexp(n = 1, rate = lambda1)\n\n  y[i]=sample(c(1, 2), size = 1)\n\n  i &lt;- i+1\n\n}\n\n# Definimos los tiempos y los valores de N\n\ntiempos &lt;- c(0,cumsum(tau))\n\nN &lt;- 0:length(tau)\n\n# Definimos los valores del proceso de Poisson 1\n\nN1 &lt;- NULL\n\nN1[y==1] &lt;- 1\n\nN1[y==2] &lt;- 0\n\nN1 &lt;- c(0, cumsum(N1))\n\n# Definimos los valores del proceso de Poisson 1\n\nN2 &lt;- NULL\n\nN2[y==2] &lt;- 1\n\nN2[y==1] &lt;- 0\n\nN2 &lt;- c(0, cumsum(N2))\n\n# Dibujamos la trayectoria del proceso 1\n\nplot(tiempos, N1, type = \"s\",\n\n     xlab = \"Tiempo\", ylab = \"Llegadas\", xlim = c(0, 10), ylim=c(0, max(N)))\n\n# Dibujamos la trayectoria del proceso 2\n\nlines(tiempos, N2, type = \"s\", col=\"blue\")\n\n# Dibujamos la trayectoria del proceso original\n\nlines(tiempos, N, type = \"s\", col=\"red\")\n\n# Añadimos una leyenda\n\nlegend(0, 18, legend=c(\"Españoles\", \"Franceses\", \"Totales\"),\n\n       col=c(\"black\", \"blue\", \"red\"), lty=c(1, 1, 1))\n\n\n\n\nSeparación del proceso de Poisson"
  },
  {
    "objectID": "Tema3.html#procesos-de-renovación",
    "href": "Tema3.html#procesos-de-renovación",
    "title": "4  Tema 3. Procesos de Poisson",
    "section": "4.5 Procesos de renovación",
    "text": "4.5 Procesos de renovación\nHemos visto anteriormente que los procesos de Poisson son caracterizados como el proceso de conteo cuando los tiempos entre llegadas vienen dados por una sucesión \\(\\tau_1,\\tau_2,\\tau_3,\\ldots\\) de variables independientes y exponenciales con la misma tasa \\(\\lambda\\). Una generalización de los procesos de Poisson son los procesos de renovación donde los tiempos entre llegadas son independientes e idénticamente distribuidos, pero no necesariamente siguen una distribución exponencial. Dicho concepto es definido formalmente como sigue.\n\nDefinición 4.5 (Proceso de renovación) Sean \\(\\tau_1,\\tau_2,\\tau_3,\\ldots\\) variables aleatorias no negativas (es decir, \\(\\tau_n\\ge 0\\)), independientes, e idénticamente distribuidas, de modo que \\(\\mathbb{P}(\\tau_n=0)&lt;1\\) para todo \\(n\\). Llamamos proceso de renovación con tiempos entre llegadas \\(\\tau_1,\\tau_2,\\tau_3,\\ldots\\) al proceso estocástico \\((N_t)_{t\\in[0,\\infty)}\\) verificando \\(N_0=0\\) y\n\\[\nN_t=\\max\\{n\\colon T_n\\le t\\},\n\\tag{4.4}\\]\ndonde \\(T_n=\\tau_1+\\tau_2+\\ldots+\\tau_n\\).\n\nAl igual que con los procesos de Poisson interpretamos \\(\\tau_1,\\tau_2,\\tau_3,\\ldots\\) como los tiempos entre llegadas, por lo que \\(T_n=\\tau_1+\\tau_3+\\ldots+\\tau_n\\) es el tiempo de la n-ésima llegada. La condición (Ecuación 4.4) implica que si \\(N_t=n\\), entonces\n\\[\nT_{n}\\le t &lt; T_{n+1}.\n\\]\n\n\n\n\n\n\nEjemplo\n\n\n\nImaginemos una máquina que funciona durante un tiempo \\(\\alpha\\) y, tras fallar, tarda un tiempo \\(\\beta\\) en ser reparada. Si la máquina falla y es reparada reiteradas veces, obtendremos variables aleatorias independientes \\(\\alpha_1,\\beta_1,\\alpha_2,\\beta_2,\\alpha_3,\\beta_3,\\ldots\\) con los correspondientes tiempos de fallo y reparación. El tiempo total de cada ciclo donde la máquina empieza a funcionar, falla y es reparada viene dado por \\(\\tau_i=\\alpha_i+\\beta_i\\). Las variables \\(\\tau_1,\\tau_2,\\tau_3,\\ldots\\) son i.i.d.. Podemos, por tanto, considerar el proceso de renovación \\((N_t)_{t\\in [0,\\infty)}\\) contando el número total de ciclos hasta tiempo \\(t\\).\n\n\nUna importante propiedad de los procesos de renovación es la siguiente versión de la ley de los grandes números.\n\nTeorema 4.4 (Ley de los grandes números para procesos de renovación) Sea \\((N_t)_{t\\in[0,\\infty)}\\) un proceso de renovación con tiempos entre llegadas \\(\\tau_1,\\tau_2,\\tau_3,\\ldots\\). Si \\(\\mathbb{E}(\\tau_i)=\\mu\\), entonces con probabilidad 1 se verifica que\n\\[\n\\frac{N_t}{t}\\to \\frac{1}{\\mu}\\quad\\mbox{ cuando }t\\to\\infty.\n\\]\n\nLa interpretación del anterior resultado es sencilla. Si el tiempo medio entre llegadas (ciclos consecutivos) de un proceso de renovación es de \\(\\mu\\) horas, entonces en el largo plazo se producirán \\(1/\\mu\\) llegadas (ciclos) por hora. En el caso de un proceso de Poisson con tasa \\(\\lambda\\) se tendrá que\n\\[\n\\frac{N_t}{t}\\to \\lambda\\quad\\mbox{ cuando }t\\to\\infty,\n\\]\nya que los tiempos entre llegadas tienen media \\(1/\\lambda\\).\nLa demostración del anterior resultado se basa en la ley fuerte de los grandes números la cual recordamos a continuación.\n\nLema 4.1 (Ley fuerte de los grandes números) Sean \\(\\tau_1,\\tau_2,\\tau_3,\\ldots\\) variables aleatorias i.i.d. con \\(\\mathbb{E}(\\tau_i)=\\mu\\). Entonces con probabilidad 1 se verifica que\n\\[\n\\frac{T_n}{n}\\to \\mu\\quad\\mbox{ cuando }n\\to\\infty,\n\\]\ndonde \\(T_n=\\tau_1+\\tau_2+\\ldots+\\tau_n\\) para cada \\(n\\in\\mathbb{N}\\).\n\nA continuación damos la demostración de la ley de los grandes números para procesos de renovación.\nDemostración del Teorema Teorema 4.4.\nPara cada \\(n\\in\\mathbb{N}\\), sea \\(T_n=\\tau_1+\\tau_2+\\ldots+\\tau_n\\). Como las variables \\(\\tau_1,\\tau_2,\\tau_3,\\ldots\\) son i.i.d. con media \\(\\mu\\), la ley fuerte de los grandes números nos dice que, con probabilidad 1, se verifica\n\\[\n\\frac{T_n}{n}\\to \\mu\\quad\\mbox{ cuando }n\\to\\infty.\n\\tag{4.5}\\]\nAhora, por definición de proceso de renovación tenemos que\n\\[\nT_{N_t}\\le t &lt; T_{N_t+1}.\n\\]\nDividiendo entre \\(N_t\\) tenemos que\n\\[\n\\frac{T_{N_t}}{N_t}\\le \\frac{t}{N_t} &lt; \\frac{T_{N_t+1}}{N_t}.\n\\]\nDe ahí se sigue que\n\\[\n\\frac{T_{N_t}}{N_t}\\le \\frac{t}{N_t} &lt; \\frac{T_{N_t+1}}{N_t+1}\\frac{N_t+1}{N_t}.\n\\tag{4.6}\\]\nPuesto que las trayectorias de \\(N_t\\) son crecientes, dando infinitos saltos de longitud 1, tendremos que \\(\\lim_{t\\to \\infty}N_t=\\infty\\). Como consecuencia de (Ecuación 4.5) se verifica, con probabilidad 1, que\n\\[\n\\lim_{t\\to \\infty}\\frac{T_{N_t}}{N_t}=\\mu.\n\\]\nPor las misma razones también se cumplirá, con probabilidad 1, que\n\\[\n\\lim_{t\\to \\infty} \\frac{T_{N_t+1}}{N_t+1}\\frac{N_t+1}{N_t}=\\mu.\n\\]\nFinalmente, tomando límites en (Ecuación 4.6) cuando \\(t\\to\\infty\\), y teniendo en cuenta lo anterior, llegamos a la conclusión deseada, ya que \\(t/N_t\\) se encuentra, con probabilidad 1, entre dos sucesiones las cuales convergen a \\(\\mu\\). \\(\\square\\)\nVolvamos al ejemplo donde una máquina se estropea y es reparada reiteradas veces. Supongamos que, de media, la máquina tarda una hora en estropearse, y quince minutos en ser reparada. Supongamos, además, que cada tiempo de fallo \\(\\alpha_i\\) y cada tiempo de reparación \\(\\beta_i\\) siguen distribuciones exponenciales. De este modo, \\(\\alpha_i\\sim {\\rm Exp}(1)\\) y \\(\\beta_i\\sim {\\rm Exp}(4)\\). El proceso de renovación resultante puede ser simulado fácilmente en R.\n\n# Fijemos los valores de los parámetros\n\nlambda_1 &lt;- 1  # tasa de fallo\n\nlambda_2 &lt;- 4  # tasa de reparación\n\nT &lt;- 10      # Intervalo de tiempo en el que observamos el proceso\n\n# Simulación de los tiempos entre llegadas\n\nset.seed(13)\n\ntau &lt;- NULL\n\ni &lt;- 1\n\nwhile(sum(tau) &lt; T){\n\n  alpha &lt;- rexp(n = 1, rate = lambda_1)\n\n  beta &lt;- rexp(n = 1, rate = lambda_2)\n\n  tau[i] &lt;-  alpha + beta\n\n  i &lt;- i+1\n\n}\n\n# Calculamos los valores del proceso de renovación\n\ntiempos &lt;- c(0,cumsum(tau))\n\nN &lt;- 0:length(tau)\n\n# Dibujamos la trayectoria\n\nplot(tiempos, N, type = \"s\",\n\n     xlab = \"Tiempo\", ylab = \"Ciclos\", xlim=c(0, 10))\n\n\n\n\nSimulación del proceso de renovación donde una máquina se estropea y repara reiteradamente\n\n\n\n\nEl tiempo medio de cada ciclo es \\(\\mathbb{E}(\\tau_i)=\\mathbb{E}(\\alpha_i)+\\mathbb{E}(\\beta_i)=1+1/4=5/4\\). Por tanto, la ley de los grandes números para procesos de renovación nos dice que\n\\[\n\\frac{N_t}{t}\\to \\frac{4}{5}\\quad\\mbox{ cuando }t\\to\\infty.\n\\]\nVamos a comprobar dicho resultado simulando una trayectoria a un plazo elevado de tiempo (por ejemplo, \\(T=1000\\)), y dibujando la gráfica del cociente \\(N_t/t\\).\n\n# Fijemos los valores de los parámetros\n\nlambda_1 &lt;- 1  # tasa de fallo\n\nlambda_2 &lt;- 4  # tasa de reparación\n\nT &lt;- 1000      # Intervalo de tiempo en el que observamos el proceso\n\n# Simulación de los tiempos entre llegadas\n\nset.seed(13)\n\ntau &lt;- NULL\n\ni &lt;- 1\n\nwhile(sum(tau) &lt; T){\n\n  alpha &lt;- rexp(n = 1, rate = lambda_1)\n\n  beta &lt;- rexp(n = 1, rate = lambda_2)\n\n  tau[i] &lt;-  alpha + beta\n\n  i &lt;- i+1\n\n}\n\ntiempos &lt;- c(0,cumsum(tau))\n\nN &lt;- 0:length(tau)\n\ncociente &lt;- N / tiempos\n\n# Dibujamos la trayectoria\n\nplot(tiempos, cociente, type = \"S\",\n\n     xlab = \"Tiempo\", ylab = \"N_t/t\", xlim=c(0, 1000))\n\n# Dibujamos una línea horizontal a la altura de la inversa de la media\n\nabline(h=4/5, col=\"blue\")\n\n\n\n\nEl cociente entre el proceso de renovación y el tiempo se va aproximando a una constante, debido a la ley de los grandes números"
  },
  {
    "objectID": "Tema4.html#introducción",
    "href": "Tema4.html#introducción",
    "title": "5  Tema 4. Conceptos básicos en series temporales",
    "section": "5.1 Introducción",
    "text": "5.1 Introducción\nEl estudio de series temporales es fundamental para el proceso de predicción (Forecasting), que consiste en anticipar eventos futuros basándose en datos históricos y patrones identificables. Esta disciplina es esencial en diversos campos, desde la economía hasta la ingeniería, y su aplicación es vital para la toma de decisiones informadas en el ámbito empresarial y gubernamental.\n¿Qué se puede predecir?\nLa predicción se utiliza en múltiples situaciones de la vida cotidiana y la industria, como son la gestión de inventarios, la planificación de la producción, la gestión energética o la asignación de personal. La capacidad de predecir con precisión depende de varios factores, entre ellos la comprensión de las causas subyacentes, la disponibilidad de datos históricos, la consistencia del comportamiento pasado y futuro, y el impacto de las predicciones en los propios eventos. Por ejemplo, las predicciones a corto plazo de la demanda eléctrica residencial suelen ser precisas debido a la estabilidad de los factores que la afectan y la abundancia de datos históricos relevantes.\nDiferencia entre predicciones, objetivos y planificación\nEs crucial diferenciar entre predicciones, objetivos y planificación. Predecir implica anticipar el futuro con la mayor precisión posible mediante el análisis de datos históricos y el conocimiento de eventos futuros. Los objetivos son metas específicas que deben alinearse con las predicciones y servir como guía para la planificación. La planificación involucra diseñar estrategias y acciones basadas en las predicciones para alcanzar los objetivos establecidos.\nDeterminación de qué predecir\nDecidir qué predecir es un paso crucial. Puede involucrar observaciones individuales o datos agregados. Es importante definir el horizonte de predicción, que puede ser a corto plazo (una hora, o unos días), a medio plazo (por ejemplo, un mes) o a largo plazo (por ejemplo, un año). Además, se debe determinar la frecuencia de las predicciones, que puede ser diaria, semanal, mensual o anual, según las necesidades de los usuarios de las predicciones. La recolección y organización de datos relevantes y precisos es esencial para asegurar la calidad de las predicciones.\nDatos y métodos de predicción\nLos métodos cuantitativos de predicción son útiles cuando hay datos numéricos disponibles y se espera que los patrones pasados continúen en el futuro. Los datos de series temporales, como las ventas trimestrales o la demanda horaria de electricidad, son fundamentales en estos análisis. La descomposición de datos permite estudiar tendencias y patrones estacionales. Entre los métodos más utilizados se encuentran el análisis clásico de series, el suavizamiento exponencial y los modelos ARIMA, efectivos para capturar y predecir patrones en los datos históricos. Los modelos explicativos, que emplean variables predictoras, y los modelos mixtos, que combinan características de varios enfoques, pueden mejorar la precisión y la utilidad de las predicciones.\nPasos básicos en Forecasting\nLas etapas a tener en cuenta en un problema de predicciones son:\n\nDefinición del problema: Entender el uso y los usuarios de las predicciones para asegurar que se adapten a sus necesidades específicas.\nRecolección de información: Obtener datos estadísticos relevantes y utilizar la experiencia de expertos en el campo.\nAnálisis preliminar: Graficar y analizar datos para identificar patrones, tendencias y estacionalidad, lo cual ayuda en la selección del modelo de predicción adecuado.\nElección y ajuste de modelos: Seleccionar y ajustar el método de predicción más apropiado basado en los datos disponibles y la situación específica.\nUso de las predicciones: Aplicar los resultados en la planificación y toma de decisiones, alineando las acciones con las expectativas futuras y los objetivos de la organización o empresa."
  },
  {
    "objectID": "Tema4.html#definición-de-serie-temporal.-gráficos",
    "href": "Tema4.html#definición-de-serie-temporal.-gráficos",
    "title": "5  Tema 4. Conceptos básicos en series temporales",
    "section": "5.2 Definición de serie temporal. Gráficos",
    "text": "5.2 Definición de serie temporal. Gráficos\nUna de las técnica más importante para hacer inferencias sobre el futuro con base en lo ocurrido en el pasado, es el análisis de series de tiempo.\nDada una serie temporal, nuestros objetivos principales serán: describir el comportamiento de la serie, investigar el mecanismo generador de la serie temporal y buscar posibles patrones temporales que permitan sobrepasar la incertidumbre del futuro.\nSe suele hablar del estudio clásico o descriptivo de las series temporales para referirse a la metodología que se ha venido empleando desde la segunda mitad del siglo XIX. A pesar de sus limitaciones, los métodos clásicos se siguen usando por su sencillez y simplificación. En la década de los 60 se plantearon métodos de previsión alternativos a los clásicos que suplen varias de sus limitaciones, como son los métodos de alisado exponencial, y a principios de los 70 aparece un nuevo enfoque, debido a los estadísticos Box y Jenkins, para los modelos univariantes de series temporales.\n\nDefinición 5.1 (Serie temporal) Llamamos serie temporal a un conjunto de mediciones de cierto fenómeno o experimento registradas secuencialmente en el tiempo. Estas observaciones suelen denotarse por:\n\\[\n\\left\\{ x_{t_1},x_{t_2},...,x_{t_n}\\right\\} \\quad \\text{con }%\n\\{t_1&lt;t_2&lt;...&lt;t_n\\}=\\mathbb{T}\\subset \\Bbb{R}\n\\] donde \\(x_{t_i}\\) representa el valor, en el instante \\(t_i\\), de una variable aleatoria que evoluciona con el tiempo.\n\n\n\n\n\n\n\nObservación\n\n\n\nTeniendo en cuenta la definición anterior, una serie temporal puede verse también como una realización (o trayectoria) de un proceso estocástico \\((X_t)_{t\\in\\mathbb{T}}\\).\n\n\nEn muchas áreas de conocimiento, las observaciones de interés son obtenidas en instantes sucesivos del tiempo. Por ejemplo, cada hora, cada día, datos mensuales, trimestrales, semestrales o bien registradas por algún aparato de medición en forma continua.\n\nDe una manera sencilla, podemos decir que si \\(\\mathbb{T}\\subset\\Bbb{Z}\\) es un conjunto contable, se dice que la serie es de tiempo discreto, mientras que si \\(T\\subset\\Bbb{R}\\) es un intervalo real, se dice que la serie es de tiempo continuo.\nCuando \\(t_{i+1}-t_i=k\\), para todo \\(i=1,...,n-1\\), se dice que la serie es equiespaciada; en caso contrario será no equiespaciada.\n\nEn adelante, trabajaremos por comodidad con series de tiempo equiespaciadas. Por tanto, se denotarán de la siguiente forma:\n\\[\n\\left\\{ x_{t_1},x_{t_2},...,x_{t_n}\\right\\} =\\left\\{ x_1,x_2,...,x_n\\right\\}.\n\\]\nEl primer paso en el análisis de cualquier serie de tiempo consiste en representarla gráficamente (gráfico temporal). En la representación gráfica de las series temporales se utilizan los ejes cartesianos. En el eje de abscisas se representa el tiempo \\(t,\\) y en el eje de ordenadas, los valores de la magnitud observada \\(x_t\\). Se obtiene así una nube de puntos \\((t,x_t)\\) que, unidos por segmentos, proporcionan una visión dinámica de la evolución de la variable a lo largo del tiempo.\nVeamos algunos ejemplos de series de datos incluidos en R. La primera, LakeHuron, contiene las medidas anuales del nivel del lago Huron (en pies), en el tramo 1875-1972. Observamos una tendencia decreciente que parece estabilizarse en el tramo final. La segunda serie de datos, AirPassengers, contiene el los viajeros mensuales en aerolíneas internacionales, en el tramo 1949-1960. Observamos un patrón periódico que se repite a lo largo de la serie, así como tendencia creciente. La tercera, EuStockMarkets, contiene los precios diarios al cierre de 4 índices stock europeos (DAX, SMI, CAC y FTSE), en el tramo 1991-1998. Observamos que las cuatro series presentan un patrón de comportamiento similar, con tendencia creciente y picos de crecimiento en los mismos tramos temporales.\n\npar(mfrow=c(1,2))\nts.plot(LakeHuron, \n        gpars = list(xlab = \"Year\", \n                   ylab = \"Level LakeHuron in feet\", \n                   lwd = 1.5))\nts.plot(AirPassengers, \n        gpars = list(xlab = \"Month & Year\", \n                   ylab = \"Thousand of passengers\", \n                   lwd = 1.5))\n\n\n\n\n\nts.plot(EuStockMarkets, \n        gpars = list(xlab = \"Time\", \n                   ylab = \"Daily closing price\", \n                   col = rainbow(4), \n                   lty = c(1:4)))\n\n\n\n\nEl gráfico de la serie permitirá:\n\nDetectar outliers (datos atípicos): se refiere a puntos de la serie que se escapan de lo “normal”. Un outlier puede corresponderse con un error de medición, o bien con un valor real del fenómeno, el cual a su vez puede tener o no influencia destacada en el modelo propuesto. Conviene identificar los outliers para determinar si deben eliminarse, reemplazarse por otro valor, o bien mantenerlos en el análisis.\nDetectar estacionalidad: la variación estacional representa un movimiento periódico de la serie de tiempo. Cada estación puede corresponder con un trimestre, un mes, un día, etc.\nDetectar tendencias: la tendencia representa el comportamiento predominante de la serie una vez eliminada la estacionalidad. Esta puede ser definida vagamente como la curva maestra que muestra el cambio de la media a lo largo del tiempo."
  },
  {
    "objectID": "Tema4.html#medidas-para-evaluación-de-predicciones",
    "href": "Tema4.html#medidas-para-evaluación-de-predicciones",
    "title": "5  Tema 4. Conceptos básicos en series temporales",
    "section": "5.3 Medidas para evaluación de predicciones",
    "text": "5.3 Medidas para evaluación de predicciones\nEn esta sección introduciremos conceptos y alguna notación referidos al contexto de predicción con series temporales.\nEn primer lugar, debemos destacar que para que tenga sentido la realización de predicciones se supondrá que los datos recopilados a lo largo del tiempo se han tomado siempre en las mismas magnitudes y que la serie presenta cierta estabilidad en la estructura del fenómeno estudiado.\nEn el análisis clásico, las predicciones futuras se realizan teniendo en cuenta únicamente el valor de la serie para instantes pasados. Si diponemos de \\(T\\) observaciones de la serie en estudio, la información disponible viene dada por:\n\\[\nx_1,x_2,...,x_T.\n\\]\nDada esta información, la predicción de la variable en estudio en el instante siguiente \\(T+1\\) se denotará por:\n\\[\\widehat{x}_{T+1}\\]\ny en un instante posterior cualquiera \\(T+m\\) será:\n\\[\\widehat{x}_{T+m}\\]\nAsí, el error de predicción vendrá dado por la diferencia entre el valor observado de la serie y la predicción:\n\\[\ne_{T+1}=x_{T+1}-\\widehat{x}_{T+1}\n\\]\nComentar que, al igual que sucede en muchos procesos de inferencia, se pueden realizar predicciones puntuales y predicciones por intervalos de confianza para las observaciones futuras. En la mayoría de los casos, nos limitaremos a proporcionar estimaciones puntuales.\nPara poder comparar diversos procedimientos de predicción, es decir, para responder a la pregunta ¿qué método es mejor para predecir esta serie?, necesitamos disponer de algún criterio que nos permita evaluar las predicciones realizadas.\nComo primer paso, podemos comentar la existencia de algunos métodos extremadamente básicos, denominados métodos ingenuos, que sirven de referencia en la comparación de predicciones. Es decir, las predicciones que se obtienen con cualquier procedimiento suelen compararse con las predicciones que se obtendrían con algún método ingenuo. Si el método ingenuo proporciona mejores predicciones (menores errores de predicción), esto será indicativo de que el método usado no es el adecuado y conviene probar con otro.\nDos ejemplos de métodos ingenuos que se utilizan como referencia son:\n\nMétodo ingenuo I: La predicción para el próximo instante es igual a la observación actual (último valor observado).\n\n\\[\n\\widehat{x}_{t+1}=x_t\n\\]\n\nMétodo ingenuo II: La predicción para el próximo instante es igual a la observación actual más el último incremento observado.\n\n\\[\n\\widehat{x}_{t+1}=x_t+(x_t-x_{t-1})\n\\]\nComo segunda opción para medir la capacidad predictiva de un modelo, se suelen calcular las siguientes medidas. Si se dispone de \\(T\\) observaciones y se han realizado predicciones desde el instante 1, las medidas son:\n\nRMSE (la raíz cuadrada del error cuadrático medio):\n\n\\[\n\\mbox{RMSE}=\\sqrt{\\frac{\\sum\\limits_{t=1}^Te_{t}^2}{T}}\n\\]\n\nMAE (el error absoluto medio):\n\n\\[\n\\mbox{MAE}=\\frac{\\sum\\limits_{t=1}^T\\left| e_{t}\\right| }{T}\n\\]\nEvidentemente, cuanto menores sean estas medidas mayor será la capacidad predictiva del modelo. Conviene indicar la existencia de otras medidas para evaluar predicciones, además de las vistas aquí.\nPor último destacaremos que para que un modelo predictivo sea adecuado no basta con que los errores de predicción sean pequeños (valores pequeños de RMSE y de MAE), sino que además pretendemos describir completamente el comportamiento sistemático de la serie (la parte determinista), de manera que la parte que queda sin describir (los errores de predicción) deberían ser un ruido blanco."
  },
  {
    "objectID": "Tema4.html#componentes-de-una-serie-temporal-y-esquemas-de-integración",
    "href": "Tema4.html#componentes-de-una-serie-temporal-y-esquemas-de-integración",
    "title": "5  Tema 4. Conceptos básicos en series temporales",
    "section": "5.4 Componentes de una serie temporal y esquemas de integración",
    "text": "5.4 Componentes de una serie temporal y esquemas de integración\nEl principal fin del estudio de series temporales es realizar predicciones. Un punto muy importante a tener en cuenta en este contexto es la cantidad de información contenida en una serie temporal.\nPor ejemplo, podemos considerar la serie temporal correspondiente a la hora de salida del sol (medida todos los días durante 10 años). Con la serie de observaciones pasadas podemos realizar una buena predicción para días futuros, es decir, la serie contiene mucha información relevante para predecir el futuro. Consideremos por otra parte la serie temporal correspondiente al número premiado del sorteo de la lotería (medida todos los sábados durante 20 años). En este caso las observaciones pasadas no nos permiten realizar una buena predicción del fenómeno en el futuro, es decir, la serie contiene poca información relevante para predecir el futuro.\nPodríamos decir que la primera serie es prácticamente determinista mientras que la segunda es totalmente aleatoria. En general, las series de tiempo contienen una parte determinista (permiten realizar predicciones) y otra parte aleatoria (perturbación impredecible).\nEn el Análisis Clásico se supone que una serie temporal, \\(\\{x_t\\}_{t=1,...,n},\\) se puede descomponer en todas o algunas de las siguientes componentes:\n\nComponente de Tendencia \\((T_t)\\)\nComponente de Ciclo \\((C_t)\\)\nComponente de Estacionalidad \\((S_t)\\)\nComponente Irregular \\((I_t)\\),\n\ny que la serie de tiempo se obtiene como una función de sus componentes:\n\\[\nx_t=f\\left( T_t,C_t,S_t,I_t\\right)\n\\] Veamos a continuación el significado de cada una de las componentes, aunque resulta complicado dar una definición exacta de cada una de ellas.\n\nComponente de Tendencia (Trend): Es la componente que representa la evolución a largo plazo de la serie, es decir, la curva maestra de evolución del fenómeno en estudio. Las variaciones de la tendencia de una serie pueden deberse a diversos motivos.\nComponente de Ciclo (Cycle): El factor cíclico refleja movimientos oscilatorios por encima y por debajo de la tendencia a largo plazo. La duración de un ciclo se suele medir desde un pico al siguiente pico de la serie suavizada (o desde un valle al siguiente valle). Se entiende que el periodo de cada ciclo es siempre superior al año. A veces se confunde con la componente estacional. La diferencia principal es que las fluctuaciones de los ciclos no tienen frecuencia fija, y suelen asociarse a aspectos económicos, mientras que las fluctuaciones de la componente estacional tienen frecuencia fija y se asocian con aspectos del calendario.\n\n\n\n\n\n\n\nObservación\n\n\n\nEn general, las componentes de tendencia y ciclo son muy difíciles de separar, de manera que se suelen fusionar en una única componente denominada Tendencia-Ciclo. En adelante, nosotros trabajaremos con ambas componentes fusionadas y usaremos la notación \\(T_t\\) y hablaremos de Tendencia para referirnos a la componente Tendencia-Ciclo.\n\n\n\nComponente de Estacionalidad (Seasonal): La componente estacional recoge el comportamiento periódico (repetitivo) de la serie. Las razones de la estacionalidad suelen ser de tipo físico-natural (tiempo meteorológico, ciclos biológicos, etc) y de tipo institucional (vacaciones, horarios comerciales, etc.). Es decir, aparece debido al efecto del calendario.\n\nEn general, la estacionalidad se refiere a las oscilaciones de una serie temporal que se completan dentro de un año y que se repiten en años sucesivos. Por tanto, el periodo de esta componente suele ser menor o igual a un año. Por ejemplo, si disponemos de datos mensuales podemos tener estacionalidad con periodo 12 meses (un año), si disponemos de datos trimestrales podemos tener estacionalidad con periodo 4 trimestres (un año). Si disponemos de datos diarios, podemos tener estacionalidad con periodo 7 días (una semana), si disponemos de datos cada hora, podemos tener estacionalidad con periodo 24 horas (un día), etc. El periodo de la componente estacional hace referencia al número de datos que conforman la parte repetitiva de la serie.\nEn Análisis Clásico, se supone que la que componente estacional (patrón periódico) se repite de forma fija a lo largo de toda la serie. Por tanto, si el periodo es \\(L\\), diremos que la componente estacional tiene \\(L\\) estaciones que podemos denotar por \\(\\{h_1, h_2, ..., h_L \\}\\) y buscamos estimar un valor correspondiente a cada estación.\nPor ejemplo, si se trata de datos mensuales, probablemente observaremos en la serie temporal un patrón repetitivo cada año (cada 12 datos). Tendremos entonces que el periodo es \\(L=12\\), cada mes del año sería una estación (\\(h_1=enero\\), \\(h_2=febrero\\), …\\(h_{12}=diciembre\\)) y por tanto estimaremos un valor que se repetirá para todos los eneros, un valor que se repetirá para todos los febreros, …, un valor que se repetirá para todos los diciembres. Si se trata de datos diarios (por ejemplo, ingresos por ventas de unos grandes almacenes), observaremos en la serie temporal un patrón repetitivo cada semana (cada 7 datos). Tendremos entonces que el periodo es \\(L=7\\), cada día sería una estación (\\(h_1=lunes\\), \\(h_2=martes\\),…, \\(h_7=domingo\\)) y por tanto estimaremos un valor que se repetirá para todos los lunes, un valor que se repetirá para todos los martes, …, un valor que se repetirá para todos los domingos.\n\nComponente Irregular (Reminder): Esta componente viene dada por las variaciones de la serie que no están recogidas en las demás componentes. La idea es que recoja la perturbación aleatoria pura de la serie, es decir, la parte impredecible de la serie. Lo ideal es que se corresponda con un ruido blanco, de manera que toda la parte determinista de la serie quede recogida en las componentes Tendencia-Ciclo y Estacional.\n\nComo ya hemos indicado, en el análisis clásico se supone que el valor que toma la serie \\(\\{x_t\\}_t\\) en cada instante se puede expresar como una función del valor correspondientes a sus componentes en dicho instante:\n\\[\nx_t=f\\left( T_t,S_t,I_t\\right) ,\n\\]\ndonde \\(T_t\\) representa la Tendencia-Ciclo. Conviene señalar que en una serie temporal no tienen por qué estar presentes todas las componentes.\nLos esquemas más utilizados para describir la forma en que las componentes se integran para dar lugar a la serie son el esquema aditivo y el multiplicativo.\n\nEsquema aditivo:\nSegún este esquema, el valor de la serie en cualquier instante se obtiene como suma de los valores correspondientes a sus componentes en dicho instante:\n\\[\n\\boxed{x_t = T_t + S_t + I_t}\n\\]\nEsquema multiplicativo:\nSegún este esquema, el valor de la serie en cualquier instante se obtiene como producto de los valores correspondientes a sus componentes en dicho instante:\n\\[\n\\boxed{x_t = T_t \\times S_t \\times I_t}\n\\]\nObsérvese que, al tomar logaritmos neperianos, el esquema multiplicativo se transforma en aditivo.\nAunque por su sencillez los esquemas más utilizados son los dos anteriores, también suelen utilizarse los esquemas mixtos, donde algunas componentes se integran de forma multiplicativa y otras de forma aditiva. Un ejemplo de esquema mixto sería:\n\n\\[\nx_t=T_t\\times S_t+I_t\n\\] ¿Esquema aditivo o multiplicativo? Para determinar si las componentes de la serie se combinan de forma aditiva o multiplicativa, se pueden usar varias herramientas:\n\nInspección visual: En un esquema aditivo, la representación gráfica de la serie mostrará una componente estacional aproximadamente estable en todo momento, independientemente de los valores que tome la tendencia (nivel de la serie). Sin embargo, en un esquema multiplicativo, la componente estacional se amplifica cuando la serie se mueve en niveles más altos.\nGráfico de desviaciones típicas frente a medias: Este gráfico consiste en calcular, para cada tramo periódico (por ejemplo, un año), tanto la desviación típica como la media de los valores de la serie. En un esquema aditivo, las desviaciones típicas se mantienen aproximadamente constantes sea cual sea el valor de la media, mientras que en el esquema multiplicativo, las desviaciones típicas aumentan cuando crece la media.\n\nA continuación mostramos un ejemplo de esquema multiplicativo (figura de la izquierda) y un esquema aditivo (figura de la derecha).\n\npar(mfrow=c(1,2))\nts.plot(AirPassengers, lwd = 1.5)\nts.plot(log(AirPassengers), lwd = 1.5)"
  },
  {
    "objectID": "Tema4.html#diferenciación-de-una-serie-temporal-y-medias-móviles",
    "href": "Tema4.html#diferenciación-de-una-serie-temporal-y-medias-móviles",
    "title": "5  Tema 4. Conceptos básicos en series temporales",
    "section": "5.5 Diferenciación de una serie temporal y medias móviles",
    "text": "5.5 Diferenciación de una serie temporal y medias móviles\nLa representación gráfica de la serie temporal nos puede ayudar a decidir el tipo de tendencia de la serie, pero a veces no es tan sencillo. Un método que permite determinar el tipo de tendencia de una serie y a su vez eliminarla consiste en tomar diferencias.\nDiferenciación de una serie\n\nDefinición 5.2 (Diferencia de primer orden) Dada una serie temporal \\(\\{x_t\\}_{t=1,...,n}\\) , se define su diferencia de primer orden como la serie que resulta de restar a cada observación, la observación anterior:\n\\[\n\\Delta x_t=x_t-x_{t-1}\n\\]\n\nDe manera análoga, se puede definir la diferencia de orden 2 de la serie como:\n\\[\n\\Delta ^2x_t=\\Delta \\left( x_t-x_{t-1}\\right) =\\left( x_t-x_{t-1}\\right)\n-\\left( x_{t-1}-x_{t-2}\\right) =x_t-2x_{t-1}+x_{t-2}\n\\]\nasí como la diferencia de orden k, en general.\n\n\n\n\n\n\nObservación\n\n\n\nAl tomar diferencias de orden uno, la serie resultante tiene un dato menos (se pierde el primer dato). Si se toman diferencias de orden dos, la serie resultante tiene dos datos menos (se pierden los dos primeros). En general, al tomar diferencias de orden \\(k\\), la serie resultante tiene \\(k\\) datos menos (se pierden los \\(k\\) primeros datos).\n\n\n\nSi la tendencia es de tipo lineal, ésta se puede eliminar tomando diferencias de orden uno:\n\\[\n\\begin{aligned}\nx_t &= b_0 + b_1 \\cdot t + \\varepsilon_t \\quad \\text{con} \\quad \\varepsilon_t \\sim \\text{ruido blanco} \\\\\n&\\Rightarrow \\; \\Delta x_t = x_t - x_{t-1} = (b_0 + b_1 t + \\varepsilon_t) - (b_0 + b_1 (t-1) + \\varepsilon_{t-1}) \\\\\n&\\Rightarrow \\; \\Delta x_t = b_1 + (\\varepsilon_t - \\varepsilon_{t-1}) = b_1 + \\tilde{\\varepsilon}_t\n\\end{aligned}\n\\]\nEs decir, la serie obtenida al tomar diferencias de orden uno es una constante (\\(b_1\\)) más un ruido blanco (\\(\\tilde{\\varepsilon}_t\\)).\nEn general, si la tendencia es de tipo polinómico de orden \\(k\\), ésta se puede eliminar tomando diferencias de orden \\(k\\).\n\nVeamos un ejemplo del efecto de tomar diferencias de orden 1 sobre la serie de precios del índice DAX y sobre la serie de pasajeros:\n\nDAX_index &lt;- EuStockMarkets[ , 1]\npar(mfrow = c(2,2))\nts.plot(DAX_index)\nts.plot(diff(DAX_index, differences = 1))\nts.plot(AirPassengers)\nts.plot(diff(AirPassengers, differences = 1))\n\n\n\n\n\nSi la tendencia es de tipo exponencial, ésta se puede eliminar tomando diferencias en el logaritmo de la serie:\n\\[\n\\begin{aligned}\nx_t &= e^{b_0 + b_1 \\cdot t} \\times e^{\\varepsilon_t}\n\\;\\Rightarrow\\;\n\\ln(x_t) = b_0 + b_1 \\cdot t + \\varepsilon_t \\\\[6pt]\n&\\Rightarrow\\;\n\\Delta \\ln(x_t) = \\ln(x_t) - \\ln(x_{t-1})\n= b_1 + \\tilde{\\varepsilon}_t\n\\end{aligned}\n\\]\nPor otra parte, la diferencia de logaritmos coincide con el logaritmo del cociente, así que:\n\\[\n\\Rightarrow\\;\n\\Delta \\ln(x_t)\n= \\ln(x_t) - \\ln(x_{t-1})\n= \\ln\\!\\left(\\frac{x_t}{x_{t-1}}\\right)\n\\]\nUsando el desarrollo de Taylor para el logaritmo se tiene que:\n\\[\n\\Delta \\ln(x_t)\n= \\ln\\!\\left(\\frac{x_t}{x_{t-1}}\\right)\n\\simeq\n\\frac{x_t - x_{t-1}}{x_{t-1}}\n\\quad \\text{(Tasa de variación relativa)}\n\\]\nPor tanto, si la tendencia es de tipo exponencial, las tasas de variación relativa oscilarán alrededor de un valor constante.\nMedias Móviles\n\nOtro método para ayudar a identificar la tendencia de una serie (análisis descriptivo de la serie), son las medias móviles, aunque también puede usarse para realizar predicciones y para eliminar la componente estacional de una serie.\nEste método consiste en realizar, para cada instante de tiempo \\(t\\), la media de unas cuantas observaciones. Necesitamos determinar cuántas observaciones se usarán para el cálculo de la media móvil (longitud u orden de la media móvil).\nLas medias móviles eliminan las irregularidades de la serie observada, es decir, se produce un suavizado de la serie eliminando o atenuando el efecto de la componente irregular, consiguiendo así identificar la trayectoria que sigue la tendencia. Además, cuanto mayor sea el orden de la media móvil, más se suaviza la serie. El problema de determinar el orden de la media móvil no es tan inmediato porque, si es demasiado pequeño, puede que no elimine las irregularidades, y si es demasiado grande, podemos perder información sobre cambios de la serie (en el caso extremo tendríamos siempre una tendencia constante).\nUn aspecto importante de este método frente al ajuste de la tendencia por mínimos cuadrados es que en este caso el análisis de la tendencia se realiza desde un enfoque local, es decir, la trayectoria de la tendencia se obtiene localmente utilizando algunas observaciones de la serie (no todas). En este sentido, este método permitirá obtener mejores predicciones a corto plazo que si ajustamos la tendencia por mínimos cuadrados. Por contra, no dispondremos de un modelo matemático que nos permita describir la serie y realizar predicciones a largo plazo.\nPodemos distinguir dos tipos: medias móviles centradas y medias móviles asimétricas.\nLas medias móviles centradas revisten mayor interés, se suelen utilizar para describir la tendencia de la serie de forma más flexible y adecuada que usando mínimos cuadrados.\n\nDefinición 5.3 (Media móvil centrada de orden impar) Dada una serie temporal \\(\\{x_t\\}_{t=1,...,n}\\), se define su media móvil centrada de orden \\((2p+1)\\) como la serie obtenida mediante la siguiente expresión:\n\\[\nMM(2p+1)_t=\\frac{x_{t-p}+x_{t-p+1}+...+x_t+...+x_{t+p-1}+x_{t+p}}{2p+1}\n\\]\nes decir, en cada instante \\(t\\), se calcula la media usando las \\(p\\) observaciones anteriores, las \\(p\\) observaciones posteriores y la propia observación en el instante \\(t.\\)\n\nSi el orden de la media móvil es par, entonces debemos realizar dos veces medias móviles para conseguir que sea centrada.\n\nDefinición 5.4 (Media móvil centrada de orden par) Dada una serie temporal \\(\\{x_t\\}_{t=1,...,n}\\), se define su media móvil centrada de orden \\((2p)\\) como la serie obtenida mediante la siguiente expresión:\n\\[\nMM(2p)_t=\\frac{MM(2p)_{t-0.5}+MM(2p)_{t+0.5}}2\n\\]\ndonde:\n\\[\nMM(2p)_{t-0.5}=\\frac{x_{t-p}+...+x_{t-1}+x_t+...+x_{t+p-1}}{2p}\n\\]\ny\n\\[\nMM(2p)_{t+0.5}=\\frac{x_{t-p+1}+...+x_t+x_{t+1}+...+x_{t+p}}{2p}\n\\]\n\n\n\n\n\n\n\nObservación\n\n\n\nLa serie obtenida por médias móviles centradas (ya sea de orden impar \\(2p+1\\) o de orden par \\(2p\\)) pierde los \\(p\\) primeros valores y los \\(p\\) últimos. Es decir, la serie suavizada tendrá \\(2p\\) datos menos que la original, así que no conviene tomar el orden de la media móvil demasiado alto porque se perderían muchos datos.\n\n\nLa siguiente figura muestra cómo aumenta el suavizado de una serie (eliminación de las irregularidades) conforme aumentamos el orden de la media móvil (en negro, la serie original; en azul, medias móviles de orden 5; en verde, medias móviles de orden 8; en rojo, medias móviles de orden 12):\n\nlibrary(forecast)\nts.plot(AirPassengers, lwd = 2)\nlines(ma(AirPassengers, order = 5), \n      col = \"blue\", lwd = 1.5)\nlines(ma(AirPassengers, order = 8, centre = TRUE), \n      col = \"green\", lwd = 1.5)\nlines(ma(AirPassengers, order = 12), \n      col = \"red\", lwd = 1.5)\n\n\n\n\n\nDefinición 5.5 (Media móvil asimétrica) Dada una serie temporal \\(\\{x_t\\}_{t=1,...,n}\\), la media móvil asimétrica de orden \\(p\\) se define de la siguiente forma:\n\\[\nMMA(p)_t=\\frac{x_{t-p+1}+...+x_{t-1}+x_t}p\n\\]\nes decir, consiste en realizar la media aritmética de las \\(p\\) últimas observaciones de la serie.\n\nEsta variante de las medias móviles se puede usar para realizar predicciones en un modelo con tendencia aproximadamente constante localmente. Suele ser más adecuado para las predicciones a corto plazo que un ajuste por mínimos cuadrados, debido a su enfoque local para la estimación de la tendencia. Es decir, si disponemos de las observaciones hasta el instante \\(T\\), la predicción para el instante siguiente viene dada por la media de las \\(p\\) últimas observaciones:\n\\[\n\\widehat{x}_{T+1}=\\frac{x_{T-p+1}+...+x_{T-1}+x_T}p\n\\]\nEn esta expresión se aprecia que todas las observaciones que intervienen en la media tienen el mismo peso. En el tema siguiente veremos que los métodos de alisado exponencial suelen dar mejores resultados porque se les da más peso a las observaciones más recientes que a las más antiguas."
  },
  {
    "objectID": "Tema4.html#descomposición-clásica-de-series-temporales",
    "href": "Tema4.html#descomposición-clásica-de-series-temporales",
    "title": "5  Tema 4. Conceptos básicos en series temporales",
    "section": "5.6 Descomposición clásica de series temporales",
    "text": "5.6 Descomposición clásica de series temporales\nEl objetivo de esta sección es mostrar las técnicas clásicas para descomponer una serie temporal en sus 3 componentes fundamentales (Tendencia-Ciclo, Estacional e Irregular). Para ello, es necesario determinar previamente si el esquema de integración de dichas componentes se considera aditivo, o multiplicativo.\nComenzaremos con el enfoque clásico para extraer las componentes en un esquema aditivo, conocido como el método de la diferencia a la media móvil.\n\n5.6.1 Método de la diferencia a la media móvil\nEl método de la diferencia a la media móvil es el método que se usa para desestacionalizar una serie que presenta un esquema aditivo:\n\\[\nx_t=T_t+S_t+I_t\n\\] Consideremos una serie temporal con el esquema anterior, presentando componente estacional, y llamemos \\(L\\) al periodo de la componente estacional. En muchas ocasiones \\(L\\) será un número par, por ejemplo \\(L=12\\) para datos mensuales, \\(L=4\\,\\)para datos trimestrales, etc.\nLa idea fundamental para intentar eliminar la componentes estacional consiste en tomar medias móviles de orden \\(L\\) (periodo de la componente estacional). Realizamos los siguientes pasos:\n\nCalcular la media móvil centrada de orden \\(L\\) para la serie y determinar la componente Tendencia-Ciclo.\nCalculando la media móvil centrada de orden \\(L\\), donde \\(L\\) representa el periodo de la componente estacional, se consigue eliminar en gran parte el efecto de la componente estacional así como de la componente irregular.\nPor tanto, la serie obtenida por medias móviles servirá como estimación de la componente Tendencia-Ciclo (\\(T_t\\)):\n\\[\nT_t = MM(L)_t\n\\]\nRecordar que si \\(L\\) es par, la media móvil centrada se obtiene realizando el promedio de dos series de medias móviles.\nAdemás, si \\(L\\) es par, la serie obtenida por medias móviles tiene \\(L\\) datos menos que la serie original.\nPor ejemplo, si la serie original se refiere a datos mensuales, tendremos un dato menos por cada mes.\nSi \\(L\\) es impar, la serie obtenida por medias móviles tiene \\(L-1\\) datos menos que la serie original.\nObtener los índices brutos de variación estacional (IBVE).\nComo el esquema es aditivo:\n\\[\nx_t = T_t + S_t + I_t\n\\]\nuna estimación de las componentes Estacional e Irregular conjuntamente viene dada por:\n\\[\n\\widehat{S_t + I_t} = x_t - T_t = x_t - MM(L)_t\n\\]\nes decir, hay que restar a la serie original la serie obtenida mediante medias móviles de orden \\(L\\) (de ahí el nombre de método de la diferencia a la media móvil).\nCada uno de los valores obtenidos mediante la diferencia anterior se denomina índice bruto de variación estacional en el instante \\(t\\):\n\\[\n(IBVE)_t = \\widehat{S_t + I_t} = x_t - MM(L)_t\n\\]\ndonde el calificativo de bruto se debe a que el índice estacional está contaminado por la componente irregular.\nObtener los índices de variación estacional no normalizados (IVENN).\nCon el fin de eliminar la componente irregular de los índices anteriores, calcularemos la media de los índices para cada estación.\nSi disponemos de información correspondiente a \\(K\\) periodos completos y un total de \\(N\\) observaciones, entonces:\n\\[\nN = L \\cdot K\n\\]\nPor ejemplo, pensemos en datos mensuales y un total de 5 años completos, es decir, \\(12 \\times 5 = 60\\) datos.\nAl realizar medias móviles se pierden \\(L\\) datos (uno por cada estación, si \\(L\\) es par), de manera que para cada estación dispondríamos de exactamente \\(K - 1\\) datos (en lugar de \\(K\\)).\nLlamaremos índice de variación estacional no normalizado al promedio de los IBVE para cada estación \\(h\\):\n\\[\n(IVENN)_h = \\frac{\\sum_{\\{t:h(t)=h\\}} (IBVE)_t}{K - 1}\n\\quad h = h_1, h_2, \\ldots, h_L\n\\]\ndonde \\(\\{t : h(t) = h\\}\\) denota el conjunto de instantes de tiempo que se corresponden con la estación \\(h\\).\nSi \\(K\\) no es muy pequeño, el promedio atenúa en gran medida la componente irregular, de modo que estos índices contienen información estacional pero no irregular.\nEn casos con periodos incompletos o cuando \\(L\\) es impar, el número de datos \\((IBVE)_t\\) disponible para cada estación puede ser diferente. Denotando por \\(K_h\\) al número de datos de cada estación \\(h\\):\n\\[\n(IVENN)_h = \\frac{\\sum_{\\{t:h(t)=h\\}} (IBVE)_t}{K_h}\n\\quad h = h_1, h_2, \\ldots, h_L\n\\]\nObtener los índices de variación estacional normalizados (IVE) y determinar la componente Estacional.\nSi una serie no tiene componente estacional, en un modelo aditivo se tendría que \\(S_t \\equiv 0\\).\nEs razonable suponer que la componente estacional no debe afectar al nivel de la serie, por lo que la media de la componente estacional debería ser 0.\nPor tanto, definimos los índices de variación estacional normalizados para cada estación \\(h\\) como:\n\\[\n(IVE)_h = (IVENN)_h -\n\\frac{\\sum_{h \\in \\{h_1, \\ldots, h_L\\}} (IVENN)_h}{L}\n\\]\n(aunque existen otras formas de normalizar los índices de variación estacional).\nEstos índices suponen una estimación de la componente estacional de la serie para cada estación \\(h\\).\nEs decir, determinamos la componente estacional para cada instante de tiempo \\(t\\), haciéndola coincidir con el índice correspondiente a su estación \\(h(t)\\):\n\\[\nS_t = (IVE)_{h(t)}\n\\]\nDesestacionalizar la serie.\nEn el modelo aditivo, la desestacionalización se logra restando los índices de variación estacional a la serie original:\n\\[\nD_t = x_t - S_t = x_t - (IVE)_{h(t)}\n\\quad \\text{(serie desestacionalizada)}\n\\]\nEn algunos programas (por ejemplo, SPSS) tras la desestacionalización se extrae una nueva componente Tendencia-Ciclo suavizando la serie desestacionalizada (por ejemplo, aplicando dos veces medias móviles de orden 3).\nEn R esta etapa puede obviarse.\nDeterminar la componente Irregular.\nUna vez extraídas las componentes Estacional (\\(S_t\\)) y Tendencia-Ciclo (\\(T_t\\)), la componente Irregular (\\(I_t\\)) se obtiene de forma inmediata mediante:\n\\[\nI_t = x_t - T_t - S_t\n\\]\nLa situación ideal sería que dicha componente irregular se comportara como un ruido blanco.\nA continuación, mostramos el enfoque clásico para extraer las componentes de una serie temporal si el esquema es multiplicativo.\n\n\n\n5.6.2 Método de la razón a la media móvil\nEl método de la razón a la media móvil es el método que se usa para desestacionalizar una serie que presenta un esquema multiplicativo:\n\\[\nx_t=T_t\\times S_t\\times I_t\n\\]\nLos pasos para desestacionalizar la serie y extraer las componentes son similares al caso aditivo, pero realizando cocientes en lugar de diferencias:\n\nCalcular la media móvil centrada de orden \\(L\\) para la serie y determinar la componente Tendencia-Ciclo.\n\\[\nT_t = MM(L)_t\n\\]\nObtener los índices brutos de variación estacional (IBVE).\nComo el esquema es multiplicativo, una estimación de las componentes Estacional e Irregular conjuntamente viene dada por:\n\\[\n\\widehat{S_t \\times I_t} = \\frac{x_t}{\\widehat{T}_t} = \\frac{x_t}{MM(L)_t}\n\\]\nEs decir, se divide la serie original entre la serie obtenida mediante medias móviles de orden \\(L\\) (de ahí el nombre de método de la razón a la media móvil).\nCada uno de los valores obtenidos mediante el cociente anterior se denomina índice bruto de variación estacional en el instante \\(t\\):\n\\[\n(IBVE)_t = \\widehat{S_t \\times I_t} = \\frac{x_t}{MM(L)_t}\n\\]\nObtener los índices de variación estacional no normalizados (IVENN).\nLlamaremos índice de variación estacional no normalizado al promedio de los IBVE para cada estación \\(h\\).\nDenotemos por \\(K_h\\) al número de datos \\((IBVE)_t\\) disponible para cada estación \\(h\\), entonces:\n\\[\n(IVENN)_h = \\frac{\\sum_{\\{t : h(t) = h\\}} (IBVE)_t}{K_h}\n\\quad h = h_1, h_2, \\ldots, h_L\n\\]\nObtener los índices de variación estacional normalizados (IVE) y determinar la componente Estacional.\nSi una serie no tiene componente estacional, en un modelo multiplicativo se tendría que \\(S_t \\equiv 1\\).\nEs razonable suponer que la componente estacional no debe afectar al nivel de la serie, por lo que en el modelo multiplicativo la media de la componente estacional debería ser 1.\nSin embargo, los índices calculados en el apartado anterior pueden no tener media uno.\nPor tanto, definimos los índices de variación estacional normalizados para cada estación \\(h\\) como:\n\\[\n(IVE)_h = \\frac{(IVENN)_h}\n{\\frac{\\sum_{h \\in \\{h_1, \\ldots, h_L\\}} (IVENN)_h}{L}}\n\\]\nEstos índices constituyen una estimación de la componente estacional de la serie para cada estación \\(h\\).\nEs decir, determinamos la componente estacional para cada instante de tiempo \\(t\\), haciéndola coincidir con el índice de variación estacional correspondiente a su estación \\(h(t)\\):\n\\[\nS_t = (IVE)_{h(t)}\n\\]\nDesestacionalizar la serie.\nEn el modelo multiplicativo, la desestacionalización de la serie se consigue dividiendo la serie por los índices de variación estacional:\n\\[\nD_t = \\frac{x_t}{(IVE)_{h(t)}}\n\\]\nEn algunos programas como SPSS, una vez desestacionalizada la serie, se extrae una nueva componente Tendencia-Ciclo suavizando la serie desestacionalizada (por ejemplo, aplicando dos veces medias móviles de orden 3).\nEn R esta etapa puede obviarse.\nDeterminar la componente Irregular.\nUna vez extraídas las componentes Estacional (\\(S_t\\)) y Tendencia (\\(T_t\\)), la componente Irregular o restante se obtiene de forma inmediata mediante:\n\\[\nI_t = \\frac{x_t}{T_t \\times S_t}\n\\]\nLa situación ideal sería que dicha componente irregular se comportara como un ruido gaussiano de media 1, o bien como la exponencial de un ruido gaussiano de media cero.\n\nA modo de ejemplo, a continuación mostramos una serie temporal y las componentes que resultan con la descomposición clásica:\n\nplot(decompose(AirPassengers, type = \"multiplicative\"))\n\n\n\n\n\n\n\n\n\n\nNota:\n\n\n\nPodemos comprobar que la componente estacional se mantiene estable a lo largo del tiempo. Es decir, todos los meses de enero toman el mismo valor, independientemente del año. Lo mismo sucede con los febreros, marzos, …, diciembres. Esta situación es característica para la descomposición clásica."
  },
  {
    "objectID": "Tema4.html#predicciones-con-análisis-clásico-y-limitaciones",
    "href": "Tema4.html#predicciones-con-análisis-clásico-y-limitaciones",
    "title": "5  Tema 4. Conceptos básicos en series temporales",
    "section": "5.7 Predicciones con Análisis Clásico y limitaciones",
    "text": "5.7 Predicciones con Análisis Clásico y limitaciones\nEn el enfoque clásico, la forma de realizar predicciones se basa en la descomposición de la serie en sus componentes fundamentales (tendencia, estacionalidad e irregular). Extraídas las componentes, se predice cada una de ellas y la predicción de la serie original se obtiene combinando dichas predicciones según se trate de un esquema aditivo o multiplicativo.\n¿Cómo realizar predicciones de la componente irregular \\(I_t\\)?\nComo se trata de la parte aleatoria de la serie, las predicciones de la componente irregular valdrán cero en el esquema aditivo y uno en el multiplicativo.\nEs decir, para todo instante \\(t\\), tendremos que la predicción de la componente irregular en dicho instante es:\n\\[\n\\widehat{I}_{t}=0\\quad (esquema \\: aditivo), \\quad \\widehat{I}_{t}=1\\quad (esquema \\: multiplicativo)\n\\]\n¿Cómo realizar predicciones de la Componente Estacional \\(S_t\\)?\nBastará con repetir el valor obtenido para cada estación. Por ejemplo, si tenemos datos mensuales y la componente estacional extraída asigna un valor de 50 a los eneros, entonces la predicción de la componente estacional será siempre de 50 para los futuros eneros. De la misma forma se realizaría la predicción para el resto de meses, pues el enfoque clásico considera componente estacional estable.\nSi la serie original tiene perido \\(L\\) y disponemos de observaciones hasta el instante \\(T\\), entonces la predicción de la componente estacional en el instante T+m es:\n\\[\n\\widehat{S}_{T+m}={S}_{T+m-L}\\quad m=1,2,...,L\n\\]\ndonde \\(S_{T+m-L}\\) representa el valor de la componente estacional en el instante \\(T+m-L\\), es decir, el valor del IVE en la estación que corresponde a dicho instante.\n¿Cómo realizar predicciones de la componente Tendencia-ciclo \\(T_t\\)?\nLa componente tendencia puede modelizarse con cualquier método para series sin estacionalidad. Por ejemplo, realizando un ajuste por mínimos cuadrados usando como predictor (predictores) el tiempo o potencias del mismo. El modelo obtenido para la tendencia usando mínimos cuadrados es adecuado para representar el comportamiento de la serie y captar los aspectos más permanentes del fenómeno estudiado (predicciones a medio o largo plazo). Sin embargo, no es aconsejable para las predicciones a corto plazo.\nPor ejemplo, si la Tendencia es lineal respecto al tiempo: \\[\nT_t=b_0+b_1\\cdot t,\n\\] podemos estimar la ecuación de dicha recta usando regresión lineal simple. Por tanto, en este caso las predicciones de la tendencia en cualquier instante \\(t\\), se obtendrán mediante:\n\\[\n\\widehat{T}_{t}=\\widehat{b_0}+\\widehat{b_1}\\cdot t\n\\]\nY si la Tendencia es polinómica: \\[\n\\widehat{T}_{t}=\\widehat{b_0}+\\widehat{b_1}\\cdot t+b_2\\cdot t^2+...+\\widehat{b_k}\\cdot t^k\n\\] también podemos estimar los coeficientes del modelo usando regresión lineal múltiple.\nObsérvese que se trata de un enfoque global del análisis de la tendencia, el cual permite obtener un modelo matemático que modeliza la tendencia de la serie usando todas las observaciones de la serie, y además todas con el mismo peso.\nLos procedimientos adecuados para obtener la tendendia desde un enfoque local que permita realizar predicciones adecuadas a corto plazo son, por ejemplo, el método de las medias móviles asimétricas o los métodos de alisado exponencial, que veremos en un tema posterior.\n¿Cómo realizar predicciones de la serie original?\nSi disponemos de \\(T\\) observaciones de la serie y queremos realizar predicciones para los \\(L\\) instantes siguientes (\\(L\\) es el periodo), en el caso de esquema aditivo tendremos:\n\\[\n\\widehat{x}_{T+m}=\\widehat{T}_{T+m}+\\widehat{S}_{T+m}\\quad m=1,2,...,L\n\\]\ny en el caso de esquema multiplicativo tendremos:\n\\[\n\\widehat{x}_{T+m}=\\widehat{T}_{T+m}\\times \\widehat{S}_{T+m}\\quad\nm=1,2,...,L\n\\]\nLimitaciones del Análisis Clásico\nEl análisis clásico de series temporales tiene dos usos principalmente:\n\nDescribir el comportamiento de la serie temporal (análisis descriptivo), haciendo uso por ejemplo de la descomposición de la serie en las componentes Tendencia, Estacionalidad e Irregular.\nRealizar predicciones a medio o largo plazo.\n\nComo método descriptivo sigue siendo interesante su uso gracias a la sencillez de los métodos expuestos. Del mismo modo, cuando sólo nos interesa estudiar el comportamiento futuro de la serie a largo plazo, es decir, estudiar cómo evolucionaría la serie a grandes rasgos, también interesa emplear un análisis clásico.\nSin embargo, el enfoque global de los método clásicos impide realizar predicciones adecuadas a corto plazo, siendo ésta la principal limitación de un análisis clásico. Además, los métodos clásicos proporcionan demasiada rigidez al modelo, perdiendo en ocasiones información relevante.\nPara suplir las carencias del método clásico, se propusieron nuevos métodos como la descomposición STL, que veremos a continuación, o los métodos de alisado exponencial, que veremos en un tema posterior."
  },
  {
    "objectID": "Tema4.html#la-descomposición-stl",
    "href": "Tema4.html#la-descomposición-stl",
    "title": "5  Tema 4. Conceptos básicos en series temporales",
    "section": "5.8 La descomposición STL",
    "text": "5.8 La descomposición STL\nEl método STL (Seasonal and Trend decomposition using LOESS) es una técnica alternativa a la descomposición clásica utilizada para descomponer una serie temporal en sus componentes básicas: tendencia, estacionalidad e irregular. Se basa en el suavizado de datos mediante LOESS (locally estimated scatterplot smoothing), que permite la obtención de las componentes de forma más versátil y flexible. Se trata de un método más reciente que la descomposición clásica, desarrollado en el siguiente artículo: Cleveland, R. B., Cleveland, W. S., McRae, J. E., & Terpenning, I. J. (1990). STL: A seasonal-trend decomposition procedure based on loess. Journal of Official Statistics, 6(1), 3–33.\nMientras que la descomposición clásica considera que la componente estacional es completamente estable, la descomposición STL permite que la componente estacional varíe a lo largo del tiempo. La diferencia fundamental radica en el proceso de desestacionalización de la serie: mientras que el enfoque clásico usa medias móviles, el STL usa el suavizado local LOESS.\nImportante: El método STL considera que las componentes de la serie se combinan siguiendo un esquema aditivo. En el caso de esquema multiplicativo, primero debe realizarse una transformación logarítmica para convertirlo en esquema aditivo.\n¿En qué consiste el método LOESS?\nLOESS realiza regresiones locales a lo largo de los datos. En cada punto \\(x_i\\) de la serie, se ajusta un polinomio (generalmente de primer o segundo grado) utilizando solo los datos cercanos a ese punto. Los puntos cercanos se definen por una ventana de vecindad, cuyo tamaño está determinado por un parámetro de suavizado. Este parámetro puede ser una proporción del total de puntos (ancho de banda o bandwidth). Los puntos dentro de la ventana de vecindad se ponderan de acuerdo con su distancia al punto \\(x_i\\). Los puntos más cercanos tienen mayor peso en la estimación del polinomio local que los puntos más lejanos. Para cada punto \\(x_i\\) de la serie, se calcula un valor ajustado \\(\\hat{x_i}\\) mediante la regresión local ponderada. Este proceso se repite para cada punto de la serie, resultando en una curva suavizada.\nLOESS es una técnica eficaz para suavizar datos y detectar tendencias locales sin imponer una estructura global rígida. Es especialmente útil para datos que no siguen una forma predefinida y permite capturar patrones locales mediante ajustes flexibles y ponderados.\nA continuación mostramos un ejemplo del método LOESS, así como el efecto del parámetro de suavizado. Para ello usaremos el conjunto de datos “economics” del paquete ggplot2, y suavizaremos la serie correspondiente al tiempo de desempleo (variable uempmed, que representa la mediana del número de días sin empleo). Observamos que la serie original (en negro) contiene numerosas irregularidades, que se suavizan al aplicar LOESS con parámetros de suavizado 10% (en azul), 30% (en verde) y 50% (en rojo). Indicar que si la serie original tiene por ejemplo 100 observaciones y se usa un suavizado del 50% (parámetro span=0.5), entonces para cada punto \\(x_i\\) de la serie, la ventana de vecindad se construye con 25 datos a la izquierda de xi y otros 25 datos a la derecha de \\(x_i\\).\n\nlibrary(ggplot2)\n\nWarning: package 'ggplot2' was built under R version 4.2.3\n\ndatos &lt;- economics  \ndatos$index &lt;- 1:nrow(datos) \nloess10 &lt;- loess(uempmed ~ index, data=datos, span=0.10) \nloess30 &lt;- loess(uempmed ~ index, data=datos, span=0.30) \nloess50 &lt;- loess(uempmed ~ index, data=datos, span=0.50) \n\nplot(datos$uempmed, x=datos$date, type=\"l\", main=\"Loess Smoothing\",\n     xlab=\"Date\", ylab=\"Unemployment (Median)\", lwd = 2)\nlines(predict(loess10), x=datos$date, col=\"blue\", lwd = 2)\nlines(predict(loess30), x=datos$date, col=\"green\", lwd = 2)\nlines(predict(loess50), x=datos$date, col=\"red\", lwd = 2)\n\n\n\n\nY para valores altos del parámetro de suavizado tendremos un suavizado global en lugar de local (obsérvese que la curva marrón se corresponde con la ecuación de una parábola que ajusta globalmente los datos de la serie):\n\nloess100 &lt;- loess(uempmed ~ index, data=datos, span=1)\nloess200 &lt;- loess(uempmed ~ index, data=datos, span=2)\n\nplot(datos$uempmed, x=datos$date, type=\"l\", main=\"Loess Smoothing\",\n     xlab=\"Date\", ylab=\"Unemployment (Median)\", lwd = 2)\nlines(predict(loess100), x=datos$date, col=\"orange\", lwd = 2)\nlines(predict(loess200), x=datos$date, col=\"brown\", lwd = 2)\n\n\n\n\nResumen de las etapas en la descomposición STL\n\nRealizar un suavizado de la serie original mediante LOESS con una ventana grande, con el fin de captar las variaciones a largo plazo (eliminando así las fluctuaciones debidas a la componente estacional). El resultado de este suavizado nos dará una primera estimación de la Tendencia-Ciclo (\\(T_t\\)).\nRestar a la serie original la Tendencia obtenida en la etapa anterior. Es decir, hacemos \\(x_t-T_t\\), para conseguir una serie temporal con tendencia constante.\nDividir la serie de la etapa anterior (sin tendencia) en subseries: Supongamos que la serie original tiene estacionalidad de periodo \\(L\\), entonces hay que dividir la serie de la etapa anterior en \\(L\\) subseries, una para cada estación. Por ejemplo, para datos mensuales durante varios años, tendremos que \\(L=12\\). Esta etapa implica considerar una serie para cada estación, es decir, una serie con los datos de enero, otra con los datos de febrero, …, y otra con los datos de diciembre.\nObtener una estimación de la componente Estacional (\\(S_t\\)) mediante suavizado LOESS: En esta etapa se fija el valor del parámetro “s.window” correspondiente al ancho de banda del suavizado para la estacionalidad. Dicho parámetro debe tomar un valor impar. Para cada subserie de la etapa anterior, se aplica el suavizado LOESS y “s.window” representa el número de periodos (años) consecutivos usados en la estimación de cada valor de la componente estacional. Valores pequeños permiten cambios más rápidos. Y en el caso de usar todos los periodos se considera estacionalidad estable (igual que en enfoque clásico). Al igual que en la descomposición clásica, las estimaciones resultantes se normalizan para conseguir que la media de cada periodo (año) completo sea cero (recordar que se supone esquema aditivo).\nObtener la componente Irregular: Para ello bastará restar a la serie original, las estimaciones obtenidas para la estacionalidad y la tendencia (\\(I_t=x_t-T_t-S_t\\)).\n\nNOTA: La extracción de las componentes puede ser mejorada siguiendo un ciclo iterativo como el siguiente.\nCon la tendencia inicial \\(T_t\\) y la estacionalidad inicial \\(S_t\\) estimadas, se sigue un ciclo iterativo para ajustar y mejorar las estimaciones:\n\nAjuste de la Tendencia: eliminar el efecto de la estacionalidad de la serie original (serie desestacionalizada) \\[\nx_t-S_t\n\\] y obtener una nueva estimación de la componente Tendencia-Ciclo (nueva \\(T_t\\)) mediante un nuevo suavizado LOESS sobre la serie desestacionalizada. En este proceso se fija el valor del parámetro “t.window” correspondiente al ancho de banda del suavizado para capturar la tendencia subyacente. Dicho parámetro debe tomar un valor impar y representa el número de observaciones consecutivas usadas para estimar la tendencia. Valores pequeños permiten cambios más rápidos.\nAjuste de la Estacionalidad: Se elimina la tendencia ajustada de la serie \\[\nx_t-T_t\n\\] Las subseries estacionales se suavizan de nuevo para recalcular \\(S_t\\).\nAjuste de la componente Irregular: Se recalcula como \\[\nI_t = x_t-T_t-S_t\n\\]\n\nEste ciclo se repite varias veces para mejorar la precisión de los componentes.\nVeamos como ejemplo la descomposición STL sobre la serie “AirPassengers” incluida en R.\n\nserie_pasajeros &lt;- AirPassengers\nts.plot(serie_pasajeros, lwd = 2)\n\n\n\n\nObservamos esquema multiplicativo, así que transformamos los datos para conseguir esquema aditivo, necesario para descomposición STL.\n\nserie_aditiva &lt;- log(serie_pasajeros)\nts.plot(serie_aditiva, lwd = 2)\n\n\n\n\nRealizamos ahora la descomposición STL sobre la serie aditiva, fijando s.window (ancho de banda de la estacionalidad):\n\nmodelo_STL &lt;- stl(serie_aditiva, s.window = 7)\n\nplot(modelo_STL)\n\n\n\n\nNota: Obsérvese que el aspecto de la componente estacional varía a lo largo del tiempo, a diferencia de lo que sucede en el enfoque clásico."
  },
  {
    "objectID": "Tema5.html#método-de-holt",
    "href": "Tema5.html#método-de-holt",
    "title": "6  Tema 5. Métodos de Alisado Exponencial",
    "section": "6.4 Método de Holt",
    "text": "6.4 Método de Holt\nEste método de alisado se aplica en las mismas situaciones que el alisado exponencial doble, es decir, cuando la serie en estudio no presenta estacionalidad y la tendencia de la serie se considera lineal localmente.\nNuevamente, la serie en estudio se expresa de la siguiente forma en cada instante:\n\\[\n\\left\\{\n\\begin{array}{lll}\nx_t=T_t+I_t=\\left( a_t+b_t\\cdot t\\right) +I_t &  & \\text{modelo aditivo} \\\\\nx_t=T_t\\times I_t=\\left( a_t+b_t\\cdot t\\right) \\times I_t &  & \\text{modelo\nmultiplicativo}\n\\end{array}\n\\right.\n\\]\ndonde \\(a_t\\) representa el de la serie en cada instante \\(t\\), mientras que \\(b_t\\) representa la de la tendencia lineal en dicho instante.\nLa idea del método de Holt es similar al alisado exponencial doble: en cada instante \\(t\\), queremos estimar el nivel de la serie (\\(a_t\\)) y la pendiente de la tendencia (\\(b_t\\)). A diferencia del alisado exponencial doble, en el método de Holt se usan dos parámetros de alisado que denotaremos por \\(\\alpha \\in \\left[0,1\\right]\\) y \\(\\beta \\in \\left[0,1\\right]\\).\nEn el método de Holt, la estimación del nivel en el instante \\(t\\) viene dada por la siguiente serie alisada:\n\\[\n\\boxed{\na_t = \\alpha x_t + (1 - \\alpha)\\left(a_{t-1} + b_{t-1}\\right),\n}\n\\]\nes decir, se obtiene como una media ponderada entre la última observación y la suma (nivel + pendiente) del instante anterior.\nPor otra parte, la estimación de la pendiente en el instante \\(t\\) viene dada por la siguiente serie alisada:\n\\[\n\\boxed{\nb_t = \\beta \\left( a_t - a_{t-1} \\right) + (1 - \\beta) b_{t-1}\n}\n\\]\nEs decir, se obtiene como una media ponderada entre el último incremento del nivel y la pendiente en el instante anterior.\nPara aplicar la fórmula recursiva anterior, necesitamos disponer de los parámetros de alisado \\(\\alpha \\in [0, 1]\\) y \\(\\beta \\in [0, 1]\\), así como de los valores iniciales de nivel (\\(a_0\\)) y pendiente (\\(b_0\\)).\nComo valores iniciales se suelen tomar la ordenada en el origen (\\(a_0 = \\text{cte}\\)) y la pendiente (\\(b_0 = \\text{pendiente}\\)) de la recta que ajusta la serie por mínimos cuadrados usando todos los datos.\nCon respecto a los parámetros de alisado, podemos seleccionar aquellos que minimicen la suma de cuadrados de los errores de estimación.\nLas predicciones con el método de Holt se obtienen de forma análoga al alisado doble:\nsi disponemos de información de la serie hasta el instante \\(T\\), \\(\\{x_t\\}_{t=1,2,\\ldots,T}\\),\nlas predicciones vienen dadas por:\n\\[\n\\boxed{\n\\begin{aligned}\n\\widehat{x}_{T+1/T} &= a_T + b_T \\cdot 1 \\\\\n\\widehat{x}_{T+2/T} &= a_T + b_T \\cdot 2 \\\\\n&\\vdots \\\\\n\\widehat{x}_{T+m/T} &= a_T + b_T \\cdot m \\qquad \\forall\\, m = 1, 2, 3, \\ldots\n\\end{aligned}\n}\n\\]\nComo siempre, a medida que disponemos de nuevas observaciones, se calculan los valores de las series alisadas para los nuevos instantes, y por tanto se revisan las predicciones de manera automática.\nEn el siguiente gráfico se muestra la serie original (negro), la serie ajustada (azul) usando el método de Holt, y las predicciones (rojo) para futuros instantes.\n\nHolt &lt;- HoltWinters(economics$uempmed, gamma = FALSE)\nts.plot(economics$uempmed, lwd = 1.5)\nlines(Holt$fitted[ , 1], col = \"blue\", lwd = 1.2)\nlines(predict(Holt, n.ahead = 20), col = \"red\", lwd = 1.2)",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Tema 5. Métodos de Alisado Exponencial</span>"
    ]
  },
  {
    "objectID": "Tema5.html#método-de-holt-winters-multiplicativo",
    "href": "Tema5.html#método-de-holt-winters-multiplicativo",
    "title": "6  Tema 5. Métodos de Alisado Exponencial",
    "section": "6.5 Método de Holt-Winters multiplicativo",
    "text": "6.5 Método de Holt-Winters multiplicativo\nEste método de alisado es una variación del método de Holt que sirve para realizar predicciones en series que presentan estacionalidad. Además de la estacionalidad, se supone tendencia lineal (localmente) y que ambas componentes (tendencia y estacionalidad) se integran en la serie de forma multiplicativa.\nPor tanto, la serie en estudio se expresa de la siguiente forma en cada instante:\n\\[\n\\begin{array}{lll}\nx_t=T_t\\times S_t \\times I_t=\\left( a_t+b_t\\cdot t\\right) \\times S_t \\times I_t &  & \\text{\nmodelo multiplicativo}\n\\end{array}\n\\]\n\\[\n\\begin{array}{lll}\nx_t=T_t\\times S_t+I_t=\\left( a_t+b_t\\cdot t\\right) \\times S_t+I_t &  & \\text{\nmodelo multiplicativo (mixto)}\n\\end{array}\n\\]\ndonde \\(a_t\\) representa el nivel de la serie en cada instante \\(t\\), \\(b_t\\) representa la pendiente de la tendencia lineal en dicho instante y \\(S_t\\) la componente estacional de la serie que supondremos de período \\(L\\).\nSiguiendo la idea del método de Holt, en cada instante \\(t\\,\\)necesitamos estimar el nivel de la serie (\\(a_t\\)), la pendiente de la tendencia (\\(b_t\\)) y el factor estacional (\\(S_t\\)). En este caso se usarán tres series alisadas y tres parámetros de alisado que denotaremos por \\(\\alpha \\in \\left[0,1\\right]\\), \\(\\beta \\in \\left[0,1\\right]\\) y \\(\\gamma \\in \\left[0,1\\right]\\).\nEn el método de Holt-Winters multiplicativo, la estimación del nivel en el instante \\(t\\) viene dada por la siguiente serie alisada:\n\\[\n\\boxed{\na_t = \\alpha \\frac{x_t}{S_{t-L}} + (1 - \\alpha)\\left(a_{t-1} + b_{t-1}\\right)\n}\n\\]\nEs decir, se obtiene como una media ponderada entre la última observación desestacionalizada y la suma (nivel + pendiente) en el instante anterior.\nPor otra parte, la estimación de la pendiente en el instante \\(t\\) viene dada por la siguiente serie alisada:\n\\[\n\\boxed{\nb_t = \\beta \\left(a_t - a_{t-1}\\right) + (1 - \\beta) b_{t-1}\n}\n\\]\nEs decir, se obtiene como una media ponderada entre el último incremento del nivel y la pendiente en el instante anterior.\nFinalmente, la estimación del factor estacional en el instante \\(t\\) viene dada por la siguiente serie alisada:\n\\[\n\\boxed{\nS_t = \\gamma \\cdot \\frac{x_t}{a_t} + (1 - \\gamma) S_{t-L}\n}\n\\]\nPara aplicar la fórmula recursiva anterior necesitamos disponer de los parámetros de alisado \\(\\alpha \\in \\left[ 0,1\\right]\\), \\(\\beta \\in \\left[ 0,1\\right]\\) y \\(\\gamma \\in \\left[ 0,1\\right]\\), y de los valores inciales de nivel (\\(a_0)\\), pendiente (\\(b_0)\\), y factores estacionales (\\(S_0\\), \\(S_{-1}\\), …, \\(S_{-L+1}\\)). Como valores iniciales para el nivel y la pendiente (\\(a_0\\) y \\(b_0\\)) se suelen tomar la ordenada en el origen (\\(a_0=cte\\)) y la pendiente (\\(b_0=pendiente\\)) de la recta que ajusta a la serie desestacionalizada por mínimos cuadrados usando todos los datos, y como valores iniciales de los factores estacionales se suelen tomar los índices de variación estacional (IVE) obtenidos al desestacionalizar la serie (visto en análisis clásico).\nCon respecto a los parámetros de alisado, podemos seleccionar aquellos que minimicen la suma de cuadrados de los errores de estimación.\nLas predicciones con el método de Holt-Winters multiplicativo se obtienen de la siguiente forma: si disponemos de información de la serie hasta el instante \\(T\\), \\(\\{x_t\\}_{t=1,2,...,T}\\), las predicciones vienen dadas por\n\\[\n\\boxed{\n\\begin{aligned}\n\\widehat{x}_{T+1/T} &= \\left(a_T + b_T \\cdot 1\\right) \\times S_{T+1-L} \\\\\n\\widehat{x}_{T+2/T} &= \\left(a_T + b_T \\cdot 2\\right) \\times S_{T+2-L} \\\\\n&\\vdots \\\\\n\\widehat{x}_{T+m/T} &= \\left(a_T + b_T \\cdot m\\right) \\times S_{T+m-L} \\qquad \\forall\\, m = 1,2,\\ldots,L\n\\end{aligned}\n}\n\\]\nComo siempre, a medida que disponemos de nuevas observaciones, se calculan los valores de las series alisadas para los nuevos instantes y por tanto se revisan las predicciones de manera automática.\nEn el siguiente gráfico se muestra la serie original (negro), la serie ajustada (azul) usando Holt-Winters multiplicativo y las predicciones (rojo) para futuros instantes.\n\nHolt_Winter_multip &lt;- HoltWinters(AirPassengers, seasonal = \"multiplicative\")\n\nforecasted_values1 &lt;- predict(Holt_Winter_multip, n.ahead = 24)\nextended_data1 &lt;- ts(c(AirPassengers, forecasted_values1), \n                     start = start(AirPassengers), \n                     frequency = frequency(AirPassengers))\n\nts.plot(extended_data1, col = \"red\")\nlines(AirPassengers, lwd = 1.5)\nlines(Holt_Winter_multip$fitted[ , 1], col = \"blue\", lwd = 1.2)\nlines(predict(Holt_Winter_multip, n.ahead = 24), col = \"red\", lwd = 1.2)",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Tema 5. Métodos de Alisado Exponencial</span>"
    ]
  },
  {
    "objectID": "Tema5.html#interpretación-de-los-parámetros-de-alisado",
    "href": "Tema5.html#interpretación-de-los-parámetros-de-alisado",
    "title": "6  Tema 5. Métodos de Alisado Exponencial",
    "section": "6.7 Interpretación de los parámetros de alisado",
    "text": "6.7 Interpretación de los parámetros de alisado\nPara clarificar un poco el papel que tiene cada uno de los parámetros de alisado en los métodos vistos, podemos proporcinar la siguiente interpretación aproximada de los parámetros de alisado \\(\\alpha\\), \\(\\beta\\) y \\(\\gamma\\):\n\nAlfa (\\(\\alpha\\)). Parámetro de suavizado exponencial que controla el peso relativo dado a las observaciones más recientes a la hora de estimar el nivel de la serie, en contraposición a la media global de la serie. Cuando alfa toma el valor 1, se utiliza exclusivamente la única observación más reciente; cuando alfa toma el valor 0, las observaciones antiguas cuentan con tanto peso como las recientes. Alfa se utiliza en todos los métodos de alisado.\nBeta (\\(\\beta\\)). Parámetro de suavizado exponencial que controla el peso relativo dado a las observaciones recientes a la hora de estimar la tendencia de la serie en el presente. Toma valores de 0 a 1. Los valores próximos a 1 indican un mayor peso para los valores recientes. Beta se utiliza sólo en los métodos de suavizado exponencial con una tendencia lineal localmente. No se utiliza en el alisado exponencial simple ni doble.\nGamma (\\(\\gamma\\)). Parámetro de suavizado exponencial que controla el peso relativo dado a las observaciones recientes al estimar la estacionalidad del presente. Toma valores de 0 a 1. Los valores próximos a 1 corresponden a un mayor peso para las observaciones recientes. La gamma se utiliza en todos los métodos de suavizado exponencial con componente estacional. No se utiliza en los método de alisado simple, doble y de Holt.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Tema 5. Métodos de Alisado Exponencial</span>"
    ]
  },
  {
    "objectID": "Tema5.html#taxonomía-de-los-métodos-de-alisado-exponencial",
    "href": "Tema5.html#taxonomía-de-los-métodos-de-alisado-exponencial",
    "title": "6  Tema 5. Métodos de Alisado Exponencial",
    "section": "6.8 Taxonomía de los métodos de alisado exponencial",
    "text": "6.8 Taxonomía de los métodos de alisado exponencial\nLos métodos de alisado desarrollados en las secciones anteriores suponen una parte del total de métodos disponibles con ese mismo enfoque.\nLas formas más usuales de variar y combinar las componentes de tendencia y estacionalidad se muestran en la siguiente tabla, dando lugar a un total de 9 métodos de alisado exponencial (fuente: Hyndman, R.J. and Athanasopoulos, G., 2021):\n\n\n\nTabla 8.5 extraída de Hyndman and Athanasopoulos (2021)\n\n\nLa mayoría de dichos métodos son los desarrollados anteriormente en este tema, incluyendo como novedad los casos de tendencia amortiguada (con parámetro de alisado adicional denotado por \\(\\phi\\)), en los que la pendiente de la tendencia se ve amortiguada conforme aumenta el horizonte de predicción (\\(h\\)):\n\n\n\nTabla extraída de Hyndman and Athanasopoulos (2021)\n\n\nLa siguiente tabla muestra las fórmulas recurrentes para aplicar cada uno de los nueve métodos de alisado mencionados arriba, así como la expresión para obtener las predicciones puntuales con horizonte \\(h\\) (fuente: Hyndman, R.J. and Athanasopoulos, G., 2021). Indicar que la notación empleada para dicha tabla difiere de la usada en nuestro caso.\n\n\n\nTabla 8.6 extraída de Hyndman and Athanasopoulos (2021)\n\n\nCabe destacar, a modo resumen, que los métodos de alisado exponencial permiten obtener predicciones puntuales de la serie para instantes futuros. Aunque no se establece ninguna regla para el horizonte de predicción permitido, estos métodos tienen sentido para predicciones a corto plazo, siendo recomendable actualizar las fórmulas recurrentes conforme se dispone de nuevas observaciones de la serie.\nEn la próxima sección se introducen los modelos ETS, que suponen una extensión de los métodos de alisado exponencial.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Tema 5. Métodos de Alisado Exponencial</span>"
    ]
  },
  {
    "objectID": "Tema5.html#los-modelos-ets",
    "href": "Tema5.html#los-modelos-ets",
    "title": "6  Tema 5. Métodos de Alisado Exponencial",
    "section": "6.9 Los modelos ETS",
    "text": "6.9 Los modelos ETS\nLos modelos ETS, cuyas siglas se corresponden con (Error, Trend, Seasonal), representan los modelos estadísticos que subyacen bajo los métodos de alisado exponencial, dando lugar a las mismas estimaciones puntuales y permitiendo la obtención de intervalos de predicción.\nCada modelo ETS consiste en una ecuación que describe al proceso estocástico generador de la serie observada y, por otro lado, una o varias ecuaciones que describen cómo varían con el tiempo los estados (nivel, pendiente de la tendencia y estacionalidad). Por eso estos modelos se conocen como modelos de espacio de estados (state space models).\nPor facilitar la distinción, hablaremos de métodos de alisado exponencial y modelos de espacio de estados. Para cada método de alisado existen dos modelos: uno con errores aditivos y otro con errores multiplicativos. Ambos proporcionan las mismas predicciones puntuales pero diferentes intervalos de predicción.\nNotación: Usaremos la nomenclatura ETS(Error, Trend, Seasonal), donde:\n\n\\(Error= \\left\\{A,M\\right\\}\\) según sean errores aditivos (A) o multiplicativos (M).\n\\(Trend=\\left\\{N,A,A_d\\right\\}\\) según sea tendencia (lineal localmente) aditiva (A), amortiguada (\\(A_d\\)), o bien no haya tendencia (N).\n\\(Seasonal=\\left\\{N,A,M\\right\\}\\) según sea esquema aditivo (A) o multiplicativo (M) para combinar la estacionalidad con la tendencia, o bien no se contemple componente estacional (N).\n\nPor ejemplo, ETS(A,N,N) representaría el modelo de espacio de estados del alisado exponencial simple con errores aditivos.\nVeremos a continuación alguno de estos modelos en detalle.\n\n6.9.1 ETS(A,N,N): Modelo de espacio de estados del alisado exponencial simple con errores aditivos\nRecordemos las ecuaciones vistas para el método de alisado exponencial simple:\n\\[\na_t=\\alpha x_t+(1-\\alpha )a_{t-1}\\qquad (\\text{ecuación suavizado})\n\\]\n\\[\n\\widehat{x}_{t+1/t}=a_t \\qquad (\\text{ecuación predicción})\n\\]\nObsérvese que la ecuación del suavizado también puede reescribirse como sigue:\n\\[\n\\begin{array}{l}\na_t=\\\\\n=a_{t-1} + \\alpha (x_t-a_{t-1})\\\\\n=a_{t-1} + \\alpha (x_t-\\widehat{x}_{t/t-1})\\\\\n=a_{t-1} + \\alpha e_t\n\\end{array}\n\\]\ndonde \\(e_t=x_t-\\widehat{x}_{t/t-1}=x_t-a_{t-1}\\) es el residuo o error de predicción en el instante \\(t\\).\nPor tanto, tendremos las dos siguientes ecuaciones. La primera describe a la serie observada y la segunda cómo varían con el tiempo los estados (en esta caso, el nivel de la serie):\n\\[\nx_t=a_{t-1}+e_t\n\\]\n\\[\na_t=a_{t-1} + \\alpha e_t\n\\]\nA partir de las ecuaciones anteriores, el modelo estadístico ETS(A,N,N) se construye considerando una distribución probabilística para los errores. En este caso, y por analogía con otras metodologías estadísticas, supondremos que los residuos provienen de distribuciones \\(N(0,\\sigma^2)\\) independientes.\nPor tanto, el modelo ETS(A,N,N) viene dado por las ecuaciones:\n\\[\nX_t=a_{t-1}+\\epsilon_t\n\\]\n\\[\na_t=a_{t-1} + \\alpha \\epsilon_t\n\\] con \\((\\epsilon_t)\\) un ruido blanco gaussiano, es decir \\(\\epsilon_t \\sim N(0,\\sigma^2)\\) independientes para todo \\(t\\), donde \\(X_t\\) denota el proceso estocástico generador de la serie.\nLa interpretación del parámetro de alisado \\(\\alpha\\) es el mismo que vimos. Es decir, si \\(\\alpha=0\\), el nivel de la serie no cambia con el tiempo, y el modelo se reduce a:\n\\[\nX_t=a_{0}+\\epsilon_t\n\\]\nY si \\(\\alpha=1\\), para cada instante \\(t\\) se tiene que \\(X_t=a_t\\), y el modelo se reduce a un paseo aleatorio:\n\\[\nX_t=a_t=a_{t-1} + \\epsilon_t=X_{t-1}+\\epsilon_t\n\\]\nPodemos simular varias trayectorias de este proceso en R mediante:\n\nset.seed(123)\n\n# parámetros\na0 &lt;- 0\nalpha &lt;- 0.2\nx0 &lt;- a0\n\nnsim &lt;- 10\nn &lt;- 1000\n\n# Proceso\ne &lt;- rnorm(n)\na &lt;- a0 + c(0, cumsum(alpha*e))\nx &lt;- c(x0, a[1:n]+e)\n\ndt &lt;- 1/n\ntiempos &lt;- seq(from=0, to=1, by=dt)\ncolores &lt;- rainbow(nsim)\nplot(tiempos, x, ylim=c(-10,10), type = \"l\", lty = 1, col=colores[1])\nfor(i in 2:nsim){\n  e &lt;- rnorm(n)\n  a &lt;- c(a0, cumsum(alpha*e))\n  x &lt;- c(a0, a[1:n]+e)\n  lines(tiempos, x, col=colores[i])\n}\n\n\n\n\n\n\n\n\nPara \\(\\alpha=0\\), obtenemos un ruido blanco gaussiano:\n\n\n\n\n\n\n\n\n\n\n\n6.9.2 ETS(M,N,N): Modelo de espacio de estados del alisado exponencial simple con errores multiplicativos\nDe forma análoga a lo visto anteriormente, podemos considerar el modelo con errores multiplicativos, definiendo los errores en términos relativos:\n\\[\ne^{*}_t= \\frac{x_t-\\widehat{x}_{t/t-1}} {\\widehat{x}_{t/t-1}}\n\\]\nY sustituyendo \\(\\widehat{x}_{t/t-1}=a_{t-1}\\) en la expresión anterior, tenemos:\n\\[\nx_t= a_{t-1}+a_{t-1}e^{*}_t=a_{t-1}(1+e^{*}_t)\n\\]\nObsérvese que los residuos usuales (\\(e_t = x_t-\\widehat{x}_{t/t-1}\\)) y los relativos (\\(e^{*}_t\\)), se relacionan mediante:\n\\[\ne_t = \\widehat{x}_{t|t-1}e^{*}_t=a_{t-1}e^{*}_t\n\\]\nPor tanto, la ecuación de suavizado se reescribe:\n\\[\na_t=a_{t-1} + \\alpha e_t \\\\\n=a_{t-1} + \\alpha a_{t-1}e^{*}_t \\\\\n=a_{t-1}(1+\\alpha e^{*}_t)\n\\]\nA partir de las ecuaciones anteriores, el modelo estadístico ETS(M,N,N) se construye considerando una distribución probabilística para los errores relativos. En este caso, supondremos que provienen de distribuciones \\(N(0,\\sigma^2)\\) independientes.\nPor tanto, el modelo ETS(M,N,N) viene dado por las ecuaciones:\n\\[\nX_t=a_{t-1}(1+\\epsilon_t)\n\\]\n\\[\na_t=a_{t-1}(1+ \\alpha \\epsilon_t)\n\\]\ncon \\((\\epsilon_t)\\) un ruido blanco gaussiano, es decir, \\(\\epsilon_t \\sim N(0,\\sigma^2)\\) independientes para todo \\(t\\), donde \\(X_t\\) denota el proceso estocástico generador de la serie. Podemos simular varias trayectorias de este proceso en R mediante:\n\nset.seed(123)\n\n# parámetros\na0 &lt;- 1\nalpha &lt;- 0.2\nx0 &lt;- a0\n\nnsim &lt;- 10\nn &lt;- 1000\n\n# Proceso\ne &lt;- rnorm(n, mean=0, sd=0.1)\na &lt;- a0*c(1, cumprod(1 + alpha*e))\nx &lt;- c(x0, a[1:n]*(1+e))\n\ndt &lt;- 1/n\ntiempos &lt;- seq(from=0, to=1, by=dt)\ncolores &lt;- rainbow(nsim)\nplot(tiempos, x, ylim=c(0, 2), type = \"l\", lty = 1, col=colores[1])\nfor(i in 2:nsim){\n  e &lt;- rnorm(n, mean=0, sd=0.1)\n  a &lt;- c(a0, a0*cumprod(1 + alpha*e))\n  x &lt;- c(x0, a[1:n]*(1+e))\n  lines(tiempos, x, col=colores[i])\n}\n\n\n\n\n\n\n\n\n\n\n6.9.3 Otros modelos ETS\nDe forma análoga, se pueden desarrollar las ecuaciones que definen los diferentes modelos ETS según variemos el tipo de error, la tendencia y estacionalidad. Los resultados aparecen recogidos en las siguientes tablas (fuente: Hyndman, R.J. and Athanasopoulos, G., 2021):\n\n\n\nTabla 8.7 extraída de Hyndman and Athanasopoulos (2021)\n\n\n\n\n\nTabla 8.7 extraída de Hyndman and Athanasopoulos (2021)\n\n\n\n\n6.9.4 Estimación, selección del modelo ETS y predicciones\nPara la estimación de los parámetros (parámetros de suavizado y estados iniciales) en los modelos ETS, se utiliza el método de máxima verosimilitud en lugar de minimizar la suma de los errores al cuadrado. Recordemos que la verosimilitud representa la probabilidad de que los datos se generen a partir del modelo especificado, y una verosimilitud alta indica un buen ajuste del modelo.\nDestacar que, en el caso de modelos con errores aditivos y asumiendo distribución Normal para los errores, el método de máxima verosimilitud proporciona los mismos resultados que minimizar la suma de cuadrados de los errores. Sin embargo, para modelos con errores multiplicativos no es cierto.\nEl empleo de la estimación máximo-verosímil en los modelos ETS, permite el uso de criterios de información para la selección del modelo, como el AIC (Criterio de Información de Akaike) y el BIC (Criterio de Información Bayesiano). Estos criterios ayudan a determinar qué modelo ETS es el más apropiado para una serie temporal dada. Recordemos las definiciones del AIC y BIC:\n\\[\nAIC = 2 \\cdot k-2\\cdot ln(L) \\quad \\quad BIC = k \\cdot ln(L)-2 \\cdot ln(L)\n\\]\ndonde \\(L\\) es la verosimilitud del modelo,\\(k\\) es el número de parámetros estimados y \\(n\\) el número de datos. El modelo con el menor valor de AIC o BIC se considera el mejor ajuste.\nSi disponemos de una serie \\(\\left\\{x_t \\right\\}_{t=1,2,...,T}\\), las predicciones con modelos ETS se obtienen iterando las ecuaciones del modelo para los instantes \\(t=T+1,…,T+h\\), siendo \\(h\\) el horizonte de predicción deseado, y asumiendo que \\(\\epsilon_t=0\\) para \\(t&gt;T\\).\nNota: Las predicciones puntuales obtenidas con los métodos de alisado exponencial coinciden con las obtenidas mediante el correspondiente modelo ETS (tanto en el caso de modelo con errores aditivos como multiplicativos), siempre que se usen los mismos parámetros de alisado. Además, la predicción puntual coincide con la media de la distribución para las predicciones, excepto en el caso de modelos con estacionalidad multiplicativa.\nLa ventaja principal de los modelos ETS frente a los métodos de alisado exponencial es que permiten la obtención de intervalos de predicción, puesto que se dispone de una expresión para las variables del proceso estocástico, \\(\\left\\{X_t \\right\\}_{t=1,2,...,T}\\), y se asume distribución Normal para los errores.\nDe forma resumida, para la mayoría de los modelos ETS, un intervalo de predicción tendrá la siguiente forma:\n\\[\n(\\text{Estimación puntual} \\pm \\text{Error de predicción}) = (\\widehat{x}_{T+h/T} \\pm c \\cdot \\sigma_h)\n\\]\ndonde \\(c\\) es el cuantil de la distribución \\(N(0,1)\\) necesario según el nivel de confianza prefijado y \\(\\sigma_h^2\\) es la varianza de la predicción con horizonte \\(h\\). Indicar que la expresión analítica de \\(\\sigma_h^2\\) es complicada de obtener para algunos modelos ETS.\nVeamos un ejemplo de aplicación de los modelos ETS para la serie “AirPassengers”. En el siguiente gráfico se muestra la serie original (negro), la serie ajustada (azul oscuro) usando el modelo ETS(M,A,M) y las predicciones (azul claro) para los dos años siguientes con los intervalos de prediccón (sobras grises).\n\nlibrary(forecast)\nETS_model &lt;- ets(AirPassengers, model = \"MAM\")\nplot(forecast(ETS_model, h = 24), lwd = 2)\nlines(ETS_model$fitted, col = \"blue\", lwd = 1.5)",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Tema 5. Métodos de Alisado Exponencial</span>"
    ]
  },
  {
    "objectID": "Tema5.html",
    "href": "Tema5.html",
    "title": "6  Tema 5. Métodos de Alisado Exponencial",
    "section": "",
    "text": "6.1 Introducción\nUna de las críticas que se les hace a estos métodos clásicos es que no se adaptan a lo largo del tiempo de forma natural: en los métodos clásicos, la tendencia y la estacionalidad se estiman una sola vez, usando todas las observaciones y todas con el mismo peso. Sin embargo, parece más lógico que las observaciones más recientes tengan un mayor peso en las predicciones futuras y que las estimaciones de la tendencia y estacionalidad se actualicen conforme se obtienen nuevas observaciones.\nUna familia de modelos que aparecen la década de los años 60, intenta solucionar este problema. Se les conoce como técnicas de alisado exponencial, y se trata de técnicas bastante sencillas. Por este motivo, y a pesar de los años transcurridos, siguen siendo utilizadas en ciertas actividades de pronóstico, principalmente para realizar predicciones a corto plazo. Aplicar técnicas más sofisticadas no siempre se justifica.\nEl estudio de una serie temporal viene marcado por las diferentes metodologías empleadas en su tratamiento. La metodología que presentamos en este tema trata de explicar la trayectoria de una serie observada a través de la información contenida en los datos históricos, es decir, intenta capturar el comportamiento sistemático que muestra el pasado de la serie y en base a ello realizar predicciones respecto al futuro.\nLos métodos de alisado exponencial se clasifican dependiendo de si la serie en estudio presenta o no estacionalidad. En este tema veremos los siguientes:",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Tema 5. Métodos de Alisado Exponencial</span>"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Procesos estocásticos y series temporales",
    "section": "",
    "text": "0.1 Presentación\nEl presente libro contiene los apuntes de la asignatura “Procesos estocásticos y series temporales”, la cual es impartida en el Grado en Ciencia e Ingeniería de Datos de la Universidad Politécnica de Cartagena y la Universidad de Murcia.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Presentación</span>"
    ]
  },
  {
    "objectID": "index.html#licencia",
    "href": "index.html#licencia",
    "title": "Procesos estocásticos y series temporales",
    "section": "0.2 Licencia",
    "text": "0.2 Licencia\nEste es un libro abierto bajo la licencia\n\nPuedes copiar, redistribuir y adaptar la obra, siempre que des el crédito correspondiente, no la uses con fines comerciales y compartas bajo la misma licencia.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Presentación</span>"
    ]
  }
]